[32m[2022-06-11 09:30:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:30:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:30:29] __main__ INFO: [0mMACs   : 255.27M
[32m[2022-06-11 09:30:29] __main__ INFO: [0m#params: 1.73M
[32m[2022-06-11 09:31:23] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:31:23] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:31:27] __main__ INFO: [0mMACs   : 255.27M
[32m[2022-06-11 09:31:27] __main__ INFO: [0m#params: 1.73M
[32m[2022-06-11 09:31:49] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:31:49] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:31:52] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:31:52] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:40:40] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:40:40] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:40:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:40:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:41:50] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:41:50] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:41:53] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:41:53] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:41:54] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:46:24] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:46:24] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:46:28] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:46:28] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:48:39] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:48:39] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:48:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:48:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:49:27] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:49:27] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:49:31] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:49:31] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:49:56] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:49:56] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:50:00] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:50:00] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:50:00] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:50:01] __main__ INFO: [0mEpoch 0 loss 16761.8818 acc@1 0.1000 acc@5 0.5000
[32m[2022-06-11 09:50:01] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 09:50:01] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 09:51:35] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:51:35] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:51:39] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:51:39] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:51:39] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:52:14] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:52:14] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:52:22] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:52:22] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:52:26] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:52:26] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:53:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:53:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:53:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:53:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:53:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:53:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 09:53:34] __main__ INFO: [0mElapsed 1.07
[32m[2022-06-11 09:53:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 09:53:38] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6737 (1.1222) acc@1 0.8047 (0.6043) acc@5 0.9922 (0.9480)
[32m[2022-06-11 09:53:42] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6866 (0.9273) acc@1 0.7734 (0.6747) acc@5 0.9922 (0.9646)
[32m[2022-06-11 09:53:46] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6710 (0.8345) acc@1 0.7500 (0.7083) acc@5 1.0000 (0.9722)
[32m[2022-06-11 09:53:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5345 (0.7789) acc@1 0.8516 (0.7280) acc@5 0.9922 (0.9758)
[32m[2022-06-11 09:53:50] __main__ INFO: [0mElapsed 16.10
[32m[2022-06-11 09:53:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 09:53:51] __main__ INFO: [0mEpoch 1 loss 0.7673 acc@1 0.7416 acc@5 0.9840
[32m[2022-06-11 09:53:51] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:53:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 09:53:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6133 (0.5385) acc@1 0.7891 (0.8152) acc@5 0.9922 (0.9912)
[32m[2022-06-11 09:53:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4462 (0.5285) acc@1 0.8594 (0.8192) acc@5 1.0000 (0.9910)
[32m[2022-06-11 09:54:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3723 (0.5239) acc@1 0.8672 (0.8203) acc@5 0.9922 (0.9910)
[32m[2022-06-11 09:54:07] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4450 (0.5197) acc@1 0.8047 (0.8212) acc@5 1.0000 (0.9911)
[32m[2022-06-11 09:54:07] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 09:54:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 09:54:08] __main__ INFO: [0mEpoch 2 loss 0.6593 acc@1 0.7904 acc@5 0.9852
[32m[2022-06-11 09:54:08] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:54:08] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 09:54:12] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.3870 (0.4540) acc@1 0.8359 (0.8427) acc@5 0.9766 (0.9943)
[32m[2022-06-11 09:54:16] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4824 (0.4590) acc@1 0.8359 (0.8407) acc@5 0.9922 (0.9936)
[32m[2022-06-11 09:54:20] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6466 (0.4524) acc@1 0.7578 (0.8429) acc@5 0.9844 (0.9936)
[32m[2022-06-11 09:54:24] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5034 (0.4538) acc@1 0.8281 (0.8420) acc@5 1.0000 (0.9934)
[32m[2022-06-11 09:54:24] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 09:54:24] __main__ INFO: [0mVal 3
[32m[2022-06-11 09:54:25] __main__ INFO: [0mEpoch 3 loss 0.5483 acc@1 0.8188 acc@5 0.9891
[32m[2022-06-11 09:54:25] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:54:25] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 09:54:29] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3638 (0.4060) acc@1 0.8828 (0.8602) acc@5 1.0000 (0.9956)
[32m[2022-06-11 09:54:33] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4588 (0.4115) acc@1 0.8438 (0.8584) acc@5 1.0000 (0.9953)
[32m[2022-06-11 09:54:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.5021 (0.4133) acc@1 0.8203 (0.8588) acc@5 1.0000 (0.9948)
[32m[2022-06-11 09:54:40] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3403 (0.4129) acc@1 0.8750 (0.8584) acc@5 1.0000 (0.9943)
[32m[2022-06-11 09:54:40] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 09:54:40] __main__ INFO: [0mVal 4
[32m[2022-06-11 09:54:41] __main__ INFO: [0mEpoch 4 loss 0.5714 acc@1 0.8152 acc@5 0.9914
[32m[2022-06-11 09:54:41] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:54:41] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 09:54:45] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3706 (0.3736) acc@1 0.8750 (0.8724) acc@5 0.9922 (0.9960)
[32m[2022-06-11 09:54:49] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2914 (0.3719) acc@1 0.8984 (0.8723) acc@5 0.9922 (0.9961)
[32m[2022-06-11 09:54:53] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2328 (0.3769) acc@1 0.9453 (0.8708) acc@5 0.9922 (0.9955)
[32m[2022-06-11 09:54:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4291 (0.3776) acc@1 0.8594 (0.8705) acc@5 1.0000 (0.9954)
[32m[2022-06-11 09:54:57] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 09:54:57] __main__ INFO: [0mVal 5
[32m[2022-06-11 09:54:57] __main__ INFO: [0mEpoch 5 loss 0.5110 acc@1 0.8320 acc@5 0.9931
[32m[2022-06-11 09:54:57] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 09:54:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 09:55:02] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4245 (0.3538) acc@1 0.8203 (0.8777) acc@5 1.0000 (0.9963)
[32m[2022-06-11 09:55:06] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2674 (0.3568) acc@1 0.8984 (0.8763) acc@5 1.0000 (0.9962)
[32m[2022-06-11 09:55:10] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2773 (0.3548) acc@1 0.8828 (0.8771) acc@5 1.0000 (0.9961)
[32m[2022-06-11 09:55:13] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3538 (0.3564) acc@1 0.8906 (0.8764) acc@5 1.0000 (0.9960)
[32m[2022-06-11 09:55:13] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 09:55:13] __main__ INFO: [0mVal 6
[32m[2022-06-11 09:55:14] __main__ INFO: [0mEpoch 6 loss 0.5229 acc@1 0.8319 acc@5 0.9906
[32m[2022-06-11 09:55:14] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:55:14] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 09:55:18] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4397 (0.3269) acc@1 0.8516 (0.8870) acc@5 0.9922 (0.9964)
[32m[2022-06-11 09:55:22] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2563 (0.3368) acc@1 0.9297 (0.8845) acc@5 0.9922 (0.9961)
[32m[2022-06-11 09:55:26] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3956 (0.3374) acc@1 0.8750 (0.8837) acc@5 0.9922 (0.9963)
[32m[2022-06-11 09:55:30] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2600 (0.3372) acc@1 0.9141 (0.8831) acc@5 0.9922 (0.9964)
[32m[2022-06-11 09:55:30] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 09:55:30] __main__ INFO: [0mVal 7
[32m[2022-06-11 09:55:31] __main__ INFO: [0mEpoch 7 loss 0.6200 acc@1 0.8104 acc@5 0.9874
[32m[2022-06-11 09:55:31] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:55:31] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 09:55:35] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4133 (0.3188) acc@1 0.8359 (0.8893) acc@5 0.9844 (0.9966)
[32m[2022-06-11 09:55:39] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3322 (0.3282) acc@1 0.8750 (0.8873) acc@5 1.0000 (0.9964)
[32m[2022-06-11 09:55:43] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3693 (0.3287) acc@1 0.8828 (0.8868) acc@5 0.9922 (0.9963)
[32m[2022-06-11 09:55:46] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3040 (0.3263) acc@1 0.9375 (0.8875) acc@5 0.9922 (0.9965)
[32m[2022-06-11 09:55:46] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 09:55:46] __main__ INFO: [0mVal 8
[32m[2022-06-11 09:55:47] __main__ INFO: [0mEpoch 8 loss 0.4959 acc@1 0.8433 acc@5 0.9915
[32m[2022-06-11 09:55:47] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:55:47] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 09:55:51] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3766 (0.2999) acc@1 0.8828 (0.8962) acc@5 0.9844 (0.9974)
[32m[2022-06-11 09:55:56] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2971 (0.3073) acc@1 0.9219 (0.8925) acc@5 1.0000 (0.9973)
[32m[2022-06-11 09:55:59] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4753 (0.3109) acc@1 0.8438 (0.8920) acc@5 1.0000 (0.9970)
[32m[2022-06-11 09:56:03] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2710 (0.3105) acc@1 0.8984 (0.8926) acc@5 1.0000 (0.9968)
[32m[2022-06-11 09:56:03] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 09:56:03] __main__ INFO: [0mVal 9
[32m[2022-06-11 09:56:04] __main__ INFO: [0mEpoch 9 loss 0.4733 acc@1 0.8490 acc@5 0.9934
[32m[2022-06-11 09:56:04] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:56:04] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 09:56:08] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3147 (0.2934) acc@1 0.8984 (0.8985) acc@5 0.9844 (0.9973)
[32m[2022-06-11 09:56:12] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3431 (0.2985) acc@1 0.9062 (0.8978) acc@5 0.9922 (0.9970)
[32m[2022-06-11 09:56:16] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2463 (0.2971) acc@1 0.9219 (0.8973) acc@5 1.0000 (0.9971)
[32m[2022-06-11 09:56:19] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2263 (0.3026) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9969)
[32m[2022-06-11 09:56:20] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 09:56:20] __main__ INFO: [0mVal 10
[32m[2022-06-11 09:56:20] __main__ INFO: [0mEpoch 10 loss 0.5039 acc@1 0.8431 acc@5 0.9935
[32m[2022-06-11 09:56:20] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:56:20] __main__ INFO: [0mTrain 11 3900
[32m[2022-06-11 09:56:25] __main__ INFO: [0mEpoch 11 Step 100/390 lr 0.100000 loss 0.3778 (0.2642) acc@1 0.8359 (0.9076) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:56:29] __main__ INFO: [0mEpoch 11 Step 200/390 lr 0.100000 loss 0.3571 (0.2753) acc@1 0.8984 (0.9041) acc@5 0.9922 (0.9979)
[32m[2022-06-11 09:56:33] __main__ INFO: [0mEpoch 11 Step 300/390 lr 0.100000 loss 0.2886 (0.2799) acc@1 0.8984 (0.9030) acc@5 1.0000 (0.9976)
[32m[2022-06-11 09:56:36] __main__ INFO: [0mEpoch 11 Step 390/390 lr 0.100000 loss 0.4592 (0.2862) acc@1 0.8281 (0.9007) acc@5 1.0000 (0.9974)
[32m[2022-06-11 09:56:36] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 09:56:36] __main__ INFO: [0mVal 11
[32m[2022-06-11 09:56:37] __main__ INFO: [0mEpoch 11 loss 0.4441 acc@1 0.8593 acc@5 0.9932
[32m[2022-06-11 09:56:37] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:56:37] __main__ INFO: [0mTrain 12 4290
[32m[2022-06-11 09:56:41] __main__ INFO: [0mEpoch 12 Step 100/390 lr 0.100000 loss 0.2452 (0.2715) acc@1 0.9219 (0.9035) acc@5 1.0000 (0.9972)
[32m[2022-06-11 09:56:45] __main__ INFO: [0mEpoch 12 Step 200/390 lr 0.100000 loss 0.3847 (0.2758) acc@1 0.8750 (0.9046) acc@5 1.0000 (0.9969)
[32m[2022-06-11 09:56:49] __main__ INFO: [0mEpoch 12 Step 300/390 lr 0.100000 loss 0.2670 (0.2776) acc@1 0.8984 (0.9045) acc@5 0.9922 (0.9969)
[32m[2022-06-11 09:56:53] __main__ INFO: [0mEpoch 12 Step 390/390 lr 0.100000 loss 0.2926 (0.2829) acc@1 0.9141 (0.9030) acc@5 1.0000 (0.9968)
[32m[2022-06-11 09:56:53] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 09:56:53] __main__ INFO: [0mVal 12
[32m[2022-06-11 09:56:54] __main__ INFO: [0mEpoch 12 loss 0.4671 acc@1 0.8482 acc@5 0.9934
[32m[2022-06-11 09:56:54] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 09:56:54] __main__ INFO: [0mTrain 13 4680
[32m[2022-06-11 09:56:58] __main__ INFO: [0mEpoch 13 Step 100/390 lr 0.100000 loss 0.2534 (0.2630) acc@1 0.9062 (0.9101) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:02] __main__ INFO: [0mEpoch 13 Step 200/390 lr 0.100000 loss 0.3493 (0.2658) acc@1 0.8906 (0.9078) acc@5 0.9922 (0.9978)
[32m[2022-06-11 09:57:06] __main__ INFO: [0mEpoch 13 Step 300/390 lr 0.100000 loss 0.2027 (0.2701) acc@1 0.9297 (0.9066) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:10] __main__ INFO: [0mEpoch 13 Step 390/390 lr 0.100000 loss 0.3353 (0.2731) acc@1 0.8672 (0.9056) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:10] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 09:57:10] __main__ INFO: [0mVal 13
[32m[2022-06-11 09:57:11] __main__ INFO: [0mEpoch 13 loss 0.4527 acc@1 0.8561 acc@5 0.9943
[32m[2022-06-11 09:57:11] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:57:11] __main__ INFO: [0mTrain 14 5070
[32m[2022-06-11 09:57:15] __main__ INFO: [0mEpoch 14 Step 100/390 lr 0.100000 loss 0.1080 (0.2505) acc@1 0.9688 (0.9129) acc@5 1.0000 (0.9976)
[32m[2022-06-11 09:57:19] __main__ INFO: [0mEpoch 14 Step 200/390 lr 0.100000 loss 0.2212 (0.2575) acc@1 0.9297 (0.9107) acc@5 0.9922 (0.9977)
[32m[2022-06-11 09:57:23] __main__ INFO: [0mEpoch 14 Step 300/390 lr 0.100000 loss 0.1798 (0.2613) acc@1 0.9453 (0.9097) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:26] __main__ INFO: [0mEpoch 14 Step 390/390 lr 0.100000 loss 0.3119 (0.2643) acc@1 0.8906 (0.9083) acc@5 0.9922 (0.9975)
[32m[2022-06-11 09:57:26] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 09:57:26] __main__ INFO: [0mVal 14
[32m[2022-06-11 09:57:27] __main__ INFO: [0mEpoch 14 loss 0.4985 acc@1 0.8424 acc@5 0.9919
[32m[2022-06-11 09:57:27] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:57:27] __main__ INFO: [0mTrain 15 5460
[32m[2022-06-11 09:57:31] __main__ INFO: [0mEpoch 15 Step 100/390 lr 0.100000 loss 0.2765 (0.2426) acc@1 0.9297 (0.9161) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:57:35] __main__ INFO: [0mEpoch 15 Step 200/390 lr 0.100000 loss 0.2194 (0.2493) acc@1 0.9219 (0.9147) acc@5 1.0000 (0.9981)
[32m[2022-06-11 09:57:39] __main__ INFO: [0mEpoch 15 Step 300/390 lr 0.100000 loss 0.2947 (0.2537) acc@1 0.9141 (0.9124) acc@5 0.9922 (0.9979)
[32m[2022-06-11 09:57:43] __main__ INFO: [0mEpoch 15 Step 390/390 lr 0.100000 loss 0.2358 (0.2571) acc@1 0.9062 (0.9114) acc@5 1.0000 (0.9980)
[32m[2022-06-11 09:57:43] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 09:57:43] __main__ INFO: [0mVal 15
[32m[2022-06-11 09:57:44] __main__ INFO: [0mEpoch 15 loss 0.4242 acc@1 0.8656 acc@5 0.9938
[32m[2022-06-11 09:57:44] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:57:44] __main__ INFO: [0mTrain 16 5850
[32m[2022-06-11 09:57:48] __main__ INFO: [0mEpoch 16 Step 100/390 lr 0.100000 loss 0.2836 (0.2382) acc@1 0.9062 (0.9158) acc@5 0.9922 (0.9978)
[32m[2022-06-11 09:57:52] __main__ INFO: [0mEpoch 16 Step 200/390 lr 0.100000 loss 0.2538 (0.2501) acc@1 0.8984 (0.9114) acc@5 0.9922 (0.9976)
[32m[2022-06-11 09:57:56] __main__ INFO: [0mEpoch 16 Step 300/390 lr 0.100000 loss 0.1840 (0.2512) acc@1 0.9297 (0.9117) acc@5 1.0000 (0.9978)
[32m[2022-06-11 09:57:59] __main__ INFO: [0mEpoch 16 Step 390/390 lr 0.100000 loss 0.2013 (0.2529) acc@1 0.9297 (0.9113) acc@5 1.0000 (0.9978)
[32m[2022-06-11 09:58:00] __main__ INFO: [0mElapsed 15.56
[32m[2022-06-11 09:58:00] __main__ INFO: [0mVal 16
[32m[2022-06-11 09:58:01] __main__ INFO: [0mEpoch 16 loss 0.5293 acc@1 0.8414 acc@5 0.9895
[32m[2022-06-11 09:58:01] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:58:01] __main__ INFO: [0mTrain 17 6240
[32m[2022-06-11 09:58:05] __main__ INFO: [0mEpoch 17 Step 100/390 lr 0.100000 loss 0.3087 (0.2463) acc@1 0.9141 (0.9148) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:58:09] __main__ INFO: [0mEpoch 17 Step 200/390 lr 0.100000 loss 0.3197 (0.2479) acc@1 0.8984 (0.9148) acc@5 0.9922 (0.9980)
[32m[2022-06-11 09:58:13] __main__ INFO: [0mEpoch 17 Step 300/390 lr 0.100000 loss 0.5097 (0.2531) acc@1 0.8125 (0.9122) acc@5 1.0000 (0.9981)
[32m[2022-06-11 09:58:16] __main__ INFO: [0mEpoch 17 Step 390/390 lr 0.100000 loss 0.1541 (0.2525) acc@1 0.9609 (0.9124) acc@5 0.9922 (0.9981)
[32m[2022-06-11 09:58:16] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 09:58:16] __main__ INFO: [0mVal 17
[32m[2022-06-11 09:58:17] __main__ INFO: [0mEpoch 17 loss 0.4396 acc@1 0.8584 acc@5 0.9936
[32m[2022-06-11 09:58:17] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:58:17] __main__ INFO: [0mTrain 18 6630
[32m[2022-06-11 09:58:21] __main__ INFO: [0mEpoch 18 Step 100/390 lr 0.100000 loss 0.3825 (0.2298) acc@1 0.8828 (0.9193) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:58:25] __main__ INFO: [0mEpoch 18 Step 200/390 lr 0.100000 loss 0.3288 (0.2344) acc@1 0.8984 (0.9167) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:58:29] __main__ INFO: [0mEpoch 18 Step 300/390 lr 0.100000 loss 0.2586 (0.2370) acc@1 0.8906 (0.9166) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:58:33] __main__ INFO: [0mEpoch 18 Step 390/390 lr 0.100000 loss 0.2421 (0.2443) acc@1 0.9453 (0.9141) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:58:33] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:58:33] __main__ INFO: [0mVal 18
[32m[2022-06-11 09:58:34] __main__ INFO: [0mEpoch 18 loss 0.4365 acc@1 0.8644 acc@5 0.9945
[32m[2022-06-11 09:58:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 09:58:34] __main__ INFO: [0mTrain 19 7020
[32m[2022-06-11 09:58:38] __main__ INFO: [0mEpoch 19 Step 100/390 lr 0.100000 loss 0.1901 (0.2104) acc@1 0.9141 (0.9274) acc@5 1.0000 (0.9987)
[32m[2022-06-11 09:58:42] __main__ INFO: [0mEpoch 19 Step 200/390 lr 0.100000 loss 0.3619 (0.2215) acc@1 0.8750 (0.9235) acc@5 0.9922 (0.9985)
[32m[2022-06-11 09:58:46] __main__ INFO: [0mEpoch 19 Step 300/390 lr 0.100000 loss 0.2559 (0.2276) acc@1 0.9219 (0.9206) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:58:49] __main__ INFO: [0mEpoch 19 Step 390/390 lr 0.100000 loss 0.3109 (0.2328) acc@1 0.8750 (0.9185) acc@5 0.9922 (0.9982)
[32m[2022-06-11 09:58:49] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 09:58:49] __main__ INFO: [0mVal 19
[32m[2022-06-11 09:58:50] __main__ INFO: [0mEpoch 19 loss 0.3774 acc@1 0.8784 acc@5 0.9946
[32m[2022-06-11 09:58:50] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:58:50] __main__ INFO: [0mTrain 20 7410
[32m[2022-06-11 09:58:55] __main__ INFO: [0mEpoch 20 Step 100/390 lr 0.100000 loss 0.2223 (0.2269) acc@1 0.9297 (0.9200) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:58:59] __main__ INFO: [0mEpoch 20 Step 200/390 lr 0.100000 loss 0.2705 (0.2316) acc@1 0.9062 (0.9187) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:59:03] __main__ INFO: [0mEpoch 20 Step 300/390 lr 0.100000 loss 0.1986 (0.2356) acc@1 0.9375 (0.9174) acc@5 0.9922 (0.9982)
[32m[2022-06-11 09:59:07] __main__ INFO: [0mEpoch 20 Step 390/390 lr 0.100000 loss 0.1408 (0.2381) acc@1 0.9531 (0.9170) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:59:07] __main__ INFO: [0mElapsed 16.32
[32m[2022-06-11 09:59:07] __main__ INFO: [0mVal 20
[32m[2022-06-11 09:59:08] __main__ INFO: [0mEpoch 20 loss 0.4564 acc@1 0.8569 acc@5 0.9947
[32m[2022-06-11 09:59:08] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 09:59:08] __main__ INFO: [0mTrain 21 7800
[32m[2022-06-11 09:59:12] __main__ INFO: [0mEpoch 21 Step 100/390 lr 0.100000 loss 0.1707 (0.2163) acc@1 0.9531 (0.9220) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:59:16] __main__ INFO: [0mEpoch 21 Step 200/390 lr 0.100000 loss 0.1988 (0.2241) acc@1 0.9219 (0.9199) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:20] __main__ INFO: [0mEpoch 21 Step 300/390 lr 0.100000 loss 0.3306 (0.2283) acc@1 0.9062 (0.9183) acc@5 0.9844 (0.9985)
[32m[2022-06-11 09:59:23] __main__ INFO: [0mEpoch 21 Step 390/390 lr 0.100000 loss 0.3509 (0.2326) acc@1 0.8672 (0.9174) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:59:23] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:59:23] __main__ INFO: [0mVal 21
[32m[2022-06-11 09:59:24] __main__ INFO: [0mEpoch 21 loss 0.4912 acc@1 0.8528 acc@5 0.9932
[32m[2022-06-11 09:59:24] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 09:59:24] __main__ INFO: [0mTrain 22 8190
[32m[2022-06-11 09:59:28] __main__ INFO: [0mEpoch 22 Step 100/390 lr 0.100000 loss 0.2923 (0.2092) acc@1 0.9062 (0.9288) acc@5 1.0000 (0.9988)
[32m[2022-06-11 09:59:32] __main__ INFO: [0mEpoch 22 Step 200/390 lr 0.100000 loss 0.2052 (0.2269) acc@1 0.9062 (0.9220) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:36] __main__ INFO: [0mEpoch 22 Step 300/390 lr 0.100000 loss 0.1581 (0.2299) acc@1 0.9297 (0.9211) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:40] __main__ INFO: [0mEpoch 22 Step 390/390 lr 0.100000 loss 0.3109 (0.2303) acc@1 0.9297 (0.9210) acc@5 0.9922 (0.9985)
[32m[2022-06-11 09:59:40] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:59:40] __main__ INFO: [0mVal 22
[32m[2022-06-11 09:59:41] __main__ INFO: [0mEpoch 22 loss 0.3968 acc@1 0.8791 acc@5 0.9952
[32m[2022-06-11 09:59:41] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:59:41] __main__ INFO: [0mTrain 23 8580
[32m[2022-06-11 09:59:45] __main__ INFO: [0mEpoch 23 Step 100/390 lr 0.100000 loss 0.2176 (0.2012) acc@1 0.9219 (0.9317) acc@5 1.0000 (0.9988)
[32m[2022-06-11 09:59:49] __main__ INFO: [0mEpoch 23 Step 200/390 lr 0.100000 loss 0.2428 (0.2105) acc@1 0.9219 (0.9268) acc@5 0.9922 (0.9986)
[32m[2022-06-11 09:59:53] __main__ INFO: [0mEpoch 23 Step 300/390 lr 0.100000 loss 0.3369 (0.2157) acc@1 0.8906 (0.9245) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:59:56] __main__ INFO: [0mEpoch 23 Step 390/390 lr 0.100000 loss 0.1396 (0.2228) acc@1 0.9219 (0.9221) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:56] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 09:59:56] __main__ INFO: [0mVal 23
[32m[2022-06-11 09:59:57] __main__ INFO: [0mEpoch 23 loss 0.4814 acc@1 0.8582 acc@5 0.9936
[32m[2022-06-11 09:59:57] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:59:57] __main__ INFO: [0mTrain 24 8970
[32m[2022-06-11 10:00:01] __main__ INFO: [0mEpoch 24 Step 100/390 lr 0.100000 loss 0.2640 (0.2123) acc@1 0.9219 (0.9257) acc@5 0.9922 (0.9984)
[32m[2022-06-11 10:00:05] __main__ INFO: [0mEpoch 24 Step 200/390 lr 0.100000 loss 0.2256 (0.2186) acc@1 0.8984 (0.9221) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:09] __main__ INFO: [0mEpoch 24 Step 300/390 lr 0.100000 loss 0.2190 (0.2230) acc@1 0.9219 (0.9201) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:13] __main__ INFO: [0mEpoch 24 Step 390/390 lr 0.100000 loss 0.2595 (0.2266) acc@1 0.9141 (0.9193) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:13] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:00:13] __main__ INFO: [0mVal 24
[32m[2022-06-11 10:00:14] __main__ INFO: [0mEpoch 24 loss 0.4320 acc@1 0.8675 acc@5 0.9939
[32m[2022-06-11 10:00:14] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:00:14] __main__ INFO: [0mTrain 25 9360
[32m[2022-06-11 10:00:18] __main__ INFO: [0mEpoch 25 Step 100/390 lr 0.100000 loss 0.1483 (0.2158) acc@1 0.9609 (0.9260) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:22] __main__ INFO: [0mEpoch 25 Step 200/390 lr 0.100000 loss 0.2036 (0.2200) acc@1 0.9375 (0.9241) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:26] __main__ INFO: [0mEpoch 25 Step 300/390 lr 0.100000 loss 0.2547 (0.2236) acc@1 0.8828 (0.9220) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:29] __main__ INFO: [0mEpoch 25 Step 390/390 lr 0.100000 loss 0.2811 (0.2238) acc@1 0.9062 (0.9218) acc@5 0.9922 (0.9984)
[32m[2022-06-11 10:00:29] __main__ INFO: [0mElapsed 15.53
[32m[2022-06-11 10:00:29] __main__ INFO: [0mVal 25
[32m[2022-06-11 10:00:30] __main__ INFO: [0mEpoch 25 loss 0.4351 acc@1 0.8652 acc@5 0.9954
[32m[2022-06-11 10:00:30] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:00:30] __main__ INFO: [0mTrain 26 9750
[32m[2022-06-11 10:00:34] __main__ INFO: [0mEpoch 26 Step 100/390 lr 0.100000 loss 0.2207 (0.1958) acc@1 0.9297 (0.9322) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:00:38] __main__ INFO: [0mEpoch 26 Step 200/390 lr 0.100000 loss 0.2122 (0.2074) acc@1 0.9375 (0.9270) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:00:42] __main__ INFO: [0mEpoch 26 Step 300/390 lr 0.100000 loss 0.2799 (0.2132) acc@1 0.9453 (0.9246) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:46] __main__ INFO: [0mEpoch 26 Step 390/390 lr 0.100000 loss 0.1616 (0.2157) acc@1 0.9297 (0.9238) acc@5 1.0000 (0.9985)
[32m[2022-06-11 10:00:46] __main__ INFO: [0mElapsed 15.56
[32m[2022-06-11 10:00:46] __main__ INFO: [0mVal 26
[32m[2022-06-11 10:00:47] __main__ INFO: [0mEpoch 26 loss 0.4064 acc@1 0.8751 acc@5 0.9946
[32m[2022-06-11 10:00:47] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:00:47] __main__ INFO: [0mTrain 27 10140
[32m[2022-06-11 10:00:51] __main__ INFO: [0mEpoch 27 Step 100/390 lr 0.100000 loss 0.2962 (0.1829) acc@1 0.9062 (0.9359) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:00:55] __main__ INFO: [0mEpoch 27 Step 200/390 lr 0.100000 loss 0.2471 (0.1973) acc@1 0.9062 (0.9318) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:00:59] __main__ INFO: [0mEpoch 27 Step 300/390 lr 0.100000 loss 0.2016 (0.2016) acc@1 0.9375 (0.9293) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:01:02] __main__ INFO: [0mEpoch 27 Step 390/390 lr 0.100000 loss 0.2381 (0.2080) acc@1 0.8984 (0.9275) acc@5 1.0000 (0.9987)
[32m[2022-06-11 10:01:02] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 10:01:02] __main__ INFO: [0mVal 27
[32m[2022-06-11 10:01:03] __main__ INFO: [0mEpoch 27 loss 0.4610 acc@1 0.8660 acc@5 0.9921
[32m[2022-06-11 10:01:03] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:01:03] __main__ INFO: [0mTrain 28 10530
[32m[2022-06-11 10:01:07] __main__ INFO: [0mEpoch 28 Step 100/390 lr 0.100000 loss 0.1918 (0.2094) acc@1 0.9609 (0.9268) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:01:11] __main__ INFO: [0mEpoch 28 Step 200/390 lr 0.100000 loss 0.3197 (0.2079) acc@1 0.8750 (0.9261) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:15] __main__ INFO: [0mEpoch 28 Step 300/390 lr 0.100000 loss 0.2019 (0.2101) acc@1 0.9219 (0.9263) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:01:19] __main__ INFO: [0mEpoch 28 Step 390/390 lr 0.100000 loss 0.1922 (0.2099) acc@1 0.9141 (0.9263) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:01:19] __main__ INFO: [0mElapsed 15.55
[32m[2022-06-11 10:01:19] __main__ INFO: [0mVal 28
[32m[2022-06-11 10:01:20] __main__ INFO: [0mEpoch 28 loss 0.4958 acc@1 0.8564 acc@5 0.9928
[32m[2022-06-11 10:01:20] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:01:20] __main__ INFO: [0mTrain 29 10920
[32m[2022-06-11 10:01:24] __main__ INFO: [0mEpoch 29 Step 100/390 lr 0.100000 loss 0.2178 (0.1924) acc@1 0.9219 (0.9321) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:01:28] __main__ INFO: [0mEpoch 29 Step 200/390 lr 0.100000 loss 0.2210 (0.2002) acc@1 0.9297 (0.9295) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:32] __main__ INFO: [0mEpoch 29 Step 300/390 lr 0.100000 loss 0.3052 (0.2045) acc@1 0.9141 (0.9283) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:01:35] __main__ INFO: [0mEpoch 29 Step 390/390 lr 0.100000 loss 0.2727 (0.2092) acc@1 0.9297 (0.9270) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:35] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:01:35] __main__ INFO: [0mVal 29
[32m[2022-06-11 10:01:36] __main__ INFO: [0mEpoch 29 loss 0.5581 acc@1 0.8409 acc@5 0.9924
[32m[2022-06-11 10:01:36] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:01:36] __main__ INFO: [0mTrain 30 11310
[32m[2022-06-11 10:01:41] __main__ INFO: [0mEpoch 30 Step 100/390 lr 0.100000 loss 0.1827 (0.1978) acc@1 0.9375 (0.9315) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:01:44] __main__ INFO: [0mEpoch 30 Step 200/390 lr 0.100000 loss 0.1548 (0.2004) acc@1 0.9375 (0.9299) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:48] __main__ INFO: [0mEpoch 30 Step 300/390 lr 0.100000 loss 0.1607 (0.2051) acc@1 0.9297 (0.9287) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:52] __main__ INFO: [0mEpoch 30 Step 390/390 lr 0.100000 loss 0.2667 (0.2067) acc@1 0.8984 (0.9277) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:52] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:01:52] __main__ INFO: [0mVal 30
[32m[2022-06-11 10:01:53] __main__ INFO: [0mEpoch 30 loss 0.4164 acc@1 0.8700 acc@5 0.9945
[32m[2022-06-11 10:01:53] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:01:53] __main__ INFO: [0mTrain 31 11700
[32m[2022-06-11 10:01:57] __main__ INFO: [0mEpoch 31 Step 100/390 lr 0.100000 loss 0.2197 (0.1952) acc@1 0.9375 (0.9316) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:02:01] __main__ INFO: [0mEpoch 31 Step 200/390 lr 0.100000 loss 0.1855 (0.2028) acc@1 0.9297 (0.9300) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:05] __main__ INFO: [0mEpoch 31 Step 300/390 lr 0.100000 loss 0.2148 (0.2064) acc@1 0.9062 (0.9276) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:09] __main__ INFO: [0mEpoch 31 Step 390/390 lr 0.100000 loss 0.1806 (0.2105) acc@1 0.9219 (0.9262) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:02:09] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 10:02:09] __main__ INFO: [0mVal 31
[32m[2022-06-11 10:02:10] __main__ INFO: [0mEpoch 31 loss 0.3997 acc@1 0.8771 acc@5 0.9951
[32m[2022-06-11 10:02:10] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:02:10] __main__ INFO: [0mTrain 32 12090
[32m[2022-06-11 10:02:14] __main__ INFO: [0mEpoch 32 Step 100/390 lr 0.100000 loss 0.1306 (0.1904) acc@1 0.9531 (0.9348) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:18] __main__ INFO: [0mEpoch 32 Step 200/390 lr 0.100000 loss 0.1924 (0.1948) acc@1 0.9219 (0.9333) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:02:22] __main__ INFO: [0mEpoch 32 Step 300/390 lr 0.100000 loss 0.2958 (0.1998) acc@1 0.9297 (0.9305) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:26] __main__ INFO: [0mEpoch 32 Step 390/390 lr 0.100000 loss 0.1743 (0.2026) acc@1 0.9219 (0.9288) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:02:26] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 10:02:26] __main__ INFO: [0mVal 32
[32m[2022-06-11 10:02:27] __main__ INFO: [0mEpoch 32 loss 0.4223 acc@1 0.8786 acc@5 0.9954
[32m[2022-06-11 10:02:27] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:02:27] __main__ INFO: [0mTrain 33 12480
[32m[2022-06-11 10:02:31] __main__ INFO: [0mEpoch 33 Step 100/390 lr 0.100000 loss 0.1936 (0.1829) acc@1 0.9297 (0.9362) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:35] __main__ INFO: [0mEpoch 33 Step 200/390 lr 0.100000 loss 0.3342 (0.1909) acc@1 0.8984 (0.9341) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:02:39] __main__ INFO: [0mEpoch 33 Step 300/390 lr 0.100000 loss 0.1701 (0.1961) acc@1 0.9375 (0.9311) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:42] __main__ INFO: [0mEpoch 33 Step 390/390 lr 0.100000 loss 0.2334 (0.2034) acc@1 0.9219 (0.9284) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:42] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:02:42] __main__ INFO: [0mVal 33
[32m[2022-06-11 10:02:43] __main__ INFO: [0mEpoch 33 loss 0.4228 acc@1 0.8734 acc@5 0.9954
[32m[2022-06-11 10:02:43] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:02:43] __main__ INFO: [0mTrain 34 12870
[32m[2022-06-11 10:02:47] __main__ INFO: [0mEpoch 34 Step 100/390 lr 0.100000 loss 0.1577 (0.1904) acc@1 0.9375 (0.9362) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:51] __main__ INFO: [0mEpoch 34 Step 200/390 lr 0.100000 loss 0.3170 (0.1905) acc@1 0.8672 (0.9330) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:02:55] __main__ INFO: [0mEpoch 34 Step 300/390 lr 0.100000 loss 0.1309 (0.1966) acc@1 0.9453 (0.9306) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:59] __main__ INFO: [0mEpoch 34 Step 390/390 lr 0.100000 loss 0.2791 (0.2001) acc@1 0.8906 (0.9289) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:59] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:02:59] __main__ INFO: [0mVal 34
[32m[2022-06-11 10:03:00] __main__ INFO: [0mEpoch 34 loss 0.4272 acc@1 0.8689 acc@5 0.9940
[32m[2022-06-11 10:03:00] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:03:00] __main__ INFO: [0mTrain 35 13260
[32m[2022-06-11 10:03:04] __main__ INFO: [0mEpoch 35 Step 100/390 lr 0.100000 loss 0.2388 (0.1837) acc@1 0.9141 (0.9379) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:03:08] __main__ INFO: [0mEpoch 35 Step 200/390 lr 0.100000 loss 0.2387 (0.1900) acc@1 0.9062 (0.9340) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:12] __main__ INFO: [0mEpoch 35 Step 300/390 lr 0.100000 loss 0.2687 (0.1965) acc@1 0.9453 (0.9315) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:03:16] __main__ INFO: [0mEpoch 35 Step 390/390 lr 0.100000 loss 0.2031 (0.2003) acc@1 0.9141 (0.9301) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:03:16] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 10:03:16] __main__ INFO: [0mVal 35
[32m[2022-06-11 10:03:17] __main__ INFO: [0mEpoch 35 loss 0.4054 acc@1 0.8770 acc@5 0.9956
[32m[2022-06-11 10:03:17] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:03:17] __main__ INFO: [0mTrain 36 13650
[32m[2022-06-11 10:03:21] __main__ INFO: [0mEpoch 36 Step 100/390 lr 0.100000 loss 0.0925 (0.1793) acc@1 0.9531 (0.9370) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:25] __main__ INFO: [0mEpoch 36 Step 200/390 lr 0.100000 loss 0.1553 (0.1852) acc@1 0.9297 (0.9345) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:29] __main__ INFO: [0mEpoch 36 Step 300/390 lr 0.100000 loss 0.2535 (0.1913) acc@1 0.9062 (0.9318) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:03:32] __main__ INFO: [0mEpoch 36 Step 390/390 lr 0.100000 loss 0.2743 (0.1955) acc@1 0.8984 (0.9311) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:03:32] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:03:32] __main__ INFO: [0mVal 36
[32m[2022-06-11 10:03:33] __main__ INFO: [0mEpoch 36 loss 0.3772 acc@1 0.8797 acc@5 0.9959
[32m[2022-06-11 10:03:33] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:03:33] __main__ INFO: [0mTrain 37 14040
[32m[2022-06-11 10:03:37] __main__ INFO: [0mEpoch 37 Step 100/390 lr 0.100000 loss 0.1979 (0.1819) acc@1 0.9141 (0.9353) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:03:41] __main__ INFO: [0mEpoch 37 Step 200/390 lr 0.100000 loss 0.1855 (0.1884) acc@1 0.9297 (0.9330) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:45] __main__ INFO: [0mEpoch 37 Step 300/390 lr 0.100000 loss 0.2755 (0.1912) acc@1 0.9219 (0.9326) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:49] __main__ INFO: [0mEpoch 37 Step 390/390 lr 0.100000 loss 0.0967 (0.1929) acc@1 0.9844 (0.9319) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:49] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 10:03:49] __main__ INFO: [0mVal 37
[32m[2022-06-11 10:03:50] __main__ INFO: [0mEpoch 37 loss 0.4156 acc@1 0.8763 acc@5 0.9949
[32m[2022-06-11 10:03:50] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:03:50] __main__ INFO: [0mTrain 38 14430
[32m[2022-06-11 10:03:54] __main__ INFO: [0mEpoch 38 Step 100/390 lr 0.100000 loss 0.1796 (0.1760) acc@1 0.9297 (0.9382) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:03:59] __main__ INFO: [0mEpoch 38 Step 200/390 lr 0.100000 loss 0.1583 (0.1833) acc@1 0.9453 (0.9358) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:04:03] __main__ INFO: [0mEpoch 38 Step 300/390 lr 0.100000 loss 0.2516 (0.1901) acc@1 0.9297 (0.9332) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:04:06] __main__ INFO: [0mEpoch 38 Step 390/390 lr 0.100000 loss 0.1651 (0.1965) acc@1 0.9453 (0.9308) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:06] __main__ INFO: [0mElapsed 16.26
[32m[2022-06-11 10:04:06] __main__ INFO: [0mVal 38
[32m[2022-06-11 10:04:07] __main__ INFO: [0mEpoch 38 loss 0.4688 acc@1 0.8599 acc@5 0.9940
[32m[2022-06-11 10:04:07] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:04:07] __main__ INFO: [0mTrain 39 14820
[32m[2022-06-11 10:04:12] __main__ INFO: [0mEpoch 39 Step 100/390 lr 0.100000 loss 0.1424 (0.1797) acc@1 0.9453 (0.9363) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:16] __main__ INFO: [0mEpoch 39 Step 200/390 lr 0.100000 loss 0.3179 (0.1899) acc@1 0.8594 (0.9323) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:04:20] __main__ INFO: [0mEpoch 39 Step 300/390 lr 0.100000 loss 0.1436 (0.1925) acc@1 0.9375 (0.9316) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:04:23] __main__ INFO: [0mEpoch 39 Step 390/390 lr 0.100000 loss 0.2037 (0.1955) acc@1 0.9453 (0.9310) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:04:23] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:04:23] __main__ INFO: [0mVal 39
[32m[2022-06-11 10:04:24] __main__ INFO: [0mEpoch 39 loss 0.4232 acc@1 0.8701 acc@5 0.9951
[32m[2022-06-11 10:04:24] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:04:24] __main__ INFO: [0mTrain 40 15210
[32m[2022-06-11 10:04:28] __main__ INFO: [0mEpoch 40 Step 100/390 lr 0.100000 loss 0.2878 (0.1744) acc@1 0.8984 (0.9397) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:04:32] __main__ INFO: [0mEpoch 40 Step 200/390 lr 0.100000 loss 0.2188 (0.1856) acc@1 0.9297 (0.9358) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:36] __main__ INFO: [0mEpoch 40 Step 300/390 lr 0.100000 loss 0.1971 (0.1897) acc@1 0.9375 (0.9339) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:04:40] __main__ INFO: [0mEpoch 40 Step 390/390 lr 0.100000 loss 0.2149 (0.1933) acc@1 0.9297 (0.9326) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:40] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:04:40] __main__ INFO: [0mVal 40
[32m[2022-06-11 10:04:41] __main__ INFO: [0mEpoch 40 loss 0.3929 acc@1 0.8760 acc@5 0.9955
[32m[2022-06-11 10:04:41] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:04:41] __main__ INFO: [0mTrain 41 15600
[32m[2022-06-11 10:04:45] __main__ INFO: [0mEpoch 41 Step 100/390 lr 0.100000 loss 0.1115 (0.1816) acc@1 0.9766 (0.9355) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:04:49] __main__ INFO: [0mEpoch 41 Step 200/390 lr 0.100000 loss 0.1483 (0.1864) acc@1 0.9453 (0.9334) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:53] __main__ INFO: [0mEpoch 41 Step 300/390 lr 0.100000 loss 0.2876 (0.1903) acc@1 0.8672 (0.9323) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:57] __main__ INFO: [0mEpoch 41 Step 390/390 lr 0.100000 loss 0.3327 (0.1921) acc@1 0.9219 (0.9317) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:04:57] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:04:57] __main__ INFO: [0mVal 41
[32m[2022-06-11 10:04:58] __main__ INFO: [0mEpoch 41 loss 0.4218 acc@1 0.8714 acc@5 0.9947
[32m[2022-06-11 10:04:58] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:04:58] __main__ INFO: [0mTrain 42 15990
[32m[2022-06-11 10:05:02] __main__ INFO: [0mEpoch 42 Step 100/390 lr 0.100000 loss 0.3850 (0.1839) acc@1 0.8359 (0.9380) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:05:06] __main__ INFO: [0mEpoch 42 Step 200/390 lr 0.100000 loss 0.1581 (0.1765) acc@1 0.9453 (0.9396) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:05:10] __main__ INFO: [0mEpoch 42 Step 300/390 lr 0.100000 loss 0.2368 (0.1817) acc@1 0.9297 (0.9372) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:05:13] __main__ INFO: [0mEpoch 42 Step 390/390 lr 0.100000 loss 0.2493 (0.1878) acc@1 0.9219 (0.9345) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:05:13] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 10:05:13] __main__ INFO: [0mVal 42
[32m[2022-06-11 10:05:14] __main__ INFO: [0mEpoch 42 loss 0.4103 acc@1 0.8779 acc@5 0.9953
[32m[2022-06-11 10:05:14] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:05:14] __main__ INFO: [0mTrain 43 16380
[32m[2022-06-11 10:05:19] __main__ INFO: [0mEpoch 43 Step 100/390 lr 0.100000 loss 0.2776 (0.1786) acc@1 0.9297 (0.9345) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:05:23] __main__ INFO: [0mEpoch 43 Step 200/390 lr 0.100000 loss 0.2200 (0.1868) acc@1 0.9297 (0.9334) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:26] __main__ INFO: [0mEpoch 43 Step 300/390 lr 0.100000 loss 0.2154 (0.1880) acc@1 0.9062 (0.9334) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:05:30] __main__ INFO: [0mEpoch 43 Step 390/390 lr 0.100000 loss 0.2582 (0.1914) acc@1 0.8984 (0.9320) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:05:30] __main__ INFO: [0mElapsed 15.87
[32m[2022-06-11 10:05:30] __main__ INFO: [0mVal 43
[32m[2022-06-11 10:05:31] __main__ INFO: [0mEpoch 43 loss 0.5084 acc@1 0.8622 acc@5 0.9936
[32m[2022-06-11 10:05:31] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:05:31] __main__ INFO: [0mTrain 44 16770
[32m[2022-06-11 10:05:35] __main__ INFO: [0mEpoch 44 Step 100/390 lr 0.100000 loss 0.1208 (0.1703) acc@1 0.9453 (0.9409) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:39] __main__ INFO: [0mEpoch 44 Step 200/390 lr 0.100000 loss 0.1179 (0.1782) acc@1 0.9688 (0.9377) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:05:43] __main__ INFO: [0mEpoch 44 Step 300/390 lr 0.100000 loss 0.1647 (0.1836) acc@1 0.9688 (0.9357) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:05:47] __main__ INFO: [0mEpoch 44 Step 390/390 lr 0.100000 loss 0.2235 (0.1863) acc@1 0.9297 (0.9347) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:05:47] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:05:47] __main__ INFO: [0mVal 44
[32m[2022-06-11 10:05:48] __main__ INFO: [0mEpoch 44 loss 0.4580 acc@1 0.8690 acc@5 0.9946
[32m[2022-06-11 10:05:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:05:48] __main__ INFO: [0mTrain 45 17160
[32m[2022-06-11 10:05:52] __main__ INFO: [0mEpoch 45 Step 100/390 lr 0.100000 loss 0.1519 (0.1650) acc@1 0.9375 (0.9432) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:56] __main__ INFO: [0mEpoch 45 Step 200/390 lr 0.100000 loss 0.1957 (0.1771) acc@1 0.9219 (0.9378) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:06:00] __main__ INFO: [0mEpoch 45 Step 300/390 lr 0.100000 loss 0.2230 (0.1845) acc@1 0.9141 (0.9360) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:04] __main__ INFO: [0mEpoch 45 Step 390/390 lr 0.100000 loss 0.1999 (0.1852) acc@1 0.9297 (0.9358) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:06:04] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:06:04] __main__ INFO: [0mVal 45
[32m[2022-06-11 10:06:05] __main__ INFO: [0mEpoch 45 loss 0.3907 acc@1 0.8825 acc@5 0.9967
[32m[2022-06-11 10:06:05] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:06:05] __main__ INFO: [0mTrain 46 17550
[32m[2022-06-11 10:06:09] __main__ INFO: [0mEpoch 46 Step 100/390 lr 0.100000 loss 0.1677 (0.1566) acc@1 0.9453 (0.9447) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:06:13] __main__ INFO: [0mEpoch 46 Step 200/390 lr 0.100000 loss 0.2985 (0.1689) acc@1 0.9062 (0.9402) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:06:17] __main__ INFO: [0mEpoch 46 Step 300/390 lr 0.100000 loss 0.0896 (0.1797) acc@1 0.9531 (0.9368) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:20] __main__ INFO: [0mEpoch 46 Step 390/390 lr 0.100000 loss 0.2303 (0.1832) acc@1 0.9219 (0.9353) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:20] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 10:06:20] __main__ INFO: [0mVal 46
[32m[2022-06-11 10:06:21] __main__ INFO: [0mEpoch 46 loss 0.4425 acc@1 0.8647 acc@5 0.9939
[32m[2022-06-11 10:06:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:06:21] __main__ INFO: [0mTrain 47 17940
[32m[2022-06-11 10:06:25] __main__ INFO: [0mEpoch 47 Step 100/390 lr 0.100000 loss 0.2178 (0.1695) acc@1 0.9141 (0.9415) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:29] __main__ INFO: [0mEpoch 47 Step 200/390 lr 0.100000 loss 0.1933 (0.1816) acc@1 0.9297 (0.9379) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:33] __main__ INFO: [0mEpoch 47 Step 300/390 lr 0.100000 loss 0.3105 (0.1862) acc@1 0.9062 (0.9351) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:37] __main__ INFO: [0mEpoch 47 Step 390/390 lr 0.100000 loss 0.1814 (0.1886) acc@1 0.9375 (0.9341) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:37] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:06:37] __main__ INFO: [0mVal 47
[32m[2022-06-11 10:06:38] __main__ INFO: [0mEpoch 47 loss 0.4524 acc@1 0.8668 acc@5 0.9920
[32m[2022-06-11 10:06:38] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:06:38] __main__ INFO: [0mTrain 48 18330
[32m[2022-06-11 10:06:42] __main__ INFO: [0mEpoch 48 Step 100/390 lr 0.100000 loss 0.1483 (0.1804) acc@1 0.9453 (0.9360) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:06:46] __main__ INFO: [0mEpoch 48 Step 200/390 lr 0.100000 loss 0.1792 (0.1800) acc@1 0.9375 (0.9362) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:50] __main__ INFO: [0mEpoch 48 Step 300/390 lr 0.100000 loss 0.1676 (0.1832) acc@1 0.9375 (0.9355) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:06:54] __main__ INFO: [0mEpoch 48 Step 390/390 lr 0.100000 loss 0.1512 (0.1830) acc@1 0.9453 (0.9358) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:54] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:06:54] __main__ INFO: [0mVal 48
[32m[2022-06-11 10:06:55] __main__ INFO: [0mEpoch 48 loss 0.4523 acc@1 0.8715 acc@5 0.9946
[32m[2022-06-11 10:06:55] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:06:55] __main__ INFO: [0mTrain 49 18720
[32m[2022-06-11 10:06:59] __main__ INFO: [0mEpoch 49 Step 100/390 lr 0.100000 loss 0.1473 (0.1686) acc@1 0.9531 (0.9405) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:03] __main__ INFO: [0mEpoch 49 Step 200/390 lr 0.100000 loss 0.2297 (0.1722) acc@1 0.8906 (0.9387) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:07] __main__ INFO: [0mEpoch 49 Step 300/390 lr 0.100000 loss 0.2212 (0.1798) acc@1 0.9141 (0.9367) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:10] __main__ INFO: [0mEpoch 49 Step 390/390 lr 0.100000 loss 0.1897 (0.1804) acc@1 0.9297 (0.9364) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:10] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:07:10] __main__ INFO: [0mVal 49
[32m[2022-06-11 10:07:11] __main__ INFO: [0mEpoch 49 loss 0.4338 acc@1 0.8710 acc@5 0.9948
[32m[2022-06-11 10:07:11] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:07:11] __main__ INFO: [0mTrain 50 19110
[32m[2022-06-11 10:07:15] __main__ INFO: [0mEpoch 50 Step 100/390 lr 0.100000 loss 0.1651 (0.1608) acc@1 0.9219 (0.9437) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:19] __main__ INFO: [0mEpoch 50 Step 200/390 lr 0.100000 loss 0.0937 (0.1710) acc@1 0.9609 (0.9393) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:23] __main__ INFO: [0mEpoch 50 Step 300/390 lr 0.100000 loss 0.2250 (0.1719) acc@1 0.9297 (0.9389) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:27] __main__ INFO: [0mEpoch 50 Step 390/390 lr 0.100000 loss 0.2063 (0.1785) acc@1 0.9219 (0.9366) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:27] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:07:27] __main__ INFO: [0mVal 50
[32m[2022-06-11 10:07:28] __main__ INFO: [0mEpoch 50 loss 0.4181 acc@1 0.8736 acc@5 0.9954
[32m[2022-06-11 10:07:28] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:07:28] __main__ INFO: [0mTrain 51 19500
[32m[2022-06-11 10:07:32] __main__ INFO: [0mEpoch 51 Step 100/390 lr 0.100000 loss 0.0999 (0.1558) acc@1 0.9609 (0.9446) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:36] __main__ INFO: [0mEpoch 51 Step 200/390 lr 0.100000 loss 0.1540 (0.1622) acc@1 0.9453 (0.9429) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:40] __main__ INFO: [0mEpoch 51 Step 300/390 lr 0.100000 loss 0.1172 (0.1710) acc@1 0.9688 (0.9401) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:07:44] __main__ INFO: [0mEpoch 51 Step 390/390 lr 0.100000 loss 0.1296 (0.1752) acc@1 0.9531 (0.9381) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:07:44] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:07:44] __main__ INFO: [0mVal 51
[32m[2022-06-11 10:07:44] __main__ INFO: [0mEpoch 51 loss 0.5047 acc@1 0.8587 acc@5 0.9935
[32m[2022-06-11 10:07:44] __main__ INFO: [0mElapsed 0.88
[32m[2022-06-11 10:07:44] __main__ INFO: [0mTrain 52 19890
[32m[2022-06-11 10:07:49] __main__ INFO: [0mEpoch 52 Step 100/390 lr 0.100000 loss 0.1697 (0.1621) acc@1 0.9531 (0.9424) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:53] __main__ INFO: [0mEpoch 52 Step 200/390 lr 0.100000 loss 0.1860 (0.1693) acc@1 0.9375 (0.9396) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:56] __main__ INFO: [0mEpoch 52 Step 300/390 lr 0.100000 loss 0.2052 (0.1763) acc@1 0.9453 (0.9371) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:00] __main__ INFO: [0mEpoch 52 Step 390/390 lr 0.100000 loss 0.2328 (0.1786) acc@1 0.9219 (0.9365) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:00] __main__ INFO: [0mElapsed 15.53
[32m[2022-06-11 10:08:00] __main__ INFO: [0mVal 52
[32m[2022-06-11 10:08:01] __main__ INFO: [0mEpoch 52 loss 0.5347 acc@1 0.8564 acc@5 0.9940
[32m[2022-06-11 10:08:01] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:08:01] __main__ INFO: [0mTrain 53 20280
[32m[2022-06-11 10:08:05] __main__ INFO: [0mEpoch 53 Step 100/390 lr 0.100000 loss 0.0901 (0.1650) acc@1 0.9688 (0.9424) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:08:09] __main__ INFO: [0mEpoch 53 Step 200/390 lr 0.100000 loss 0.1687 (0.1689) acc@1 0.9453 (0.9408) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:13] __main__ INFO: [0mEpoch 53 Step 300/390 lr 0.100000 loss 0.1484 (0.1790) acc@1 0.9453 (0.9369) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:17] __main__ INFO: [0mEpoch 53 Step 390/390 lr 0.100000 loss 0.2219 (0.1822) acc@1 0.9062 (0.9356) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:17] __main__ INFO: [0mElapsed 16.00
[32m[2022-06-11 10:08:17] __main__ INFO: [0mVal 53
[32m[2022-06-11 10:08:18] __main__ INFO: [0mEpoch 53 loss 0.4402 acc@1 0.8657 acc@5 0.9958
[32m[2022-06-11 10:08:18] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:08:18] __main__ INFO: [0mTrain 54 20670
[32m[2022-06-11 10:08:22] __main__ INFO: [0mEpoch 54 Step 100/390 lr 0.100000 loss 0.2007 (0.1632) acc@1 0.9375 (0.9425) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:26] __main__ INFO: [0mEpoch 54 Step 200/390 lr 0.100000 loss 0.1342 (0.1673) acc@1 0.9609 (0.9421) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:30] __main__ INFO: [0mEpoch 54 Step 300/390 lr 0.100000 loss 0.2482 (0.1771) acc@1 0.9219 (0.9384) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:08:33] __main__ INFO: [0mEpoch 54 Step 390/390 lr 0.100000 loss 0.1585 (0.1794) acc@1 0.9375 (0.9371) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:08:33] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:08:33] __main__ INFO: [0mVal 54
[32m[2022-06-11 10:08:34] __main__ INFO: [0mEpoch 54 loss 0.3966 acc@1 0.8816 acc@5 0.9946
[32m[2022-06-11 10:08:34] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:08:34] __main__ INFO: [0mTrain 55 21060
[32m[2022-06-11 10:08:39] __main__ INFO: [0mEpoch 55 Step 100/390 lr 0.100000 loss 0.1921 (0.1562) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:43] __main__ INFO: [0mEpoch 55 Step 200/390 lr 0.100000 loss 0.1993 (0.1639) acc@1 0.9141 (0.9417) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:08:46] __main__ INFO: [0mEpoch 55 Step 300/390 lr 0.100000 loss 0.1708 (0.1721) acc@1 0.9453 (0.9389) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:50] __main__ INFO: [0mEpoch 55 Step 390/390 lr 0.100000 loss 0.1495 (0.1741) acc@1 0.9531 (0.9384) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:50] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:08:50] __main__ INFO: [0mVal 55
[32m[2022-06-11 10:08:51] __main__ INFO: [0mEpoch 55 loss 0.4541 acc@1 0.8705 acc@5 0.9954
[32m[2022-06-11 10:08:51] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:08:51] __main__ INFO: [0mTrain 56 21450
[32m[2022-06-11 10:08:55] __main__ INFO: [0mEpoch 56 Step 100/390 lr 0.100000 loss 0.1482 (0.1601) acc@1 0.9453 (0.9433) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:59] __main__ INFO: [0mEpoch 56 Step 200/390 lr 0.100000 loss 0.1875 (0.1660) acc@1 0.9375 (0.9413) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:03] __main__ INFO: [0mEpoch 56 Step 300/390 lr 0.100000 loss 0.2170 (0.1720) acc@1 0.9062 (0.9394) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:09:07] __main__ INFO: [0mEpoch 56 Step 390/390 lr 0.100000 loss 0.2959 (0.1779) acc@1 0.8594 (0.9374) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:07] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:09:07] __main__ INFO: [0mVal 56
[32m[2022-06-11 10:09:08] __main__ INFO: [0mEpoch 56 loss 0.5320 acc@1 0.8482 acc@5 0.9941
[32m[2022-06-11 10:09:08] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:09:08] __main__ INFO: [0mTrain 57 21840
[32m[2022-06-11 10:09:12] __main__ INFO: [0mEpoch 57 Step 100/390 lr 0.100000 loss 0.0682 (0.1587) acc@1 0.9688 (0.9470) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:16] __main__ INFO: [0mEpoch 57 Step 200/390 lr 0.100000 loss 0.1411 (0.1619) acc@1 0.9453 (0.9455) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:20] __main__ INFO: [0mEpoch 57 Step 300/390 lr 0.100000 loss 0.2608 (0.1711) acc@1 0.9062 (0.9416) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:23] __main__ INFO: [0mEpoch 57 Step 390/390 lr 0.100000 loss 0.1162 (0.1737) acc@1 0.9609 (0.9406) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:23] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:09:23] __main__ INFO: [0mVal 57
[32m[2022-06-11 10:09:24] __main__ INFO: [0mEpoch 57 loss 0.4003 acc@1 0.8831 acc@5 0.9942
[32m[2022-06-11 10:09:24] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:09:24] __main__ INFO: [0mTrain 58 22230
[32m[2022-06-11 10:09:28] __main__ INFO: [0mEpoch 58 Step 100/390 lr 0.100000 loss 0.1705 (0.1586) acc@1 0.9375 (0.9434) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:09:32] __main__ INFO: [0mEpoch 58 Step 200/390 lr 0.100000 loss 0.1757 (0.1637) acc@1 0.9297 (0.9416) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:36] __main__ INFO: [0mEpoch 58 Step 300/390 lr 0.100000 loss 0.3046 (0.1701) acc@1 0.9141 (0.9399) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:09:40] __main__ INFO: [0mEpoch 58 Step 390/390 lr 0.100000 loss 0.1266 (0.1733) acc@1 0.9609 (0.9391) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:09:40] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 10:09:40] __main__ INFO: [0mVal 58
[32m[2022-06-11 10:09:41] __main__ INFO: [0mEpoch 58 loss 0.5951 acc@1 0.8389 acc@5 0.9862
[32m[2022-06-11 10:09:41] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:09:41] __main__ INFO: [0mTrain 59 22620
[32m[2022-06-11 10:09:45] __main__ INFO: [0mEpoch 59 Step 100/390 lr 0.100000 loss 0.0636 (0.1499) acc@1 0.9922 (0.9469) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:49] __main__ INFO: [0mEpoch 59 Step 200/390 lr 0.100000 loss 0.2237 (0.1619) acc@1 0.9141 (0.9429) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:53] __main__ INFO: [0mEpoch 59 Step 300/390 lr 0.100000 loss 0.1630 (0.1697) acc@1 0.9297 (0.9405) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:57] __main__ INFO: [0mEpoch 59 Step 390/390 lr 0.100000 loss 0.2786 (0.1749) acc@1 0.8984 (0.9385) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:09:57] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:09:57] __main__ INFO: [0mVal 59
[32m[2022-06-11 10:09:58] __main__ INFO: [0mEpoch 59 loss 0.4630 acc@1 0.8669 acc@5 0.9956
[32m[2022-06-11 10:09:58] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:09:58] __main__ INFO: [0mTrain 60 23010
[32m[2022-06-11 10:10:02] __main__ INFO: [0mEpoch 60 Step 100/390 lr 0.100000 loss 0.1661 (0.1598) acc@1 0.9297 (0.9427) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:10:06] __main__ INFO: [0mEpoch 60 Step 200/390 lr 0.100000 loss 0.1581 (0.1668) acc@1 0.9531 (0.9397) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:10:10] __main__ INFO: [0mEpoch 60 Step 300/390 lr 0.100000 loss 0.2078 (0.1707) acc@1 0.9297 (0.9392) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:10:14] __main__ INFO: [0mEpoch 60 Step 390/390 lr 0.100000 loss 0.1692 (0.1724) acc@1 0.9141 (0.9387) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:10:14] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:10:14] __main__ INFO: [0mVal 60
[32m[2022-06-11 10:10:15] __main__ INFO: [0mEpoch 60 loss 0.4576 acc@1 0.8678 acc@5 0.9952
[32m[2022-06-11 10:10:15] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:10:15] __main__ INFO: [0mTrain 61 23400
[32m[2022-06-11 10:10:19] __main__ INFO: [0mEpoch 61 Step 100/390 lr 0.100000 loss 0.0885 (0.1610) acc@1 0.9766 (0.9437) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:10:23] __main__ INFO: [0mEpoch 61 Step 200/390 lr 0.100000 loss 0.1754 (0.1645) acc@1 0.9375 (0.9424) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:27] __main__ INFO: [0mEpoch 61 Step 300/390 lr 0.100000 loss 0.0850 (0.1688) acc@1 0.9688 (0.9408) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:30] __main__ INFO: [0mEpoch 61 Step 390/390 lr 0.100000 loss 0.1750 (0.1738) acc@1 0.9453 (0.9390) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:10:30] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:10:30] __main__ INFO: [0mVal 61
[32m[2022-06-11 10:10:31] __main__ INFO: [0mEpoch 61 loss 0.4547 acc@1 0.8651 acc@5 0.9948
[32m[2022-06-11 10:10:31] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:10:31] __main__ INFO: [0mTrain 62 23790
[32m[2022-06-11 10:10:35] __main__ INFO: [0mEpoch 62 Step 100/390 lr 0.100000 loss 0.2101 (0.1668) acc@1 0.9375 (0.9403) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:39] __main__ INFO: [0mEpoch 62 Step 200/390 lr 0.100000 loss 0.1727 (0.1672) acc@1 0.9375 (0.9405) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:10:43] __main__ INFO: [0mEpoch 62 Step 300/390 lr 0.100000 loss 0.2856 (0.1712) acc@1 0.9141 (0.9394) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:47] __main__ INFO: [0mEpoch 62 Step 390/390 lr 0.100000 loss 0.1850 (0.1751) acc@1 0.9609 (0.9378) acc@5 0.9922 (0.9991)
[32m[2022-06-11 10:10:47] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:10:47] __main__ INFO: [0mVal 62
[32m[2022-06-11 10:10:48] __main__ INFO: [0mEpoch 62 loss 0.4471 acc@1 0.8674 acc@5 0.9929
[32m[2022-06-11 10:10:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:10:48] __main__ INFO: [0mTrain 63 24180
[32m[2022-06-11 10:10:52] __main__ INFO: [0mEpoch 63 Step 100/390 lr 0.100000 loss 0.0745 (0.1544) acc@1 0.9766 (0.9455) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:10:56] __main__ INFO: [0mEpoch 63 Step 200/390 lr 0.100000 loss 0.1782 (0.1555) acc@1 0.9531 (0.9446) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:11:00] __main__ INFO: [0mEpoch 63 Step 300/390 lr 0.100000 loss 0.1254 (0.1653) acc@1 0.9531 (0.9412) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:04] __main__ INFO: [0mEpoch 63 Step 390/390 lr 0.100000 loss 0.2158 (0.1700) acc@1 0.9375 (0.9392) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:04] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:11:04] __main__ INFO: [0mVal 63
[32m[2022-06-11 10:11:05] __main__ INFO: [0mEpoch 63 loss 0.4124 acc@1 0.8758 acc@5 0.9947
[32m[2022-06-11 10:11:05] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:11:05] __main__ INFO: [0mTrain 64 24570
[32m[2022-06-11 10:11:09] __main__ INFO: [0mEpoch 64 Step 100/390 lr 0.100000 loss 0.1533 (0.1548) acc@1 0.9531 (0.9468) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:13] __main__ INFO: [0mEpoch 64 Step 200/390 lr 0.100000 loss 0.1931 (0.1623) acc@1 0.9297 (0.9439) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:17] __main__ INFO: [0mEpoch 64 Step 300/390 lr 0.100000 loss 0.1510 (0.1670) acc@1 0.9219 (0.9424) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:20] __main__ INFO: [0mEpoch 64 Step 390/390 lr 0.100000 loss 0.1181 (0.1692) acc@1 0.9688 (0.9418) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:20] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 10:11:20] __main__ INFO: [0mVal 64
[32m[2022-06-11 10:11:21] __main__ INFO: [0mEpoch 64 loss 0.4547 acc@1 0.8683 acc@5 0.9954
[32m[2022-06-11 10:11:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:11:21] __main__ INFO: [0mTrain 65 24960
[32m[2022-06-11 10:11:25] __main__ INFO: [0mEpoch 65 Step 100/390 lr 0.100000 loss 0.1940 (0.1515) acc@1 0.9062 (0.9464) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:11:29] __main__ INFO: [0mEpoch 65 Step 200/390 lr 0.100000 loss 0.2388 (0.1572) acc@1 0.9141 (0.9452) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:11:33] __main__ INFO: [0mEpoch 65 Step 300/390 lr 0.100000 loss 0.2012 (0.1633) acc@1 0.9297 (0.9430) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:37] __main__ INFO: [0mEpoch 65 Step 390/390 lr 0.100000 loss 0.1326 (0.1696) acc@1 0.9688 (0.9408) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:37] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:11:37] __main__ INFO: [0mVal 65
[32m[2022-06-11 10:11:38] __main__ INFO: [0mEpoch 65 loss 0.4387 acc@1 0.8740 acc@5 0.9938
[32m[2022-06-11 10:11:38] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:11:38] __main__ INFO: [0mTrain 66 25350
[32m[2022-06-11 10:11:42] __main__ INFO: [0mEpoch 66 Step 100/390 lr 0.100000 loss 0.1973 (0.1620) acc@1 0.9453 (0.9423) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:46] __main__ INFO: [0mEpoch 66 Step 200/390 lr 0.100000 loss 0.1866 (0.1668) acc@1 0.9531 (0.9405) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:50] __main__ INFO: [0mEpoch 66 Step 300/390 lr 0.100000 loss 0.1529 (0.1724) acc@1 0.9375 (0.9388) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:54] __main__ INFO: [0mEpoch 66 Step 390/390 lr 0.100000 loss 0.2226 (0.1738) acc@1 0.9297 (0.9384) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:54] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:11:54] __main__ INFO: [0mVal 66
[32m[2022-06-11 10:11:55] __main__ INFO: [0mEpoch 66 loss 0.4242 acc@1 0.8764 acc@5 0.9960
[32m[2022-06-11 10:11:55] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:11:55] __main__ INFO: [0mTrain 67 25740
[32m[2022-06-11 10:11:59] __main__ INFO: [0mEpoch 67 Step 100/390 lr 0.100000 loss 0.1892 (0.1595) acc@1 0.9375 (0.9452) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:12:03] __main__ INFO: [0mEpoch 67 Step 200/390 lr 0.100000 loss 0.1947 (0.1700) acc@1 0.8984 (0.9416) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:07] __main__ INFO: [0mEpoch 67 Step 300/390 lr 0.100000 loss 0.0885 (0.1698) acc@1 0.9844 (0.9410) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:12:10] __main__ INFO: [0mEpoch 67 Step 390/390 lr 0.100000 loss 0.1674 (0.1705) acc@1 0.9297 (0.9407) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:12:10] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:12:10] __main__ INFO: [0mVal 67
[32m[2022-06-11 10:12:11] __main__ INFO: [0mEpoch 67 loss 0.4086 acc@1 0.8769 acc@5 0.9950
[32m[2022-06-11 10:12:11] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:12:11] __main__ INFO: [0mTrain 68 26130
[32m[2022-06-11 10:12:16] __main__ INFO: [0mEpoch 68 Step 100/390 lr 0.100000 loss 0.1197 (0.1533) acc@1 0.9688 (0.9489) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:19] __main__ INFO: [0mEpoch 68 Step 200/390 lr 0.100000 loss 0.2528 (0.1621) acc@1 0.9219 (0.9450) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:23] __main__ INFO: [0mEpoch 68 Step 300/390 lr 0.100000 loss 0.1191 (0.1685) acc@1 0.9688 (0.9421) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:27] __main__ INFO: [0mEpoch 68 Step 390/390 lr 0.100000 loss 0.2163 (0.1743) acc@1 0.9375 (0.9398) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:27] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:12:27] __main__ INFO: [0mVal 68
[32m[2022-06-11 10:12:28] __main__ INFO: [0mEpoch 68 loss 0.4890 acc@1 0.8668 acc@5 0.9950
[32m[2022-06-11 10:12:28] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 10:12:28] __main__ INFO: [0mTrain 69 26520
[32m[2022-06-11 10:12:32] __main__ INFO: [0mEpoch 69 Step 100/390 lr 0.100000 loss 0.1154 (0.1541) acc@1 0.9844 (0.9462) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:36] __main__ INFO: [0mEpoch 69 Step 200/390 lr 0.100000 loss 0.1364 (0.1577) acc@1 0.9453 (0.9451) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:40] __main__ INFO: [0mEpoch 69 Step 300/390 lr 0.100000 loss 0.2041 (0.1620) acc@1 0.9375 (0.9426) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:44] __main__ INFO: [0mEpoch 69 Step 390/390 lr 0.100000 loss 0.2820 (0.1644) acc@1 0.8984 (0.9417) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:44] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 10:12:44] __main__ INFO: [0mVal 69
[32m[2022-06-11 10:12:45] __main__ INFO: [0mEpoch 69 loss 0.4136 acc@1 0.8826 acc@5 0.9956
[32m[2022-06-11 10:12:45] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:12:45] __main__ INFO: [0mTrain 70 26910
[32m[2022-06-11 10:12:49] __main__ INFO: [0mEpoch 70 Step 100/390 lr 0.100000 loss 0.1851 (0.1507) acc@1 0.9531 (0.9485) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:53] __main__ INFO: [0mEpoch 70 Step 200/390 lr 0.100000 loss 0.2008 (0.1591) acc@1 0.9219 (0.9446) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:12:57] __main__ INFO: [0mEpoch 70 Step 300/390 lr 0.100000 loss 0.1953 (0.1631) acc@1 0.9453 (0.9429) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:00] __main__ INFO: [0mEpoch 70 Step 390/390 lr 0.100000 loss 0.1586 (0.1653) acc@1 0.9297 (0.9423) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:00] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:13:00] __main__ INFO: [0mVal 70
[32m[2022-06-11 10:13:01] __main__ INFO: [0mEpoch 70 loss 0.4163 acc@1 0.8764 acc@5 0.9947
[32m[2022-06-11 10:13:01] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:13:01] __main__ INFO: [0mTrain 71 27300
[32m[2022-06-11 10:13:05] __main__ INFO: [0mEpoch 71 Step 100/390 lr 0.100000 loss 0.2445 (0.1573) acc@1 0.8984 (0.9456) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:13:09] __main__ INFO: [0mEpoch 71 Step 200/390 lr 0.100000 loss 0.1584 (0.1580) acc@1 0.9219 (0.9444) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:13] __main__ INFO: [0mEpoch 71 Step 300/390 lr 0.100000 loss 0.1556 (0.1608) acc@1 0.9375 (0.9434) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:17] __main__ INFO: [0mEpoch 71 Step 390/390 lr 0.100000 loss 0.1637 (0.1653) acc@1 0.9531 (0.9420) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:17] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:13:17] __main__ INFO: [0mVal 71
[32m[2022-06-11 10:13:18] __main__ INFO: [0mEpoch 71 loss 0.4424 acc@1 0.8694 acc@5 0.9961
[32m[2022-06-11 10:13:18] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:13:18] __main__ INFO: [0mTrain 72 27690
[32m[2022-06-11 10:13:22] __main__ INFO: [0mEpoch 72 Step 100/390 lr 0.100000 loss 0.1730 (0.1564) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:13:26] __main__ INFO: [0mEpoch 72 Step 200/390 lr 0.100000 loss 0.1855 (0.1637) acc@1 0.9297 (0.9428) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:30] __main__ INFO: [0mEpoch 72 Step 300/390 lr 0.100000 loss 0.1909 (0.1673) acc@1 0.9219 (0.9412) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:34] __main__ INFO: [0mEpoch 72 Step 390/390 lr 0.100000 loss 0.1195 (0.1737) acc@1 0.9688 (0.9388) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:13:34] __main__ INFO: [0mElapsed 16.00
[32m[2022-06-11 10:13:34] __main__ INFO: [0mVal 72
[32m[2022-06-11 10:13:35] __main__ INFO: [0mEpoch 72 loss 0.4116 acc@1 0.8795 acc@5 0.9945
[32m[2022-06-11 10:13:35] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:13:35] __main__ INFO: [0mTrain 73 28080
[32m[2022-06-11 10:13:39] __main__ INFO: [0mEpoch 73 Step 100/390 lr 0.100000 loss 0.1155 (0.1535) acc@1 0.9609 (0.9478) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:43] __main__ INFO: [0mEpoch 73 Step 200/390 lr 0.100000 loss 0.2923 (0.1658) acc@1 0.8828 (0.9431) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:47] __main__ INFO: [0mEpoch 73 Step 300/390 lr 0.100000 loss 0.0928 (0.1658) acc@1 0.9688 (0.9423) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:51] __main__ INFO: [0mEpoch 73 Step 390/390 lr 0.100000 loss 0.1483 (0.1660) acc@1 0.9453 (0.9417) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:51] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:13:51] __main__ INFO: [0mVal 73
[32m[2022-06-11 10:13:52] __main__ INFO: [0mEpoch 73 loss 0.3855 acc@1 0.8893 acc@5 0.9964
[32m[2022-06-11 10:13:52] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:13:52] __main__ INFO: [0mTrain 74 28470
[32m[2022-06-11 10:13:56] __main__ INFO: [0mEpoch 74 Step 100/390 lr 0.100000 loss 0.1283 (0.1567) acc@1 0.9688 (0.9450) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:00] __main__ INFO: [0mEpoch 74 Step 200/390 lr 0.100000 loss 0.2075 (0.1606) acc@1 0.9062 (0.9433) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:04] __main__ INFO: [0mEpoch 74 Step 300/390 lr 0.100000 loss 0.1245 (0.1633) acc@1 0.9453 (0.9422) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:07] __main__ INFO: [0mEpoch 74 Step 390/390 lr 0.100000 loss 0.1689 (0.1659) acc@1 0.9375 (0.9411) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:08] __main__ INFO: [0mElapsed 15.88
[32m[2022-06-11 10:14:08] __main__ INFO: [0mVal 74
[32m[2022-06-11 10:14:08] __main__ INFO: [0mEpoch 74 loss 0.4028 acc@1 0.8822 acc@5 0.9947
[32m[2022-06-11 10:14:08] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 10:14:08] __main__ INFO: [0mTrain 75 28860
[32m[2022-06-11 10:14:12] __main__ INFO: [0mEpoch 75 Step 100/390 lr 0.100000 loss 0.2284 (0.1518) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:14:16] __main__ INFO: [0mEpoch 75 Step 200/390 lr 0.100000 loss 0.1127 (0.1638) acc@1 0.9609 (0.9417) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:20] __main__ INFO: [0mEpoch 75 Step 300/390 lr 0.100000 loss 0.2286 (0.1649) acc@1 0.9297 (0.9409) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:24] __main__ INFO: [0mEpoch 75 Step 390/390 lr 0.100000 loss 0.1444 (0.1672) acc@1 0.9453 (0.9400) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:14:24] __main__ INFO: [0mElapsed 15.41
[32m[2022-06-11 10:14:24] __main__ INFO: [0mVal 75
[32m[2022-06-11 10:14:25] __main__ INFO: [0mEpoch 75 loss 0.5518 acc@1 0.8532 acc@5 0.9930
[32m[2022-06-11 10:14:25] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:14:25] __main__ INFO: [0mTrain 76 29250
[32m[2022-06-11 10:14:29] __main__ INFO: [0mEpoch 76 Step 100/390 lr 0.100000 loss 0.1722 (0.1435) acc@1 0.8984 (0.9504) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:14:33] __main__ INFO: [0mEpoch 76 Step 200/390 lr 0.100000 loss 0.0423 (0.1577) acc@1 0.9922 (0.9446) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:14:37] __main__ INFO: [0mEpoch 76 Step 300/390 lr 0.100000 loss 0.1654 (0.1618) acc@1 0.9375 (0.9435) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:14:40] __main__ INFO: [0mEpoch 76 Step 390/390 lr 0.100000 loss 0.2284 (0.1651) acc@1 0.9297 (0.9420) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:14:40] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 10:14:40] __main__ INFO: [0mVal 76
[32m[2022-06-11 10:14:41] __main__ INFO: [0mEpoch 76 loss 0.5314 acc@1 0.8520 acc@5 0.9902
[32m[2022-06-11 10:14:41] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:14:41] __main__ INFO: [0mTrain 77 29640
[32m[2022-06-11 10:14:46] __main__ INFO: [0mEpoch 77 Step 100/390 lr 0.100000 loss 0.1711 (0.1479) acc@1 0.9453 (0.9481) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:14:49] __main__ INFO: [0mEpoch 77 Step 200/390 lr 0.100000 loss 0.1918 (0.1561) acc@1 0.9453 (0.9457) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:14:53] __main__ INFO: [0mEpoch 77 Step 300/390 lr 0.100000 loss 0.1137 (0.1575) acc@1 0.9609 (0.9452) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:57] __main__ INFO: [0mEpoch 77 Step 390/390 lr 0.100000 loss 0.2483 (0.1644) acc@1 0.9141 (0.9423) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:14:57] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:14:57] __main__ INFO: [0mVal 77
[32m[2022-06-11 10:14:58] __main__ INFO: [0mEpoch 77 loss 0.4007 acc@1 0.8793 acc@5 0.9942
[32m[2022-06-11 10:14:58] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:14:58] __main__ INFO: [0mTrain 78 30030
[32m[2022-06-11 10:15:02] __main__ INFO: [0mEpoch 78 Step 100/390 lr 0.100000 loss 0.1286 (0.1560) acc@1 0.9688 (0.9437) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:15:06] __main__ INFO: [0mEpoch 78 Step 200/390 lr 0.100000 loss 0.1946 (0.1659) acc@1 0.9453 (0.9419) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:15:10] __main__ INFO: [0mEpoch 78 Step 300/390 lr 0.100000 loss 0.1194 (0.1641) acc@1 0.9453 (0.9424) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:15:13] __main__ INFO: [0mEpoch 78 Step 390/390 lr 0.100000 loss 0.1781 (0.1691) acc@1 0.9297 (0.9410) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:15:13] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:15:13] __main__ INFO: [0mVal 78
[32m[2022-06-11 10:15:14] __main__ INFO: [0mEpoch 78 loss 0.4610 acc@1 0.8641 acc@5 0.9939
[32m[2022-06-11 10:15:14] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:15:14] __main__ INFO: [0mTrain 79 30420
[32m[2022-06-11 10:15:19] __main__ INFO: [0mEpoch 79 Step 100/390 lr 0.100000 loss 0.1092 (0.1518) acc@1 0.9453 (0.9446) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:15:23] __main__ INFO: [0mEpoch 79 Step 200/390 lr 0.100000 loss 0.2298 (0.1540) acc@1 0.9531 (0.9442) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:27] __main__ INFO: [0mEpoch 79 Step 300/390 lr 0.100000 loss 0.1178 (0.1587) acc@1 0.9844 (0.9434) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:30] __main__ INFO: [0mEpoch 79 Step 390/390 lr 0.100000 loss 0.1030 (0.1629) acc@1 0.9844 (0.9419) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:30] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:15:30] __main__ INFO: [0mVal 79
[32m[2022-06-11 10:15:31] __main__ INFO: [0mEpoch 79 loss 0.4525 acc@1 0.8770 acc@5 0.9948
[32m[2022-06-11 10:15:31] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 10:15:31] __main__ INFO: [0mTrain 80 30810
[32m[2022-06-11 10:15:35] __main__ INFO: [0mEpoch 80 Step 100/390 lr 0.100000 loss 0.0857 (0.1653) acc@1 0.9688 (0.9413) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:39] __main__ INFO: [0mEpoch 80 Step 200/390 lr 0.100000 loss 0.1711 (0.1677) acc@1 0.9531 (0.9416) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:15:43] __main__ INFO: [0mEpoch 80 Step 300/390 lr 0.100000 loss 0.1633 (0.1639) acc@1 0.9219 (0.9422) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:47] __main__ INFO: [0mEpoch 80 Step 390/390 lr 0.100000 loss 0.2726 (0.1679) acc@1 0.9141 (0.9412) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:47] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 10:15:47] __main__ INFO: [0mVal 80
[32m[2022-06-11 10:15:48] __main__ INFO: [0mEpoch 80 loss 0.4470 acc@1 0.8739 acc@5 0.9944
[32m[2022-06-11 10:15:48] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:15:48] __main__ INFO: [0mTrain 81 31200
[32m[2022-06-11 10:15:52] __main__ INFO: [0mEpoch 81 Step 100/390 lr 0.010000 loss 0.1312 (0.1110) acc@1 0.9453 (0.9637) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:15:56] __main__ INFO: [0mEpoch 81 Step 200/390 lr 0.010000 loss 0.1008 (0.1033) acc@1 0.9688 (0.9656) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:16:00] __main__ INFO: [0mEpoch 81 Step 300/390 lr 0.010000 loss 0.0895 (0.0951) acc@1 0.9766 (0.9686) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:16:03] __main__ INFO: [0mEpoch 81 Step 390/390 lr 0.010000 loss 0.1290 (0.0900) acc@1 0.9609 (0.9703) acc@5 0.9922 (0.9997)
[32m[2022-06-11 10:16:03] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:16:03] __main__ INFO: [0mVal 81
[32m[2022-06-11 10:16:04] __main__ INFO: [0mEpoch 81 loss 0.2692 acc@1 0.9189 acc@5 0.9980
[32m[2022-06-11 10:16:04] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:16:04] __main__ INFO: [0mTrain 82 31590
[32m[2022-06-11 10:16:08] __main__ INFO: [0mEpoch 82 Step 100/390 lr 0.010000 loss 0.0511 (0.0664) acc@1 0.9688 (0.9798) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:12] __main__ INFO: [0mEpoch 82 Step 200/390 lr 0.010000 loss 0.0407 (0.0640) acc@1 0.9922 (0.9802) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:16] __main__ INFO: [0mEpoch 82 Step 300/390 lr 0.010000 loss 0.0616 (0.0620) acc@1 0.9844 (0.9805) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:20] __main__ INFO: [0mEpoch 82 Step 390/390 lr 0.010000 loss 0.0667 (0.0604) acc@1 0.9844 (0.9809) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:20] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:16:20] __main__ INFO: [0mVal 82
[32m[2022-06-11 10:16:21] __main__ INFO: [0mEpoch 82 loss 0.2662 acc@1 0.9216 acc@5 0.9978
[32m[2022-06-11 10:16:21] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:16:21] __main__ INFO: [0mTrain 83 31980
[32m[2022-06-11 10:16:25] __main__ INFO: [0mEpoch 83 Step 100/390 lr 0.010000 loss 0.0720 (0.0500) acc@1 0.9766 (0.9849) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:16:29] __main__ INFO: [0mEpoch 83 Step 200/390 lr 0.010000 loss 0.0488 (0.0496) acc@1 0.9844 (0.9852) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:16:33] __main__ INFO: [0mEpoch 83 Step 300/390 lr 0.010000 loss 0.0369 (0.0505) acc@1 0.9922 (0.9848) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:37] __main__ INFO: [0mEpoch 83 Step 390/390 lr 0.010000 loss 0.0652 (0.0510) acc@1 0.9609 (0.9843) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:37] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:16:37] __main__ INFO: [0mVal 83
[32m[2022-06-11 10:16:38] __main__ INFO: [0mEpoch 83 loss 0.2687 acc@1 0.9226 acc@5 0.9982
[32m[2022-06-11 10:16:38] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:16:38] __main__ INFO: [0mTrain 84 32370
[32m[2022-06-11 10:16:42] __main__ INFO: [0mEpoch 84 Step 100/390 lr 0.010000 loss 0.0351 (0.0445) acc@1 0.9922 (0.9857) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:46] __main__ INFO: [0mEpoch 84 Step 200/390 lr 0.010000 loss 0.0446 (0.0439) acc@1 0.9844 (0.9863) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:50] __main__ INFO: [0mEpoch 84 Step 300/390 lr 0.010000 loss 0.0233 (0.0445) acc@1 1.0000 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:53] __main__ INFO: [0mEpoch 84 Step 390/390 lr 0.010000 loss 0.0310 (0.0439) acc@1 0.9922 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:53] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:16:53] __main__ INFO: [0mVal 84
[32m[2022-06-11 10:16:54] __main__ INFO: [0mEpoch 84 loss 0.2741 acc@1 0.9240 acc@5 0.9983
[32m[2022-06-11 10:16:54] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:16:54] __main__ INFO: [0mTrain 85 32760
[32m[2022-06-11 10:16:58] __main__ INFO: [0mEpoch 85 Step 100/390 lr 0.010000 loss 0.0217 (0.0396) acc@1 1.0000 (0.9883) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:02] __main__ INFO: [0mEpoch 85 Step 200/390 lr 0.010000 loss 0.0505 (0.0387) acc@1 0.9844 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:06] __main__ INFO: [0mEpoch 85 Step 300/390 lr 0.010000 loss 0.0119 (0.0391) acc@1 1.0000 (0.9885) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:10] __main__ INFO: [0mEpoch 85 Step 390/390 lr 0.010000 loss 0.0405 (0.0396) acc@1 0.9922 (0.9883) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:10] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:17:10] __main__ INFO: [0mVal 85
[32m[2022-06-11 10:17:11] __main__ INFO: [0mEpoch 85 loss 0.2732 acc@1 0.9250 acc@5 0.9980
[32m[2022-06-11 10:17:11] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:17:11] __main__ INFO: [0mTrain 86 33150
[32m[2022-06-11 10:17:15] __main__ INFO: [0mEpoch 86 Step 100/390 lr 0.010000 loss 0.0420 (0.0334) acc@1 1.0000 (0.9904) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:17:19] __main__ INFO: [0mEpoch 86 Step 200/390 lr 0.010000 loss 0.0225 (0.0351) acc@1 0.9922 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:23] __main__ INFO: [0mEpoch 86 Step 300/390 lr 0.010000 loss 0.0333 (0.0352) acc@1 0.9922 (0.9897) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:26] __main__ INFO: [0mEpoch 86 Step 390/390 lr 0.010000 loss 0.0376 (0.0345) acc@1 0.9922 (0.9897) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:27] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:17:27] __main__ INFO: [0mVal 86
[32m[2022-06-11 10:17:28] __main__ INFO: [0mEpoch 86 loss 0.2806 acc@1 0.9228 acc@5 0.9976
[32m[2022-06-11 10:17:28] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:17:28] __main__ INFO: [0mTrain 87 33540
[32m[2022-06-11 10:17:32] __main__ INFO: [0mEpoch 87 Step 100/390 lr 0.010000 loss 0.0558 (0.0305) acc@1 0.9844 (0.9914) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:17:36] __main__ INFO: [0mEpoch 87 Step 200/390 lr 0.010000 loss 0.0516 (0.0320) acc@1 0.9844 (0.9907) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:40] __main__ INFO: [0mEpoch 87 Step 300/390 lr 0.010000 loss 0.0618 (0.0331) acc@1 0.9844 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:43] __main__ INFO: [0mEpoch 87 Step 390/390 lr 0.010000 loss 0.0911 (0.0330) acc@1 0.9609 (0.9901) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:43] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:17:43] __main__ INFO: [0mVal 87
[32m[2022-06-11 10:17:44] __main__ INFO: [0mEpoch 87 loss 0.2785 acc@1 0.9240 acc@5 0.9981
[32m[2022-06-11 10:17:44] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:17:44] __main__ INFO: [0mTrain 88 33930
[32m[2022-06-11 10:17:48] __main__ INFO: [0mEpoch 88 Step 100/390 lr 0.010000 loss 0.0578 (0.0300) acc@1 0.9766 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:52] __main__ INFO: [0mEpoch 88 Step 200/390 lr 0.010000 loss 0.0232 (0.0309) acc@1 0.9922 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:56] __main__ INFO: [0mEpoch 88 Step 300/390 lr 0.010000 loss 0.0469 (0.0314) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:00] __main__ INFO: [0mEpoch 88 Step 390/390 lr 0.010000 loss 0.0201 (0.0306) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:00] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:18:00] __main__ INFO: [0mVal 88
[32m[2022-06-11 10:18:01] __main__ INFO: [0mEpoch 88 loss 0.2954 acc@1 0.9225 acc@5 0.9979
[32m[2022-06-11 10:18:01] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:18:01] __main__ INFO: [0mTrain 89 34320
[32m[2022-06-11 10:18:05] __main__ INFO: [0mEpoch 89 Step 100/390 lr 0.010000 loss 0.0360 (0.0287) acc@1 0.9922 (0.9915) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:09] __main__ INFO: [0mEpoch 89 Step 200/390 lr 0.010000 loss 0.0474 (0.0284) acc@1 0.9766 (0.9913) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:13] __main__ INFO: [0mEpoch 89 Step 300/390 lr 0.010000 loss 0.0416 (0.0287) acc@1 0.9844 (0.9913) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:16] __main__ INFO: [0mEpoch 89 Step 390/390 lr 0.010000 loss 0.0227 (0.0287) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:16] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 10:18:16] __main__ INFO: [0mVal 89
[32m[2022-06-11 10:18:17] __main__ INFO: [0mEpoch 89 loss 0.2878 acc@1 0.9241 acc@5 0.9981
[32m[2022-06-11 10:18:17] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:18:17] __main__ INFO: [0mTrain 90 34710
[32m[2022-06-11 10:18:22] __main__ INFO: [0mEpoch 90 Step 100/390 lr 0.010000 loss 0.0301 (0.0265) acc@1 0.9922 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:26] __main__ INFO: [0mEpoch 90 Step 200/390 lr 0.010000 loss 0.0109 (0.0266) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:30] __main__ INFO: [0mEpoch 90 Step 300/390 lr 0.010000 loss 0.0110 (0.0269) acc@1 1.0000 (0.9915) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:33] __main__ INFO: [0mEpoch 90 Step 390/390 lr 0.010000 loss 0.0377 (0.0269) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:33] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:18:33] __main__ INFO: [0mVal 90
[32m[2022-06-11 10:18:34] __main__ INFO: [0mEpoch 90 loss 0.2952 acc@1 0.9240 acc@5 0.9980
[32m[2022-06-11 10:18:34] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:18:34] __main__ INFO: [0mTrain 91 35100
[32m[2022-06-11 10:18:38] __main__ INFO: [0mEpoch 91 Step 100/390 lr 0.010000 loss 0.0487 (0.0245) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:42] __main__ INFO: [0mEpoch 91 Step 200/390 lr 0.010000 loss 0.0078 (0.0249) acc@1 1.0000 (0.9931) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:46] __main__ INFO: [0mEpoch 91 Step 300/390 lr 0.010000 loss 0.0336 (0.0258) acc@1 0.9844 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:50] __main__ INFO: [0mEpoch 91 Step 390/390 lr 0.010000 loss 0.0142 (0.0262) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:50] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:18:50] __main__ INFO: [0mVal 91
[32m[2022-06-11 10:18:51] __main__ INFO: [0mEpoch 91 loss 0.2955 acc@1 0.9237 acc@5 0.9986
[32m[2022-06-11 10:18:51] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:18:51] __main__ INFO: [0mTrain 92 35490
[32m[2022-06-11 10:18:55] __main__ INFO: [0mEpoch 92 Step 100/390 lr 0.010000 loss 0.0458 (0.0249) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:59] __main__ INFO: [0mEpoch 92 Step 200/390 lr 0.010000 loss 0.0081 (0.0241) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:03] __main__ INFO: [0mEpoch 92 Step 300/390 lr 0.010000 loss 0.0335 (0.0243) acc@1 0.9922 (0.9929) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:07] __main__ INFO: [0mEpoch 92 Step 390/390 lr 0.010000 loss 0.0214 (0.0239) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:07] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:19:07] __main__ INFO: [0mVal 92
[32m[2022-06-11 10:19:08] __main__ INFO: [0mEpoch 92 loss 0.2951 acc@1 0.9247 acc@5 0.9982
[32m[2022-06-11 10:19:08] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:19:08] __main__ INFO: [0mTrain 93 35880
[32m[2022-06-11 10:19:12] __main__ INFO: [0mEpoch 93 Step 100/390 lr 0.010000 loss 0.0193 (0.0218) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:16] __main__ INFO: [0mEpoch 93 Step 200/390 lr 0.010000 loss 0.0160 (0.0222) acc@1 1.0000 (0.9937) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:20] __main__ INFO: [0mEpoch 93 Step 300/390 lr 0.010000 loss 0.0109 (0.0227) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:23] __main__ INFO: [0mEpoch 93 Step 390/390 lr 0.010000 loss 0.0062 (0.0234) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:24] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:19:24] __main__ INFO: [0mVal 93
[32m[2022-06-11 10:19:24] __main__ INFO: [0mEpoch 93 loss 0.2997 acc@1 0.9233 acc@5 0.9983
[32m[2022-06-11 10:19:24] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:19:24] __main__ INFO: [0mTrain 94 36270
[32m[2022-06-11 10:19:29] __main__ INFO: [0mEpoch 94 Step 100/390 lr 0.010000 loss 0.0110 (0.0196) acc@1 0.9922 (0.9949) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:32] __main__ INFO: [0mEpoch 94 Step 200/390 lr 0.010000 loss 0.0251 (0.0199) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:36] __main__ INFO: [0mEpoch 94 Step 300/390 lr 0.010000 loss 0.0230 (0.0196) acc@1 0.9922 (0.9948) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:40] __main__ INFO: [0mEpoch 94 Step 390/390 lr 0.010000 loss 0.0177 (0.0202) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:40] __main__ INFO: [0mElapsed 15.55
[32m[2022-06-11 10:19:40] __main__ INFO: [0mVal 94
[32m[2022-06-11 10:19:41] __main__ INFO: [0mEpoch 94 loss 0.3075 acc@1 0.9243 acc@5 0.9983
[32m[2022-06-11 10:19:41] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:19:41] __main__ INFO: [0mTrain 95 36660
[32m[2022-06-11 10:19:45] __main__ INFO: [0mEpoch 95 Step 100/390 lr 0.010000 loss 0.0206 (0.0197) acc@1 0.9922 (0.9945) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:49] __main__ INFO: [0mEpoch 95 Step 200/390 lr 0.010000 loss 0.0169 (0.0195) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:53] __main__ INFO: [0mEpoch 95 Step 300/390 lr 0.010000 loss 0.0225 (0.0188) acc@1 0.9922 (0.9951) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:57] __main__ INFO: [0mEpoch 95 Step 390/390 lr 0.010000 loss 0.0112 (0.0191) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:57] __main__ INFO: [0mElapsed 16.08
[32m[2022-06-11 10:19:57] __main__ INFO: [0mVal 95
[32m[2022-06-11 10:19:58] __main__ INFO: [0mEpoch 95 loss 0.3033 acc@1 0.9251 acc@5 0.9986
[32m[2022-06-11 10:19:58] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:19:58] __main__ INFO: [0mTrain 96 37050
[32m[2022-06-11 10:20:02] __main__ INFO: [0mEpoch 96 Step 100/390 lr 0.010000 loss 0.0192 (0.0196) acc@1 0.9922 (0.9951) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:06] __main__ INFO: [0mEpoch 96 Step 200/390 lr 0.010000 loss 0.0066 (0.0188) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:10] __main__ INFO: [0mEpoch 96 Step 300/390 lr 0.010000 loss 0.0357 (0.0186) acc@1 0.9844 (0.9954) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:14] __main__ INFO: [0mEpoch 96 Step 390/390 lr 0.010000 loss 0.0109 (0.0186) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:14] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:20:14] __main__ INFO: [0mVal 96
[32m[2022-06-11 10:20:15] __main__ INFO: [0mEpoch 96 loss 0.3079 acc@1 0.9249 acc@5 0.9982
[32m[2022-06-11 10:20:15] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:20:15] __main__ INFO: [0mTrain 97 37440
[32m[2022-06-11 10:20:19] __main__ INFO: [0mEpoch 97 Step 100/390 lr 0.010000 loss 0.0209 (0.0174) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:23] __main__ INFO: [0mEpoch 97 Step 200/390 lr 0.010000 loss 0.0208 (0.0171) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:27] __main__ INFO: [0mEpoch 97 Step 300/390 lr 0.010000 loss 0.0121 (0.0173) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:30] __main__ INFO: [0mEpoch 97 Step 390/390 lr 0.010000 loss 0.0156 (0.0177) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:31] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:20:31] __main__ INFO: [0mVal 97
[32m[2022-06-11 10:20:32] __main__ INFO: [0mEpoch 97 loss 0.3126 acc@1 0.9248 acc@5 0.9985
[32m[2022-06-11 10:20:32] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:20:32] __main__ INFO: [0mTrain 98 37830
[32m[2022-06-11 10:20:36] __main__ INFO: [0mEpoch 98 Step 100/390 lr 0.010000 loss 0.0034 (0.0186) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:40] __main__ INFO: [0mEpoch 98 Step 200/390 lr 0.010000 loss 0.0068 (0.0171) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:43] __main__ INFO: [0mEpoch 98 Step 300/390 lr 0.010000 loss 0.0238 (0.0168) acc@1 0.9922 (0.9957) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:47] __main__ INFO: [0mEpoch 98 Step 390/390 lr 0.010000 loss 0.0182 (0.0168) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:47] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:20:47] __main__ INFO: [0mVal 98
[32m[2022-06-11 10:20:48] __main__ INFO: [0mEpoch 98 loss 0.3147 acc@1 0.9257 acc@5 0.9984
[32m[2022-06-11 10:20:48] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:20:48] __main__ INFO: [0mTrain 99 38220
[32m[2022-06-11 10:20:52] __main__ INFO: [0mEpoch 99 Step 100/390 lr 0.010000 loss 0.0130 (0.0157) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:56] __main__ INFO: [0mEpoch 99 Step 200/390 lr 0.010000 loss 0.0091 (0.0160) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:00] __main__ INFO: [0mEpoch 99 Step 300/390 lr 0.010000 loss 0.0119 (0.0158) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:04] __main__ INFO: [0mEpoch 99 Step 390/390 lr 0.010000 loss 0.0271 (0.0159) acc@1 0.9922 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:04] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:21:04] __main__ INFO: [0mVal 99
[32m[2022-06-11 10:21:05] __main__ INFO: [0mEpoch 99 loss 0.3089 acc@1 0.9257 acc@5 0.9984
[32m[2022-06-11 10:21:05] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:21:05] __main__ INFO: [0mTrain 100 38610
[32m[2022-06-11 10:21:09] __main__ INFO: [0mEpoch 100 Step 100/390 lr 0.010000 loss 0.0340 (0.0130) acc@1 0.9844 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:13] __main__ INFO: [0mEpoch 100 Step 200/390 lr 0.010000 loss 0.0062 (0.0142) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:17] __main__ INFO: [0mEpoch 100 Step 300/390 lr 0.010000 loss 0.0227 (0.0144) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:20] __main__ INFO: [0mEpoch 100 Step 390/390 lr 0.010000 loss 0.0256 (0.0148) acc@1 0.9844 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:21] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:21:21] __main__ INFO: [0mVal 100
[32m[2022-06-11 10:21:22] __main__ INFO: [0mEpoch 100 loss 0.3121 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:21:22] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:21:22] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00100.pth
[32m[2022-06-11 10:21:22] __main__ INFO: [0mTrain 101 39000
[32m[2022-06-11 10:21:26] __main__ INFO: [0mEpoch 101 Step 100/390 lr 0.010000 loss 0.0396 (0.0149) acc@1 0.9922 (0.9961) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:21:30] __main__ INFO: [0mEpoch 101 Step 200/390 lr 0.010000 loss 0.0291 (0.0150) acc@1 0.9922 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:34] __main__ INFO: [0mEpoch 101 Step 300/390 lr 0.010000 loss 0.0304 (0.0155) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:37] __main__ INFO: [0mEpoch 101 Step 390/390 lr 0.010000 loss 0.0062 (0.0157) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:37] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:21:37] __main__ INFO: [0mVal 101
[32m[2022-06-11 10:21:38] __main__ INFO: [0mEpoch 101 loss 0.3245 acc@1 0.9236 acc@5 0.9982
[32m[2022-06-11 10:21:38] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:21:38] __main__ INFO: [0mTrain 102 39390
[32m[2022-06-11 10:21:43] __main__ INFO: [0mEpoch 102 Step 100/390 lr 0.010000 loss 0.0160 (0.0143) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:47] __main__ INFO: [0mEpoch 102 Step 200/390 lr 0.010000 loss 0.0140 (0.0152) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:51] __main__ INFO: [0mEpoch 102 Step 300/390 lr 0.010000 loss 0.0241 (0.0152) acc@1 0.9922 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:54] __main__ INFO: [0mEpoch 102 Step 390/390 lr 0.010000 loss 0.0056 (0.0152) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:54] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:21:54] __main__ INFO: [0mVal 102
[32m[2022-06-11 10:21:55] __main__ INFO: [0mEpoch 102 loss 0.3157 acc@1 0.9243 acc@5 0.9984
[32m[2022-06-11 10:21:55] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:21:55] __main__ INFO: [0mTrain 103 39780
[32m[2022-06-11 10:21:59] __main__ INFO: [0mEpoch 103 Step 100/390 lr 0.010000 loss 0.0052 (0.0144) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:03] __main__ INFO: [0mEpoch 103 Step 200/390 lr 0.010000 loss 0.0146 (0.0152) acc@1 0.9922 (0.9956) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:07] __main__ INFO: [0mEpoch 103 Step 300/390 lr 0.010000 loss 0.0121 (0.0153) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:11] __main__ INFO: [0mEpoch 103 Step 390/390 lr 0.010000 loss 0.0110 (0.0150) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:11] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:22:11] __main__ INFO: [0mVal 103
[32m[2022-06-11 10:22:12] __main__ INFO: [0mEpoch 103 loss 0.3255 acc@1 0.9215 acc@5 0.9984
[32m[2022-06-11 10:22:12] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:22:12] __main__ INFO: [0mTrain 104 40170
[32m[2022-06-11 10:22:16] __main__ INFO: [0mEpoch 104 Step 100/390 lr 0.010000 loss 0.0080 (0.0146) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:20] __main__ INFO: [0mEpoch 104 Step 200/390 lr 0.010000 loss 0.0050 (0.0135) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:24] __main__ INFO: [0mEpoch 104 Step 300/390 lr 0.010000 loss 0.0224 (0.0131) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:27] __main__ INFO: [0mEpoch 104 Step 390/390 lr 0.010000 loss 0.0241 (0.0132) acc@1 0.9844 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:27] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:22:27] __main__ INFO: [0mVal 104
[32m[2022-06-11 10:22:28] __main__ INFO: [0mEpoch 104 loss 0.3291 acc@1 0.9229 acc@5 0.9981
[32m[2022-06-11 10:22:28] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:22:28] __main__ INFO: [0mTrain 105 40560
[32m[2022-06-11 10:22:32] __main__ INFO: [0mEpoch 105 Step 100/390 lr 0.010000 loss 0.0369 (0.0129) acc@1 0.9844 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:36] __main__ INFO: [0mEpoch 105 Step 200/390 lr 0.010000 loss 0.0176 (0.0128) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:40] __main__ INFO: [0mEpoch 105 Step 300/390 lr 0.010000 loss 0.0210 (0.0131) acc@1 0.9844 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:44] __main__ INFO: [0mEpoch 105 Step 390/390 lr 0.010000 loss 0.0223 (0.0136) acc@1 0.9922 (0.9966) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:44] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:22:44] __main__ INFO: [0mVal 105
[32m[2022-06-11 10:22:45] __main__ INFO: [0mEpoch 105 loss 0.3259 acc@1 0.9234 acc@5 0.9980
[32m[2022-06-11 10:22:45] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:22:45] __main__ INFO: [0mTrain 106 40950
[32m[2022-06-11 10:22:49] __main__ INFO: [0mEpoch 106 Step 100/390 lr 0.010000 loss 0.0076 (0.0118) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:53] __main__ INFO: [0mEpoch 106 Step 200/390 lr 0.010000 loss 0.0049 (0.0114) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:57] __main__ INFO: [0mEpoch 106 Step 300/390 lr 0.010000 loss 0.0101 (0.0121) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:00] __main__ INFO: [0mEpoch 106 Step 390/390 lr 0.010000 loss 0.0011 (0.0125) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:01] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:23:01] __main__ INFO: [0mVal 106
[32m[2022-06-11 10:23:02] __main__ INFO: [0mEpoch 106 loss 0.3271 acc@1 0.9249 acc@5 0.9978
[32m[2022-06-11 10:23:02] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:23:02] __main__ INFO: [0mTrain 107 41340
[32m[2022-06-11 10:23:06] __main__ INFO: [0mEpoch 107 Step 100/390 lr 0.010000 loss 0.0056 (0.0108) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:10] __main__ INFO: [0mEpoch 107 Step 200/390 lr 0.010000 loss 0.0076 (0.0114) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:14] __main__ INFO: [0mEpoch 107 Step 300/390 lr 0.010000 loss 0.0186 (0.0114) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:17] __main__ INFO: [0mEpoch 107 Step 390/390 lr 0.010000 loss 0.0027 (0.0117) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:17] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 10:23:17] __main__ INFO: [0mVal 107
[32m[2022-06-11 10:23:18] __main__ INFO: [0mEpoch 107 loss 0.3328 acc@1 0.9237 acc@5 0.9977
[32m[2022-06-11 10:23:18] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:23:18] __main__ INFO: [0mTrain 108 41730
[32m[2022-06-11 10:23:23] __main__ INFO: [0mEpoch 108 Step 100/390 lr 0.010000 loss 0.0044 (0.0143) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:26] __main__ INFO: [0mEpoch 108 Step 200/390 lr 0.010000 loss 0.0060 (0.0134) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:30] __main__ INFO: [0mEpoch 108 Step 300/390 lr 0.010000 loss 0.0194 (0.0128) acc@1 0.9922 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:34] __main__ INFO: [0mEpoch 108 Step 390/390 lr 0.010000 loss 0.0053 (0.0125) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:34] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:23:34] __main__ INFO: [0mVal 108
[32m[2022-06-11 10:23:35] __main__ INFO: [0mEpoch 108 loss 0.3304 acc@1 0.9239 acc@5 0.9977
[32m[2022-06-11 10:23:35] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:23:35] __main__ INFO: [0mTrain 109 42120
[32m[2022-06-11 10:23:39] __main__ INFO: [0mEpoch 109 Step 100/390 lr 0.010000 loss 0.0232 (0.0108) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:43] __main__ INFO: [0mEpoch 109 Step 200/390 lr 0.010000 loss 0.0030 (0.0118) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:47] __main__ INFO: [0mEpoch 109 Step 300/390 lr 0.010000 loss 0.0125 (0.0118) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:50] __main__ INFO: [0mEpoch 109 Step 390/390 lr 0.010000 loss 0.0112 (0.0122) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:51] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:23:51] __main__ INFO: [0mVal 109
[32m[2022-06-11 10:23:52] __main__ INFO: [0mEpoch 109 loss 0.3293 acc@1 0.9226 acc@5 0.9973
[32m[2022-06-11 10:23:52] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:23:52] __main__ INFO: [0mTrain 110 42510
[32m[2022-06-11 10:23:56] __main__ INFO: [0mEpoch 110 Step 100/390 lr 0.010000 loss 0.0127 (0.0104) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:00] __main__ INFO: [0mEpoch 110 Step 200/390 lr 0.010000 loss 0.0354 (0.0106) acc@1 0.9922 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:04] __main__ INFO: [0mEpoch 110 Step 300/390 lr 0.010000 loss 0.0714 (0.0113) acc@1 0.9766 (0.9972) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:07] __main__ INFO: [0mEpoch 110 Step 390/390 lr 0.010000 loss 0.0118 (0.0112) acc@1 0.9922 (0.9973) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:07] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:24:07] __main__ INFO: [0mVal 110
[32m[2022-06-11 10:24:08] __main__ INFO: [0mEpoch 110 loss 0.3347 acc@1 0.9238 acc@5 0.9981
[32m[2022-06-11 10:24:08] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:24:08] __main__ INFO: [0mTrain 111 42900
[32m[2022-06-11 10:24:12] __main__ INFO: [0mEpoch 111 Step 100/390 lr 0.010000 loss 0.0154 (0.0119) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:16] __main__ INFO: [0mEpoch 111 Step 200/390 lr 0.010000 loss 0.0149 (0.0116) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:20] __main__ INFO: [0mEpoch 111 Step 300/390 lr 0.010000 loss 0.0379 (0.0112) acc@1 0.9922 (0.9971) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:24] __main__ INFO: [0mEpoch 111 Step 390/390 lr 0.010000 loss 0.0229 (0.0114) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:24] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:24:24] __main__ INFO: [0mVal 111
[32m[2022-06-11 10:24:25] __main__ INFO: [0mEpoch 111 loss 0.3314 acc@1 0.9236 acc@5 0.9980
[32m[2022-06-11 10:24:25] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:24:25] __main__ INFO: [0mTrain 112 43290
[32m[2022-06-11 10:24:29] __main__ INFO: [0mEpoch 112 Step 100/390 lr 0.010000 loss 0.0054 (0.0097) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:33] __main__ INFO: [0mEpoch 112 Step 200/390 lr 0.010000 loss 0.0113 (0.0101) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:37] __main__ INFO: [0mEpoch 112 Step 300/390 lr 0.010000 loss 0.0124 (0.0100) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:40] __main__ INFO: [0mEpoch 112 Step 390/390 lr 0.010000 loss 0.0067 (0.0104) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:41] __main__ INFO: [0mElapsed 15.96
[32m[2022-06-11 10:24:41] __main__ INFO: [0mVal 112
[32m[2022-06-11 10:24:42] __main__ INFO: [0mEpoch 112 loss 0.3295 acc@1 0.9269 acc@5 0.9978
[32m[2022-06-11 10:24:42] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:24:42] __main__ INFO: [0mTrain 113 43680
[32m[2022-06-11 10:24:46] __main__ INFO: [0mEpoch 113 Step 100/390 lr 0.010000 loss 0.0218 (0.0108) acc@1 0.9922 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:50] __main__ INFO: [0mEpoch 113 Step 200/390 lr 0.010000 loss 0.0106 (0.0103) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:54] __main__ INFO: [0mEpoch 113 Step 300/390 lr 0.010000 loss 0.0092 (0.0103) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:58] __main__ INFO: [0mEpoch 113 Step 390/390 lr 0.010000 loss 0.0017 (0.0104) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:58] __main__ INFO: [0mElapsed 16.11
[32m[2022-06-11 10:24:58] __main__ INFO: [0mVal 113
[32m[2022-06-11 10:24:59] __main__ INFO: [0mEpoch 113 loss 0.3368 acc@1 0.9232 acc@5 0.9979
[32m[2022-06-11 10:24:59] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:24:59] __main__ INFO: [0mTrain 114 44070
[32m[2022-06-11 10:25:03] __main__ INFO: [0mEpoch 114 Step 100/390 lr 0.010000 loss 0.0130 (0.0112) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:07] __main__ INFO: [0mEpoch 114 Step 200/390 lr 0.010000 loss 0.0103 (0.0106) acc@1 0.9922 (0.9973) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:11] __main__ INFO: [0mEpoch 114 Step 300/390 lr 0.010000 loss 0.0056 (0.0104) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:14] __main__ INFO: [0mEpoch 114 Step 390/390 lr 0.010000 loss 0.0054 (0.0105) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:14] __main__ INFO: [0mElapsed 15.86
[32m[2022-06-11 10:25:14] __main__ INFO: [0mVal 114
[32m[2022-06-11 10:25:15] __main__ INFO: [0mEpoch 114 loss 0.3349 acc@1 0.9241 acc@5 0.9982
[32m[2022-06-11 10:25:15] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:25:15] __main__ INFO: [0mTrain 115 44460
[32m[2022-06-11 10:25:20] __main__ INFO: [0mEpoch 115 Step 100/390 lr 0.010000 loss 0.0038 (0.0092) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:23] __main__ INFO: [0mEpoch 115 Step 200/390 lr 0.010000 loss 0.0056 (0.0091) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:27] __main__ INFO: [0mEpoch 115 Step 300/390 lr 0.010000 loss 0.0078 (0.0093) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:31] __main__ INFO: [0mEpoch 115 Step 390/390 lr 0.010000 loss 0.0032 (0.0099) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:31] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:25:31] __main__ INFO: [0mVal 115
[32m[2022-06-11 10:25:32] __main__ INFO: [0mEpoch 115 loss 0.3382 acc@1 0.9232 acc@5 0.9980
[32m[2022-06-11 10:25:32] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:25:32] __main__ INFO: [0mTrain 116 44850
[32m[2022-06-11 10:25:36] __main__ INFO: [0mEpoch 116 Step 100/390 lr 0.010000 loss 0.0104 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:40] __main__ INFO: [0mEpoch 116 Step 200/390 lr 0.010000 loss 0.0052 (0.0097) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:44] __main__ INFO: [0mEpoch 116 Step 300/390 lr 0.010000 loss 0.0034 (0.0091) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:48] __main__ INFO: [0mEpoch 116 Step 390/390 lr 0.010000 loss 0.0038 (0.0094) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:48] __main__ INFO: [0mElapsed 16.21
[32m[2022-06-11 10:25:48] __main__ INFO: [0mVal 116
[32m[2022-06-11 10:25:49] __main__ INFO: [0mEpoch 116 loss 0.3378 acc@1 0.9256 acc@5 0.9981
[32m[2022-06-11 10:25:49] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:25:49] __main__ INFO: [0mTrain 117 45240
[32m[2022-06-11 10:25:53] __main__ INFO: [0mEpoch 117 Step 100/390 lr 0.010000 loss 0.0078 (0.0095) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:57] __main__ INFO: [0mEpoch 117 Step 200/390 lr 0.010000 loss 0.0057 (0.0097) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:02] __main__ INFO: [0mEpoch 117 Step 300/390 lr 0.010000 loss 0.0104 (0.0095) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:05] __main__ INFO: [0mEpoch 117 Step 390/390 lr 0.010000 loss 0.0465 (0.0098) acc@1 0.9766 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:05] __main__ INFO: [0mElapsed 16.14
[32m[2022-06-11 10:26:05] __main__ INFO: [0mVal 117
[32m[2022-06-11 10:26:06] __main__ INFO: [0mEpoch 117 loss 0.3420 acc@1 0.9234 acc@5 0.9975
[32m[2022-06-11 10:26:06] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 10:26:06] __main__ INFO: [0mTrain 118 45630
[32m[2022-06-11 10:26:10] __main__ INFO: [0mEpoch 118 Step 100/390 lr 0.010000 loss 0.0028 (0.0096) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:14] __main__ INFO: [0mEpoch 118 Step 200/390 lr 0.010000 loss 0.0137 (0.0091) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:18] __main__ INFO: [0mEpoch 118 Step 300/390 lr 0.010000 loss 0.0096 (0.0090) acc@1 0.9922 (0.9980) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:22] __main__ INFO: [0mEpoch 118 Step 390/390 lr 0.010000 loss 0.0078 (0.0092) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:22] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:26:22] __main__ INFO: [0mVal 118
[32m[2022-06-11 10:26:23] __main__ INFO: [0mEpoch 118 loss 0.3374 acc@1 0.9246 acc@5 0.9981
[32m[2022-06-11 10:26:23] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:26:23] __main__ INFO: [0mTrain 119 46020
[32m[2022-06-11 10:26:27] __main__ INFO: [0mEpoch 119 Step 100/390 lr 0.010000 loss 0.0241 (0.0096) acc@1 0.9922 (0.9981) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:31] __main__ INFO: [0mEpoch 119 Step 200/390 lr 0.010000 loss 0.0026 (0.0095) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:35] __main__ INFO: [0mEpoch 119 Step 300/390 lr 0.010000 loss 0.0066 (0.0094) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:38] __main__ INFO: [0mEpoch 119 Step 390/390 lr 0.010000 loss 0.0066 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:39] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 10:26:39] __main__ INFO: [0mVal 119
[32m[2022-06-11 10:26:40] __main__ INFO: [0mEpoch 119 loss 0.3417 acc@1 0.9243 acc@5 0.9982
[32m[2022-06-11 10:26:40] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:26:40] __main__ INFO: [0mTrain 120 46410
[32m[2022-06-11 10:26:44] __main__ INFO: [0mEpoch 120 Step 100/390 lr 0.010000 loss 0.0080 (0.0086) acc@1 0.9922 (0.9981) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:48] __main__ INFO: [0mEpoch 120 Step 200/390 lr 0.010000 loss 0.0103 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:52] __main__ INFO: [0mEpoch 120 Step 300/390 lr 0.010000 loss 0.0150 (0.0089) acc@1 0.9922 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:55] __main__ INFO: [0mEpoch 120 Step 390/390 lr 0.010000 loss 0.0097 (0.0091) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:55] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 10:26:55] __main__ INFO: [0mVal 120
[32m[2022-06-11 10:26:56] __main__ INFO: [0mEpoch 120 loss 0.3371 acc@1 0.9245 acc@5 0.9983
[32m[2022-06-11 10:26:56] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:26:56] __main__ INFO: [0mTrain 121 46800
[32m[2022-06-11 10:27:01] __main__ INFO: [0mEpoch 121 Step 100/390 lr 0.001000 loss 0.0052 (0.0080) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:04] __main__ INFO: [0mEpoch 121 Step 200/390 lr 0.001000 loss 0.0036 (0.0078) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:08] __main__ INFO: [0mEpoch 121 Step 300/390 lr 0.001000 loss 0.0076 (0.0074) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:12] __main__ INFO: [0mEpoch 121 Step 390/390 lr 0.001000 loss 0.0044 (0.0077) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:12] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:27:12] __main__ INFO: [0mVal 121
[32m[2022-06-11 10:27:13] __main__ INFO: [0mEpoch 121 loss 0.3372 acc@1 0.9249 acc@5 0.9982
[32m[2022-06-11 10:27:13] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:27:13] __main__ INFO: [0mTrain 122 47190
[32m[2022-06-11 10:27:17] __main__ INFO: [0mEpoch 122 Step 100/390 lr 0.001000 loss 0.0092 (0.0073) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:21] __main__ INFO: [0mEpoch 122 Step 200/390 lr 0.001000 loss 0.0058 (0.0075) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:25] __main__ INFO: [0mEpoch 122 Step 300/390 lr 0.001000 loss 0.0053 (0.0074) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:29] __main__ INFO: [0mEpoch 122 Step 390/390 lr 0.001000 loss 0.0069 (0.0075) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:29] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:27:29] __main__ INFO: [0mVal 122
[32m[2022-06-11 10:27:30] __main__ INFO: [0mEpoch 122 loss 0.3346 acc@1 0.9258 acc@5 0.9979
[32m[2022-06-11 10:27:30] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:27:30] __main__ INFO: [0mTrain 123 47580
[32m[2022-06-11 10:27:34] __main__ INFO: [0mEpoch 123 Step 100/390 lr 0.001000 loss 0.0082 (0.0062) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:38] __main__ INFO: [0mEpoch 123 Step 200/390 lr 0.001000 loss 0.0059 (0.0065) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:42] __main__ INFO: [0mEpoch 123 Step 300/390 lr 0.001000 loss 0.0020 (0.0070) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:45] __main__ INFO: [0mEpoch 123 Step 390/390 lr 0.001000 loss 0.0136 (0.0071) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:45] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:27:45] __main__ INFO: [0mVal 123
[32m[2022-06-11 10:27:46] __main__ INFO: [0mEpoch 123 loss 0.3341 acc@1 0.9247 acc@5 0.9980
[32m[2022-06-11 10:27:46] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:27:46] __main__ INFO: [0mTrain 124 47970
[32m[2022-06-11 10:27:50] __main__ INFO: [0mEpoch 124 Step 100/390 lr 0.001000 loss 0.0045 (0.0086) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:54] __main__ INFO: [0mEpoch 124 Step 200/390 lr 0.001000 loss 0.0027 (0.0076) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:58] __main__ INFO: [0mEpoch 124 Step 300/390 lr 0.001000 loss 0.0223 (0.0074) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:02] __main__ INFO: [0mEpoch 124 Step 390/390 lr 0.001000 loss 0.0039 (0.0073) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:02] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:28:02] __main__ INFO: [0mVal 124
[32m[2022-06-11 10:28:03] __main__ INFO: [0mEpoch 124 loss 0.3348 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:28:03] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:28:03] __main__ INFO: [0mTrain 125 48360
[32m[2022-06-11 10:28:07] __main__ INFO: [0mEpoch 125 Step 100/390 lr 0.001000 loss 0.0354 (0.0077) acc@1 0.9922 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:11] __main__ INFO: [0mEpoch 125 Step 200/390 lr 0.001000 loss 0.0044 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:15] __main__ INFO: [0mEpoch 125 Step 300/390 lr 0.001000 loss 0.0058 (0.0069) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:19] __main__ INFO: [0mEpoch 125 Step 390/390 lr 0.001000 loss 0.0120 (0.0071) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:19] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:28:19] __main__ INFO: [0mVal 125
[32m[2022-06-11 10:28:20] __main__ INFO: [0mEpoch 125 loss 0.3356 acc@1 0.9260 acc@5 0.9982
[32m[2022-06-11 10:28:20] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:28:20] __main__ INFO: [0mTrain 126 48750
[32m[2022-06-11 10:28:24] __main__ INFO: [0mEpoch 126 Step 100/390 lr 0.001000 loss 0.0039 (0.0072) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:28] __main__ INFO: [0mEpoch 126 Step 200/390 lr 0.001000 loss 0.0036 (0.0076) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:32] __main__ INFO: [0mEpoch 126 Step 300/390 lr 0.001000 loss 0.0049 (0.0076) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:36] __main__ INFO: [0mEpoch 126 Step 390/390 lr 0.001000 loss 0.0028 (0.0076) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:36] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:28:36] __main__ INFO: [0mVal 126
[32m[2022-06-11 10:28:37] __main__ INFO: [0mEpoch 126 loss 0.3332 acc@1 0.9261 acc@5 0.9980
[32m[2022-06-11 10:28:37] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:28:37] __main__ INFO: [0mTrain 127 49140
[32m[2022-06-11 10:28:41] __main__ INFO: [0mEpoch 127 Step 100/390 lr 0.001000 loss 0.0024 (0.0068) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:45] __main__ INFO: [0mEpoch 127 Step 200/390 lr 0.001000 loss 0.0094 (0.0069) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:49] __main__ INFO: [0mEpoch 127 Step 300/390 lr 0.001000 loss 0.0051 (0.0072) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:52] __main__ INFO: [0mEpoch 127 Step 390/390 lr 0.001000 loss 0.0033 (0.0071) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:52] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:28:52] __main__ INFO: [0mVal 127
[32m[2022-06-11 10:28:53] __main__ INFO: [0mEpoch 127 loss 0.3333 acc@1 0.9273 acc@5 0.9983
[32m[2022-06-11 10:28:53] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:28:53] __main__ INFO: [0mTrain 128 49530
[32m[2022-06-11 10:28:57] __main__ INFO: [0mEpoch 128 Step 100/390 lr 0.001000 loss 0.0028 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:02] __main__ INFO: [0mEpoch 128 Step 200/390 lr 0.001000 loss 0.0021 (0.0067) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:06] __main__ INFO: [0mEpoch 128 Step 300/390 lr 0.001000 loss 0.0020 (0.0066) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:09] __main__ INFO: [0mEpoch 128 Step 390/390 lr 0.001000 loss 0.0038 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:10] __main__ INFO: [0mElapsed 16.38
[32m[2022-06-11 10:29:10] __main__ INFO: [0mVal 128
[32m[2022-06-11 10:29:11] __main__ INFO: [0mEpoch 128 loss 0.3336 acc@1 0.9268 acc@5 0.9982
[32m[2022-06-11 10:29:11] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:29:11] __main__ INFO: [0mTrain 129 49920
[32m[2022-06-11 10:29:15] __main__ INFO: [0mEpoch 129 Step 100/390 lr 0.001000 loss 0.0073 (0.0072) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:19] __main__ INFO: [0mEpoch 129 Step 200/390 lr 0.001000 loss 0.0060 (0.0071) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:23] __main__ INFO: [0mEpoch 129 Step 300/390 lr 0.001000 loss 0.0015 (0.0067) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:26] __main__ INFO: [0mEpoch 129 Step 390/390 lr 0.001000 loss 0.0021 (0.0065) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:26] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:29:26] __main__ INFO: [0mVal 129
[32m[2022-06-11 10:29:27] __main__ INFO: [0mEpoch 129 loss 0.3328 acc@1 0.9267 acc@5 0.9982
[32m[2022-06-11 10:29:27] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:29:27] __main__ INFO: [0mTrain 130 50310
[32m[2022-06-11 10:29:31] __main__ INFO: [0mEpoch 130 Step 100/390 lr 0.001000 loss 0.0047 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:35] __main__ INFO: [0mEpoch 130 Step 200/390 lr 0.001000 loss 0.0048 (0.0056) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:40] __main__ INFO: [0mEpoch 130 Step 300/390 lr 0.001000 loss 0.0022 (0.0061) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:43] __main__ INFO: [0mEpoch 130 Step 390/390 lr 0.001000 loss 0.0029 (0.0061) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:43] __main__ INFO: [0mElapsed 16.03
[32m[2022-06-11 10:29:43] __main__ INFO: [0mVal 130
[32m[2022-06-11 10:29:44] __main__ INFO: [0mEpoch 130 loss 0.3332 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:29:44] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:29:44] __main__ INFO: [0mTrain 131 50700
[32m[2022-06-11 10:29:48] __main__ INFO: [0mEpoch 131 Step 100/390 lr 0.001000 loss 0.0112 (0.0061) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:52] __main__ INFO: [0mEpoch 131 Step 200/390 lr 0.001000 loss 0.0026 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:56] __main__ INFO: [0mEpoch 131 Step 300/390 lr 0.001000 loss 0.0196 (0.0068) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:00] __main__ INFO: [0mEpoch 131 Step 390/390 lr 0.001000 loss 0.0069 (0.0068) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:00] __main__ INFO: [0mElapsed 15.98
[32m[2022-06-11 10:30:00] __main__ INFO: [0mVal 131
[32m[2022-06-11 10:30:01] __main__ INFO: [0mEpoch 131 loss 0.3339 acc@1 0.9273 acc@5 0.9983
[32m[2022-06-11 10:30:01] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:30:01] __main__ INFO: [0mTrain 132 51090
[32m[2022-06-11 10:30:05] __main__ INFO: [0mEpoch 132 Step 100/390 lr 0.001000 loss 0.0064 (0.0062) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:09] __main__ INFO: [0mEpoch 132 Step 200/390 lr 0.001000 loss 0.0073 (0.0064) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:13] __main__ INFO: [0mEpoch 132 Step 300/390 lr 0.001000 loss 0.0027 (0.0063) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:17] __main__ INFO: [0mEpoch 132 Step 390/390 lr 0.001000 loss 0.0036 (0.0065) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:17] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:30:17] __main__ INFO: [0mVal 132
[32m[2022-06-11 10:30:18] __main__ INFO: [0mEpoch 132 loss 0.3362 acc@1 0.9260 acc@5 0.9981
[32m[2022-06-11 10:30:18] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:30:18] __main__ INFO: [0mTrain 133 51480
[32m[2022-06-11 10:30:22] __main__ INFO: [0mEpoch 133 Step 100/390 lr 0.001000 loss 0.0055 (0.0067) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:26] __main__ INFO: [0mEpoch 133 Step 200/390 lr 0.001000 loss 0.0054 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:30] __main__ INFO: [0mEpoch 133 Step 300/390 lr 0.001000 loss 0.0036 (0.0062) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:33] __main__ INFO: [0mEpoch 133 Step 390/390 lr 0.001000 loss 0.0072 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:33] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:30:33] __main__ INFO: [0mVal 133
[32m[2022-06-11 10:30:34] __main__ INFO: [0mEpoch 133 loss 0.3328 acc@1 0.9266 acc@5 0.9982
[32m[2022-06-11 10:30:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:30:34] __main__ INFO: [0mTrain 134 51870
[32m[2022-06-11 10:30:38] __main__ INFO: [0mEpoch 134 Step 100/390 lr 0.001000 loss 0.0065 (0.0062) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:42] __main__ INFO: [0mEpoch 134 Step 200/390 lr 0.001000 loss 0.0072 (0.0060) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:46] __main__ INFO: [0mEpoch 134 Step 300/390 lr 0.001000 loss 0.0050 (0.0063) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:50] __main__ INFO: [0mEpoch 134 Step 390/390 lr 0.001000 loss 0.0045 (0.0062) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:50] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:30:50] __main__ INFO: [0mVal 134
[32m[2022-06-11 10:30:51] __main__ INFO: [0mEpoch 134 loss 0.3339 acc@1 0.9271 acc@5 0.9981
[32m[2022-06-11 10:30:51] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:30:51] __main__ INFO: [0mTrain 135 52260
[32m[2022-06-11 10:30:55] __main__ INFO: [0mEpoch 135 Step 100/390 lr 0.001000 loss 0.0108 (0.0056) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:59] __main__ INFO: [0mEpoch 135 Step 200/390 lr 0.001000 loss 0.0101 (0.0058) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:03] __main__ INFO: [0mEpoch 135 Step 300/390 lr 0.001000 loss 0.0070 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:07] __main__ INFO: [0mEpoch 135 Step 390/390 lr 0.001000 loss 0.0052 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:07] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:31:07] __main__ INFO: [0mVal 135
[32m[2022-06-11 10:31:08] __main__ INFO: [0mEpoch 135 loss 0.3347 acc@1 0.9272 acc@5 0.9982
[32m[2022-06-11 10:31:08] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:31:08] __main__ INFO: [0mTrain 136 52650
[32m[2022-06-11 10:31:12] __main__ INFO: [0mEpoch 136 Step 100/390 lr 0.001000 loss 0.0041 (0.0059) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:16] __main__ INFO: [0mEpoch 136 Step 200/390 lr 0.001000 loss 0.0026 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:20] __main__ INFO: [0mEpoch 136 Step 300/390 lr 0.001000 loss 0.0223 (0.0063) acc@1 0.9922 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:23] __main__ INFO: [0mEpoch 136 Step 390/390 lr 0.001000 loss 0.0054 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:23] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:31:23] __main__ INFO: [0mVal 136
[32m[2022-06-11 10:31:24] __main__ INFO: [0mEpoch 136 loss 0.3359 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:31:24] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:31:24] __main__ INFO: [0mTrain 137 53040
[32m[2022-06-11 10:31:28] __main__ INFO: [0mEpoch 137 Step 100/390 lr 0.001000 loss 0.0048 (0.0056) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:32] __main__ INFO: [0mEpoch 137 Step 200/390 lr 0.001000 loss 0.0014 (0.0056) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:36] __main__ INFO: [0mEpoch 137 Step 300/390 lr 0.001000 loss 0.0034 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:40] __main__ INFO: [0mEpoch 137 Step 390/390 lr 0.001000 loss 0.0210 (0.0057) acc@1 0.9844 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:40] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:31:40] __main__ INFO: [0mVal 137
[32m[2022-06-11 10:31:41] __main__ INFO: [0mEpoch 137 loss 0.3332 acc@1 0.9271 acc@5 0.9982
[32m[2022-06-11 10:31:41] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:31:41] __main__ INFO: [0mTrain 138 53430
[32m[2022-06-11 10:31:45] __main__ INFO: [0mEpoch 138 Step 100/390 lr 0.001000 loss 0.0024 (0.0071) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:49] __main__ INFO: [0mEpoch 138 Step 200/390 lr 0.001000 loss 0.0046 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:53] __main__ INFO: [0mEpoch 138 Step 300/390 lr 0.001000 loss 0.0037 (0.0070) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:57] __main__ INFO: [0mEpoch 138 Step 390/390 lr 0.001000 loss 0.0058 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:57] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 10:31:57] __main__ INFO: [0mVal 138
[32m[2022-06-11 10:31:58] __main__ INFO: [0mEpoch 138 loss 0.3346 acc@1 0.9269 acc@5 0.9982
[32m[2022-06-11 10:31:58] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:31:58] __main__ INFO: [0mTrain 139 53820
[32m[2022-06-11 10:32:02] __main__ INFO: [0mEpoch 139 Step 100/390 lr 0.001000 loss 0.0025 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:06] __main__ INFO: [0mEpoch 139 Step 200/390 lr 0.001000 loss 0.0043 (0.0058) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:10] __main__ INFO: [0mEpoch 139 Step 300/390 lr 0.001000 loss 0.0031 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:13] __main__ INFO: [0mEpoch 139 Step 390/390 lr 0.001000 loss 0.0043 (0.0060) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:13] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:32:13] __main__ INFO: [0mVal 139
[32m[2022-06-11 10:32:14] __main__ INFO: [0mEpoch 139 loss 0.3363 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:32:14] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:32:14] __main__ INFO: [0mTrain 140 54210
[32m[2022-06-11 10:32:19] __main__ INFO: [0mEpoch 140 Step 100/390 lr 0.001000 loss 0.0022 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:22] __main__ INFO: [0mEpoch 140 Step 200/390 lr 0.001000 loss 0.0044 (0.0063) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:26] __main__ INFO: [0mEpoch 140 Step 300/390 lr 0.001000 loss 0.0017 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:30] __main__ INFO: [0mEpoch 140 Step 390/390 lr 0.001000 loss 0.0125 (0.0062) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:30] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:32:30] __main__ INFO: [0mVal 140
[32m[2022-06-11 10:32:31] __main__ INFO: [0mEpoch 140 loss 0.3373 acc@1 0.9267 acc@5 0.9981
[32m[2022-06-11 10:32:31] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:32:31] __main__ INFO: [0mTrain 141 54600
[32m[2022-06-11 10:32:35] __main__ INFO: [0mEpoch 141 Step 100/390 lr 0.001000 loss 0.0035 (0.0053) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:39] __main__ INFO: [0mEpoch 141 Step 200/390 lr 0.001000 loss 0.0054 (0.0061) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:43] __main__ INFO: [0mEpoch 141 Step 300/390 lr 0.001000 loss 0.0061 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:47] __main__ INFO: [0mEpoch 141 Step 390/390 lr 0.001000 loss 0.0043 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:47] __main__ INFO: [0mElapsed 16.02
[32m[2022-06-11 10:32:47] __main__ INFO: [0mVal 141
[32m[2022-06-11 10:32:48] __main__ INFO: [0mEpoch 141 loss 0.3360 acc@1 0.9276 acc@5 0.9981
[32m[2022-06-11 10:32:48] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:32:48] __main__ INFO: [0mTrain 142 54990
[32m[2022-06-11 10:32:52] __main__ INFO: [0mEpoch 142 Step 100/390 lr 0.001000 loss 0.0058 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:56] __main__ INFO: [0mEpoch 142 Step 200/390 lr 0.001000 loss 0.0057 (0.0064) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:00] __main__ INFO: [0mEpoch 142 Step 300/390 lr 0.001000 loss 0.0074 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:04] __main__ INFO: [0mEpoch 142 Step 390/390 lr 0.001000 loss 0.0032 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:04] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:33:04] __main__ INFO: [0mVal 142
[32m[2022-06-11 10:33:05] __main__ INFO: [0mEpoch 142 loss 0.3345 acc@1 0.9268 acc@5 0.9981
[32m[2022-06-11 10:33:05] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:05] __main__ INFO: [0mTrain 143 55380
[32m[2022-06-11 10:33:09] __main__ INFO: [0mEpoch 143 Step 100/390 lr 0.001000 loss 0.0029 (0.0059) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:13] __main__ INFO: [0mEpoch 143 Step 200/390 lr 0.001000 loss 0.0023 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:17] __main__ INFO: [0mEpoch 143 Step 300/390 lr 0.001000 loss 0.0222 (0.0058) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:20] __main__ INFO: [0mEpoch 143 Step 390/390 lr 0.001000 loss 0.0018 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:21] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:33:21] __main__ INFO: [0mVal 143
[32m[2022-06-11 10:33:22] __main__ INFO: [0mEpoch 143 loss 0.3364 acc@1 0.9265 acc@5 0.9980
[32m[2022-06-11 10:33:22] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:22] __main__ INFO: [0mTrain 144 55770
[32m[2022-06-11 10:33:26] __main__ INFO: [0mEpoch 144 Step 100/390 lr 0.001000 loss 0.0027 (0.0057) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:30] __main__ INFO: [0mEpoch 144 Step 200/390 lr 0.001000 loss 0.0042 (0.0064) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:34] __main__ INFO: [0mEpoch 144 Step 300/390 lr 0.001000 loss 0.0040 (0.0061) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:37] __main__ INFO: [0mEpoch 144 Step 390/390 lr 0.001000 loss 0.0034 (0.0059) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:37] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:33:37] __main__ INFO: [0mVal 144
[32m[2022-06-11 10:33:38] __main__ INFO: [0mEpoch 144 loss 0.3348 acc@1 0.9269 acc@5 0.9981
[32m[2022-06-11 10:33:38] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:33:38] __main__ INFO: [0mTrain 145 56160
[32m[2022-06-11 10:33:42] __main__ INFO: [0mEpoch 145 Step 100/390 lr 0.001000 loss 0.0053 (0.0065) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:46] __main__ INFO: [0mEpoch 145 Step 200/390 lr 0.001000 loss 0.0062 (0.0066) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:50] __main__ INFO: [0mEpoch 145 Step 300/390 lr 0.001000 loss 0.0048 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:54] __main__ INFO: [0mEpoch 145 Step 390/390 lr 0.001000 loss 0.0046 (0.0064) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:54] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:33:54] __main__ INFO: [0mVal 145
[32m[2022-06-11 10:33:55] __main__ INFO: [0mEpoch 145 loss 0.3356 acc@1 0.9269 acc@5 0.9979
[32m[2022-06-11 10:33:55] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:55] __main__ INFO: [0mTrain 146 56550
[32m[2022-06-11 10:33:59] __main__ INFO: [0mEpoch 146 Step 100/390 lr 0.001000 loss 0.0037 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:03] __main__ INFO: [0mEpoch 146 Step 200/390 lr 0.001000 loss 0.0009 (0.0059) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:07] __main__ INFO: [0mEpoch 146 Step 300/390 lr 0.001000 loss 0.0023 (0.0059) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:10] __main__ INFO: [0mEpoch 146 Step 390/390 lr 0.001000 loss 0.0045 (0.0058) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:11] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:34:11] __main__ INFO: [0mVal 146
[32m[2022-06-11 10:34:12] __main__ INFO: [0mEpoch 146 loss 0.3340 acc@1 0.9270 acc@5 0.9979
[32m[2022-06-11 10:34:12] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:34:12] __main__ INFO: [0mTrain 147 56940
[32m[2022-06-11 10:34:16] __main__ INFO: [0mEpoch 147 Step 100/390 lr 0.001000 loss 0.0075 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:20] __main__ INFO: [0mEpoch 147 Step 200/390 lr 0.001000 loss 0.0040 (0.0056) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:24] __main__ INFO: [0mEpoch 147 Step 300/390 lr 0.001000 loss 0.0028 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:27] __main__ INFO: [0mEpoch 147 Step 390/390 lr 0.001000 loss 0.0010 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:27] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:34:27] __main__ INFO: [0mVal 147
[32m[2022-06-11 10:34:28] __main__ INFO: [0mEpoch 147 loss 0.3350 acc@1 0.9273 acc@5 0.9981
[32m[2022-06-11 10:34:28] __main__ INFO: [0mElapsed 0.88
[32m[2022-06-11 10:34:28] __main__ INFO: [0mTrain 148 57330
[32m[2022-06-11 10:34:32] __main__ INFO: [0mEpoch 148 Step 100/390 lr 0.001000 loss 0.0044 (0.0063) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:36] __main__ INFO: [0mEpoch 148 Step 200/390 lr 0.001000 loss 0.0027 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:40] __main__ INFO: [0mEpoch 148 Step 300/390 lr 0.001000 loss 0.0059 (0.0057) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:44] __main__ INFO: [0mEpoch 148 Step 390/390 lr 0.001000 loss 0.0237 (0.0059) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:44] __main__ INFO: [0mElapsed 16.07
[32m[2022-06-11 10:34:44] __main__ INFO: [0mVal 148
[32m[2022-06-11 10:34:45] __main__ INFO: [0mEpoch 148 loss 0.3374 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:34:45] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:34:45] __main__ INFO: [0mTrain 149 57720
[32m[2022-06-11 10:34:49] __main__ INFO: [0mEpoch 149 Step 100/390 lr 0.001000 loss 0.0026 (0.0054) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:53] __main__ INFO: [0mEpoch 149 Step 200/390 lr 0.001000 loss 0.0056 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:57] __main__ INFO: [0mEpoch 149 Step 300/390 lr 0.001000 loss 0.0048 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:01] __main__ INFO: [0mEpoch 149 Step 390/390 lr 0.001000 loss 0.0046 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:01] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:35:01] __main__ INFO: [0mVal 149
[32m[2022-06-11 10:35:02] __main__ INFO: [0mEpoch 149 loss 0.3367 acc@1 0.9266 acc@5 0.9983
[32m[2022-06-11 10:35:02] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:35:02] __main__ INFO: [0mTrain 150 58110
[32m[2022-06-11 10:35:06] __main__ INFO: [0mEpoch 150 Step 100/390 lr 0.001000 loss 0.0055 (0.0053) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:10] __main__ INFO: [0mEpoch 150 Step 200/390 lr 0.001000 loss 0.0041 (0.0051) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:14] __main__ INFO: [0mEpoch 150 Step 300/390 lr 0.001000 loss 0.0046 (0.0053) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:17] __main__ INFO: [0mEpoch 150 Step 390/390 lr 0.001000 loss 0.0030 (0.0055) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:18] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 10:35:18] __main__ INFO: [0mVal 150
[32m[2022-06-11 10:35:19] __main__ INFO: [0mEpoch 150 loss 0.3352 acc@1 0.9272 acc@5 0.9981
[32m[2022-06-11 10:35:19] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:35:19] __main__ INFO: [0mTrain 151 58500
[32m[2022-06-11 10:35:23] __main__ INFO: [0mEpoch 151 Step 100/390 lr 0.001000 loss 0.0057 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:27] __main__ INFO: [0mEpoch 151 Step 200/390 lr 0.001000 loss 0.0042 (0.0056) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:31] __main__ INFO: [0mEpoch 151 Step 300/390 lr 0.001000 loss 0.0042 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:34] __main__ INFO: [0mEpoch 151 Step 390/390 lr 0.001000 loss 0.0060 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:34] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 10:35:34] __main__ INFO: [0mVal 151
[32m[2022-06-11 10:35:36] __main__ INFO: [0mEpoch 151 loss 0.3377 acc@1 0.9272 acc@5 0.9981
[32m[2022-06-11 10:35:36] __main__ INFO: [0mElapsed 1.04
[32m[2022-06-11 10:35:36] __main__ INFO: [0mTrain 152 58890
[32m[2022-06-11 10:35:40] __main__ INFO: [0mEpoch 152 Step 100/390 lr 0.001000 loss 0.0056 (0.0056) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:44] __main__ INFO: [0mEpoch 152 Step 200/390 lr 0.001000 loss 0.0035 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:48] __main__ INFO: [0mEpoch 152 Step 300/390 lr 0.001000 loss 0.0013 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:51] __main__ INFO: [0mEpoch 152 Step 390/390 lr 0.001000 loss 0.0038 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:51] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:35:51] __main__ INFO: [0mVal 152
[32m[2022-06-11 10:35:52] __main__ INFO: [0mEpoch 152 loss 0.3377 acc@1 0.9270 acc@5 0.9982
[32m[2022-06-11 10:35:52] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:35:52] __main__ INFO: [0mTrain 153 59280
[32m[2022-06-11 10:35:56] __main__ INFO: [0mEpoch 153 Step 100/390 lr 0.001000 loss 0.0153 (0.0063) acc@1 0.9922 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:00] __main__ INFO: [0mEpoch 153 Step 200/390 lr 0.001000 loss 0.0035 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:04] __main__ INFO: [0mEpoch 153 Step 300/390 lr 0.001000 loss 0.0062 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:08] __main__ INFO: [0mEpoch 153 Step 390/390 lr 0.001000 loss 0.0128 (0.0057) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:08] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:36:08] __main__ INFO: [0mVal 153
[32m[2022-06-11 10:36:09] __main__ INFO: [0mEpoch 153 loss 0.3357 acc@1 0.9265 acc@5 0.9983
[32m[2022-06-11 10:36:09] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:36:09] __main__ INFO: [0mTrain 154 59670
[32m[2022-06-11 10:36:13] __main__ INFO: [0mEpoch 154 Step 100/390 lr 0.001000 loss 0.0048 (0.0051) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:17] __main__ INFO: [0mEpoch 154 Step 200/390 lr 0.001000 loss 0.0085 (0.0051) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:21] __main__ INFO: [0mEpoch 154 Step 300/390 lr 0.001000 loss 0.0046 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:25] __main__ INFO: [0mEpoch 154 Step 390/390 lr 0.001000 loss 0.0077 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:25] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:36:25] __main__ INFO: [0mVal 154
[32m[2022-06-11 10:36:26] __main__ INFO: [0mEpoch 154 loss 0.3375 acc@1 0.9269 acc@5 0.9982
[32m[2022-06-11 10:36:26] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:36:26] __main__ INFO: [0mTrain 155 60060
[32m[2022-06-11 10:36:30] __main__ INFO: [0mEpoch 155 Step 100/390 lr 0.001000 loss 0.0028 (0.0061) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:34] __main__ INFO: [0mEpoch 155 Step 200/390 lr 0.001000 loss 0.0175 (0.0060) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:38] __main__ INFO: [0mEpoch 155 Step 300/390 lr 0.001000 loss 0.0041 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:41] __main__ INFO: [0mEpoch 155 Step 390/390 lr 0.001000 loss 0.0038 (0.0059) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:42] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:36:42] __main__ INFO: [0mVal 155
[32m[2022-06-11 10:36:42] __main__ INFO: [0mEpoch 155 loss 0.3379 acc@1 0.9256 acc@5 0.9981
[32m[2022-06-11 10:36:42] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:36:42] __main__ INFO: [0mTrain 156 60450
[32m[2022-06-11 10:36:47] __main__ INFO: [0mEpoch 156 Step 100/390 lr 0.001000 loss 0.0027 (0.0050) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:50] __main__ INFO: [0mEpoch 156 Step 200/390 lr 0.001000 loss 0.0033 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:54] __main__ INFO: [0mEpoch 156 Step 300/390 lr 0.001000 loss 0.0081 (0.0059) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:58] __main__ INFO: [0mEpoch 156 Step 390/390 lr 0.001000 loss 0.0036 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:58] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 10:36:58] __main__ INFO: [0mVal 156
[32m[2022-06-11 10:36:59] __main__ INFO: [0mEpoch 156 loss 0.3391 acc@1 0.9267 acc@5 0.9980
[32m[2022-06-11 10:36:59] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:36:59] __main__ INFO: [0mTrain 157 60840
[32m[2022-06-11 10:37:03] __main__ INFO: [0mEpoch 157 Step 100/390 lr 0.001000 loss 0.0097 (0.0055) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:07] __main__ INFO: [0mEpoch 157 Step 200/390 lr 0.001000 loss 0.0103 (0.0053) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:11] __main__ INFO: [0mEpoch 157 Step 300/390 lr 0.001000 loss 0.0024 (0.0054) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:15] __main__ INFO: [0mEpoch 157 Step 390/390 lr 0.001000 loss 0.0007 (0.0054) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:15] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:37:15] __main__ INFO: [0mVal 157
[32m[2022-06-11 10:37:16] __main__ INFO: [0mEpoch 157 loss 0.3397 acc@1 0.9260 acc@5 0.9981
[32m[2022-06-11 10:37:16] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:37:16] __main__ INFO: [0mTrain 158 61230
[32m[2022-06-11 10:37:20] __main__ INFO: [0mEpoch 158 Step 100/390 lr 0.001000 loss 0.0058 (0.0058) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:24] __main__ INFO: [0mEpoch 158 Step 200/390 lr 0.001000 loss 0.0295 (0.0059) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:28] __main__ INFO: [0mEpoch 158 Step 300/390 lr 0.001000 loss 0.0022 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:31] __main__ INFO: [0mEpoch 158 Step 390/390 lr 0.001000 loss 0.0085 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:31] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:37:31] __main__ INFO: [0mVal 158
[32m[2022-06-11 10:37:32] __main__ INFO: [0mEpoch 158 loss 0.3394 acc@1 0.9261 acc@5 0.9982
[32m[2022-06-11 10:37:32] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:37:32] __main__ INFO: [0mTrain 159 61620
[32m[2022-06-11 10:37:37] __main__ INFO: [0mEpoch 159 Step 100/390 lr 0.001000 loss 0.0038 (0.0056) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:41] __main__ INFO: [0mEpoch 159 Step 200/390 lr 0.001000 loss 0.0041 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:45] __main__ INFO: [0mEpoch 159 Step 300/390 lr 0.001000 loss 0.0081 (0.0055) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:48] __main__ INFO: [0mEpoch 159 Step 390/390 lr 0.001000 loss 0.0014 (0.0055) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:48] __main__ INFO: [0mElapsed 15.96
[32m[2022-06-11 10:37:48] __main__ INFO: [0mVal 159
[32m[2022-06-11 10:37:49] __main__ INFO: [0mEpoch 159 loss 0.3392 acc@1 0.9253 acc@5 0.9982
[32m[2022-06-11 10:37:49] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:37:49] __main__ INFO: [0mTrain 160 62010
[32m[2022-06-11 10:37:54] __main__ INFO: [0mEpoch 160 Step 100/390 lr 0.001000 loss 0.0034 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:58] __main__ INFO: [0mEpoch 160 Step 200/390 lr 0.001000 loss 0.0026 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:02] __main__ INFO: [0mEpoch 160 Step 300/390 lr 0.001000 loss 0.0014 (0.0051) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:05] __main__ INFO: [0mEpoch 160 Step 390/390 lr 0.001000 loss 0.0021 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:05] __main__ INFO: [0mElapsed 16.19
[32m[2022-06-11 10:38:05] __main__ INFO: [0mVal 160
[32m[2022-06-11 10:38:07] __main__ INFO: [0mEpoch 160 loss 0.3397 acc@1 0.9269 acc@5 0.9983
[32m[2022-06-11 10:38:07] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:38:07] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00160.pth
[32m[2022-06-11 10:40:57] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:40:57] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:41:01] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:41:01] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:41:01] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:41:02] __main__ INFO: [0mEpoch 0 loss 16761.8818 acc@1 0.1000 acc@5 0.5000
[32m[2022-06-11 10:41:02] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:41:02] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:41:06] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 2.0921 (3.0445) acc@1 0.2266 (0.1339) acc@5 0.7344 (0.5749)
[32m[2022-06-11 10:41:10] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 1.9818 (2.5336) acc@1 0.2109 (0.1777) acc@5 0.7891 (0.6750)
[32m[2022-06-11 10:41:14] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 1.8391 (2.3184) acc@1 0.3594 (0.2121) acc@5 0.8359 (0.7251)
[32m[2022-06-11 10:41:18] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 1.7720 (2.2011) acc@1 0.3672 (0.2393) acc@5 0.8984 (0.7548)
[32m[2022-06-11 10:41:18] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:41:18] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:41:19] __main__ INFO: [0mEpoch 1 loss 1.7234 acc@1 0.3559 acc@5 0.8697
[32m[2022-06-11 10:41:19] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:41:19] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:41:39] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:41:39] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:41:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:41:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:41:56] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:41:56] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:42:00] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:42:00] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:42:00] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:42:01] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 10:42:01] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:42:01] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:42:05] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6691 (1.1213) acc@1 0.8047 (0.6034) acc@5 0.9844 (0.9481)
[32m[2022-06-11 10:42:09] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7345 (0.9261) acc@1 0.7266 (0.6763) acc@5 0.9766 (0.9654)
[32m[2022-06-11 10:42:13] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6907 (0.8324) acc@1 0.7344 (0.7102) acc@5 1.0000 (0.9728)
[32m[2022-06-11 10:42:17] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5141 (0.7787) acc@1 0.8203 (0.7294) acc@5 0.9922 (0.9766)
[32m[2022-06-11 10:42:17] __main__ INFO: [0mElapsed 15.89
[32m[2022-06-11 10:42:17] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:42:18] __main__ INFO: [0mEpoch 1 loss 0.9312 acc@1 0.7042 acc@5 0.9808
[32m[2022-06-11 10:42:18] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:42:18] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:42:22] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.5724 (0.5403) acc@1 0.7891 (0.8145) acc@5 0.9844 (0.9914)
[32m[2022-06-11 10:42:26] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4236 (0.5283) acc@1 0.8359 (0.8182) acc@5 0.9922 (0.9916)
[32m[2022-06-11 10:42:30] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3453 (0.5233) acc@1 0.9062 (0.8201) acc@5 1.0000 (0.9918)
[32m[2022-06-11 10:42:33] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4180 (0.5189) acc@1 0.8438 (0.8216) acc@5 1.0000 (0.9917)
[32m[2022-06-11 10:42:33] __main__ INFO: [0mElapsed 15.38
[32m[2022-06-11 10:42:33] __main__ INFO: [0mVal 2
[32m[2022-06-11 10:42:34] __main__ INFO: [0mEpoch 2 loss 0.6407 acc@1 0.7932 acc@5 0.9863
[32m[2022-06-11 10:42:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:42:34] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 10:42:38] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4105 (0.4575) acc@1 0.8438 (0.8416) acc@5 0.9922 (0.9945)
[32m[2022-06-11 10:42:43] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4895 (0.4595) acc@1 0.8438 (0.8409) acc@5 1.0000 (0.9937)
[32m[2022-06-11 10:42:46] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6639 (0.4528) acc@1 0.7578 (0.8445) acc@5 0.9844 (0.9935)
[32m[2022-06-11 10:42:50] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5132 (0.4524) acc@1 0.8047 (0.8439) acc@5 0.9922 (0.9934)
[32m[2022-06-11 10:42:50] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:42:50] __main__ INFO: [0mVal 3
[32m[2022-06-11 10:42:51] __main__ INFO: [0mEpoch 3 loss 0.6262 acc@1 0.7988 acc@5 0.9880
[32m[2022-06-11 10:42:51] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:42:51] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 10:42:55] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4061 (0.4096) acc@1 0.8516 (0.8577) acc@5 1.0000 (0.9963)
[32m[2022-06-11 10:42:59] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4589 (0.4128) acc@1 0.8750 (0.8575) acc@5 0.9922 (0.9953)
[32m[2022-06-11 10:43:03] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.5466 (0.4142) acc@1 0.8359 (0.8571) acc@5 0.9922 (0.9949)
[32m[2022-06-11 10:43:07] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3279 (0.4123) acc@1 0.8906 (0.8575) acc@5 0.9922 (0.9947)
[32m[2022-06-11 10:43:07] __main__ INFO: [0mElapsed 15.88
[32m[2022-06-11 10:43:07] __main__ INFO: [0mVal 4
[32m[2022-06-11 10:43:08] __main__ INFO: [0mEpoch 4 loss 0.6014 acc@1 0.8002 acc@5 0.9893
[32m[2022-06-11 10:43:08] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:43:08] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 10:43:12] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4272 (0.3719) acc@1 0.8750 (0.8752) acc@5 0.9922 (0.9950)
[32m[2022-06-11 10:43:16] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3475 (0.3740) acc@1 0.8750 (0.8723) acc@5 0.9922 (0.9954)
[32m[2022-06-11 10:43:20] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2680 (0.3766) acc@1 0.9141 (0.8716) acc@5 0.9922 (0.9949)
[32m[2022-06-11 10:43:24] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3758 (0.3763) acc@1 0.8906 (0.8713) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:43:24] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:43:24] __main__ INFO: [0mVal 5
[32m[2022-06-11 10:43:25] __main__ INFO: [0mEpoch 5 loss 0.5451 acc@1 0.8250 acc@5 0.9886
[32m[2022-06-11 10:43:25] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:43:25] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 10:43:29] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4855 (0.3594) acc@1 0.8516 (0.8762) acc@5 1.0000 (0.9962)
[32m[2022-06-11 10:43:33] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2561 (0.3590) acc@1 0.9062 (0.8753) acc@5 1.0000 (0.9959)
[32m[2022-06-11 10:43:37] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3281 (0.3557) acc@1 0.8750 (0.8768) acc@5 0.9922 (0.9957)
[32m[2022-06-11 10:43:40] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3798 (0.3583) acc@1 0.8828 (0.8751) acc@5 1.0000 (0.9957)
[32m[2022-06-11 10:43:40] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:43:40] __main__ INFO: [0mVal 6
[32m[2022-06-11 10:43:41] __main__ INFO: [0mEpoch 6 loss 0.4687 acc@1 0.8438 acc@5 0.9932
[32m[2022-06-11 10:43:41] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:43:41] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 10:43:45] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4040 (0.3372) acc@1 0.8516 (0.8834) acc@5 1.0000 (0.9959)
[32m[2022-06-11 10:43:49] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2708 (0.3400) acc@1 0.9141 (0.8826) acc@5 0.9922 (0.9959)
[32m[2022-06-11 10:56:27] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:56:27] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:56:31] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:56:31] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:56:31] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:56:32] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 10:56:32] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:56:32] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:56:36] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6951 (1.1207) acc@1 0.7891 (0.6041) acc@5 0.9922 (0.9481)
[32m[2022-06-11 10:56:40] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6980 (0.9291) acc@1 0.7578 (0.6738) acc@5 0.9922 (0.9647)
[32m[2022-06-11 10:56:44] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6337 (0.8341) acc@1 0.7734 (0.7078) acc@5 1.0000 (0.9726)
[32m[2022-06-11 10:56:47] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5439 (0.7788) acc@1 0.8359 (0.7276) acc@5 1.0000 (0.9764)
[32m[2022-06-11 10:56:47] __main__ INFO: [0mElapsed 15.91
[32m[2022-06-11 10:56:47] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:56:48] __main__ INFO: [0mEpoch 1 loss 0.8453 acc@1 0.7230 acc@5 0.9805
[32m[2022-06-11 10:56:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:56:48] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:56:53] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6121 (0.5395) acc@1 0.7969 (0.8155) acc@5 0.9844 (0.9912)
[32m[2022-06-11 10:56:57] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4845 (0.5274) acc@1 0.8438 (0.8182) acc@5 0.9922 (0.9912)
[32m[2022-06-11 10:57:01] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3920 (0.5210) acc@1 0.8828 (0.8208) acc@5 0.9922 (0.9913)
[32m[2022-06-11 10:57:04] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.3620 (0.5155) acc@1 0.8672 (0.8228) acc@5 1.0000 (0.9915)
[32m[2022-06-11 10:57:04] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:57:04] __main__ INFO: [0mVal 2
[32m[2022-06-11 10:57:05] __main__ INFO: [0mEpoch 2 loss 0.6125 acc@1 0.8026 acc@5 0.9878
[32m[2022-06-11 10:57:05] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:57:05] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 10:57:09] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4144 (0.4560) acc@1 0.8594 (0.8421) acc@5 0.9844 (0.9934)
[32m[2022-06-11 10:57:13] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5340 (0.4564) acc@1 0.8438 (0.8409) acc@5 0.9922 (0.9931)
[32m[2022-06-11 10:57:17] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5588 (0.4509) acc@1 0.7812 (0.8440) acc@5 0.9766 (0.9932)
[32m[2022-06-11 10:57:21] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5174 (0.4521) acc@1 0.7812 (0.8432) acc@5 0.9922 (0.9932)
[32m[2022-06-11 10:57:21] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:57:21] __main__ INFO: [0mVal 3
[32m[2022-06-11 10:57:22] __main__ INFO: [0mEpoch 3 loss 0.6062 acc@1 0.8054 acc@5 0.9853
[32m[2022-06-11 10:57:22] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:57:22] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 10:57:26] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4386 (0.4043) acc@1 0.8672 (0.8594) acc@5 0.9844 (0.9952)
[32m[2022-06-11 10:57:30] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4525 (0.4087) acc@1 0.8359 (0.8574) acc@5 1.0000 (0.9950)
[32m[2022-06-11 10:57:34] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4729 (0.4107) acc@1 0.8516 (0.8561) acc@5 0.9922 (0.9946)
[32m[2022-06-11 10:57:37] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.2988 (0.4105) acc@1 0.8984 (0.8572) acc@5 1.0000 (0.9946)
[32m[2022-06-11 10:57:37] __main__ INFO: [0mElapsed 15.48
[32m[2022-06-11 10:57:37] __main__ INFO: [0mVal 4
[32m[2022-06-11 10:57:38] __main__ INFO: [0mEpoch 4 loss 0.5357 acc@1 0.8176 acc@5 0.9896
[32m[2022-06-11 10:57:38] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:57:38] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 10:57:42] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3871 (0.3745) acc@1 0.8906 (0.8741) acc@5 0.9922 (0.9955)
[32m[2022-06-11 10:57:46] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2828 (0.3717) acc@1 0.9297 (0.8736) acc@5 0.9922 (0.9952)
[32m[2022-06-11 10:57:50] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2867 (0.3730) acc@1 0.9062 (0.8727) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:57:54] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3977 (0.3736) acc@1 0.8750 (0.8719) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:57:54] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:57:54] __main__ INFO: [0mVal 5
[32m[2022-06-11 10:57:55] __main__ INFO: [0mEpoch 5 loss 0.6330 acc@1 0.7968 acc@5 0.9832
[32m[2022-06-11 10:57:55] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:57:55] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 10:57:59] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4442 (0.3665) acc@1 0.8359 (0.8715) acc@5 1.0000 (0.9958)
[32m[2022-06-11 10:58:03] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2820 (0.3629) acc@1 0.8828 (0.8736) acc@5 1.0000 (0.9957)
[32m[2022-06-11 10:58:07] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2700 (0.3601) acc@1 0.8906 (0.8750) acc@5 0.9922 (0.9953)
[32m[2022-06-11 10:58:10] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3269 (0.3596) acc@1 0.8984 (0.8749) acc@5 0.9922 (0.9954)
[32m[2022-06-11 10:58:11] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:58:11] __main__ INFO: [0mVal 6
[32m[2022-06-11 10:58:12] __main__ INFO: [0mEpoch 6 loss 0.5733 acc@1 0.8152 acc@5 0.9924
[32m[2022-06-11 10:58:12] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:58:12] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 10:58:16] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4802 (0.3335) acc@1 0.8281 (0.8825) acc@5 0.9922 (0.9968)
[32m[2022-06-11 10:58:19] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2045 (0.3386) acc@1 0.9531 (0.8829) acc@5 0.9922 (0.9961)
[32m[2022-06-11 10:58:23] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4583 (0.3393) acc@1 0.8438 (0.8824) acc@5 1.0000 (0.9961)
[32m[2022-06-11 10:58:27] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2662 (0.3389) acc@1 0.9219 (0.8823) acc@5 0.9922 (0.9962)
[32m[2022-06-11 10:58:27] __main__ INFO: [0mElapsed 15.52
[32m[2022-06-11 10:58:27] __main__ INFO: [0mVal 7
[32m[2022-06-11 10:58:28] __main__ INFO: [0mEpoch 7 loss 0.5119 acc@1 0.8397 acc@5 0.9914
[32m[2022-06-11 10:58:28] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:58:28] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 10:58:32] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4452 (0.3094) acc@1 0.8281 (0.8938) acc@5 0.9922 (0.9968)
[32m[2022-06-11 10:58:36] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.2973 (0.3230) acc@1 0.8984 (0.8889) acc@5 1.0000 (0.9962)
[32m[2022-06-11 10:58:40] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3904 (0.3244) acc@1 0.8750 (0.8890) acc@5 0.9922 (0.9961)
[32m[2022-06-11 10:58:43] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3229 (0.3242) acc@1 0.9062 (0.8897) acc@5 0.9844 (0.9964)
[32m[2022-06-11 10:58:44] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:58:44] __main__ INFO: [0mVal 8
[32m[2022-06-11 10:58:45] __main__ INFO: [0mEpoch 8 loss 0.4766 acc@1 0.8468 acc@5 0.9921
[32m[2022-06-11 10:58:45] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:58:45] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 10:58:49] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4175 (0.3099) acc@1 0.8828 (0.8935) acc@5 0.9844 (0.9970)
[32m[2022-06-11 10:58:53] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2971 (0.3112) acc@1 0.9141 (0.8927) acc@5 1.0000 (0.9972)
[32m[2022-06-11 10:58:57] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3992 (0.3152) acc@1 0.8672 (0.8915) acc@5 1.0000 (0.9968)
[32m[2022-06-11 10:59:00] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2723 (0.3143) acc@1 0.9141 (0.8917) acc@5 1.0000 (0.9968)
[32m[2022-06-11 10:59:00] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 10:59:00] __main__ INFO: [0mVal 9
[32m[2022-06-11 10:59:01] __main__ INFO: [0mEpoch 9 loss 0.4917 acc@1 0.8401 acc@5 0.9942
[32m[2022-06-11 10:59:01] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:59:01] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 10:59:05] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3100 (0.2918) acc@1 0.8750 (0.8984) acc@5 1.0000 (0.9975)
[32m[2022-06-11 10:59:09] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3057 (0.2993) acc@1 0.8984 (0.8969) acc@5 1.0000 (0.9969)
[32m[2022-06-11 10:59:13] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2057 (0.2991) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9973)
[32m[2022-06-11 10:59:17] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2768 (0.3041) acc@1 0.9062 (0.8941) acc@5 1.0000 (0.9972)
[32m[2022-06-11 10:59:17] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:59:17] __main__ INFO: [0mVal 10
[32m[2022-06-11 10:59:18] __main__ INFO: [0mEpoch 10 loss 0.6311 acc@1 0.8086 acc@5 0.9872
[32m[2022-06-11 10:59:18] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:59:18] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:07:48] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:07:48] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:07:52] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:07:52] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:07:52] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:07:53] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:07:53] __main__ INFO: [0mElapsed 1.05
[32m[2022-06-11 11:07:53] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:07:57] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6641 (1.1200) acc@1 0.7969 (0.6042) acc@5 0.9922 (0.9484)
[32m[2022-06-11 11:08:01] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7145 (0.9269) acc@1 0.7656 (0.6759) acc@5 0.9922 (0.9649)
[32m[2022-06-11 11:08:05] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6042 (0.8352) acc@1 0.7266 (0.7097) acc@5 1.0000 (0.9723)
[32m[2022-06-11 11:08:09] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5422 (0.7822) acc@1 0.8125 (0.7281) acc@5 1.0000 (0.9762)
[32m[2022-06-11 11:08:09] __main__ INFO: [0mElapsed 16.07
[32m[2022-06-11 11:08:09] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:08:10] __main__ INFO: [0mEpoch 1 loss 0.7418 acc@1 0.7514 acc@5 0.9830
[32m[2022-06-11 11:08:10] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:08:10] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:08:14] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.7173 (0.5433) acc@1 0.7422 (0.8114) acc@5 0.9922 (0.9912)
[32m[2022-06-11 11:08:18] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4550 (0.5308) acc@1 0.8594 (0.8161) acc@5 0.9922 (0.9907)
[32m[2022-06-11 11:08:22] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3489 (0.5249) acc@1 0.9062 (0.8193) acc@5 0.9922 (0.9913)
[32m[2022-06-11 11:08:25] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4092 (0.5187) acc@1 0.8203 (0.8216) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:08:26] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 11:08:26] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:08:27] __main__ INFO: [0mEpoch 2 loss 0.7899 acc@1 0.7582 acc@5 0.9773
[32m[2022-06-11 11:08:27] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:08:27] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:08:31] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.3938 (0.4555) acc@1 0.8594 (0.8454) acc@5 0.9922 (0.9943)
[32m[2022-06-11 11:08:35] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4942 (0.4565) acc@1 0.8281 (0.8434) acc@5 0.9922 (0.9936)
[32m[2022-06-11 11:08:39] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6109 (0.4499) acc@1 0.7578 (0.8452) acc@5 0.9844 (0.9939)
[32m[2022-06-11 11:08:42] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4959 (0.4518) acc@1 0.8281 (0.8447) acc@5 1.0000 (0.9939)
[32m[2022-06-11 11:08:42] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 11:08:42] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:08:43] __main__ INFO: [0mEpoch 3 loss 0.6889 acc@1 0.7752 acc@5 0.9861
[32m[2022-06-11 11:08:43] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:08:43] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:08:48] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4060 (0.4074) acc@1 0.8750 (0.8597) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:08:52] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4291 (0.4097) acc@1 0.8516 (0.8597) acc@5 1.0000 (0.9946)
[32m[2022-06-11 11:08:55] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4992 (0.4119) acc@1 0.8438 (0.8579) acc@5 0.9922 (0.9945)
[32m[2022-06-11 11:08:59] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3074 (0.4104) acc@1 0.8984 (0.8586) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:08:59] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 11:08:59] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:09:00] __main__ INFO: [0mEpoch 4 loss 0.5217 acc@1 0.8262 acc@5 0.9915
[32m[2022-06-11 11:09:00] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:09:00] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:09:04] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4267 (0.3737) acc@1 0.8828 (0.8723) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:09:08] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2756 (0.3737) acc@1 0.9375 (0.8712) acc@5 0.9922 (0.9953)
[32m[2022-06-11 11:09:12] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2928 (0.3770) acc@1 0.8828 (0.8699) acc@5 0.9922 (0.9952)
[32m[2022-06-11 11:09:16] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4317 (0.3776) acc@1 0.8516 (0.8698) acc@5 0.9922 (0.9949)
[32m[2022-06-11 11:09:16] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 11:09:16] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:09:17] __main__ INFO: [0mEpoch 5 loss 0.5635 acc@1 0.8131 acc@5 0.9898
[32m[2022-06-11 11:09:17] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:09:17] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:09:21] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4078 (0.3572) acc@1 0.8281 (0.8753) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:09:25] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2983 (0.3572) acc@1 0.8516 (0.8752) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:09:29] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3187 (0.3543) acc@1 0.8672 (0.8772) acc@5 1.0000 (0.9963)
[32m[2022-06-11 11:09:32] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3353 (0.3550) acc@1 0.8828 (0.8765) acc@5 0.9922 (0.9961)
[32m[2022-06-11 11:09:32] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:09:32] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:09:33] __main__ INFO: [0mEpoch 6 loss 0.5299 acc@1 0.8240 acc@5 0.9914
[32m[2022-06-11 11:09:33] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:09:33] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:09:38] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4683 (0.3395) acc@1 0.8125 (0.8820) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:09:42] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2793 (0.3389) acc@1 0.9141 (0.8820) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:09:46] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4390 (0.3415) acc@1 0.8672 (0.8807) acc@5 0.9922 (0.9961)
[32m[2022-06-11 11:09:49] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2575 (0.3419) acc@1 0.9062 (0.8807) acc@5 1.0000 (0.9961)
[32m[2022-06-11 11:09:49] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 11:09:49] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:09:50] __main__ INFO: [0mEpoch 7 loss 0.5152 acc@1 0.8341 acc@5 0.9914
[32m[2022-06-11 11:09:50] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:09:50] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:09:54] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4600 (0.3088) acc@1 0.8203 (0.8924) acc@5 0.9844 (0.9974)
[32m[2022-06-11 11:09:58] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3304 (0.3197) acc@1 0.8672 (0.8892) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:10:02] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3306 (0.3223) acc@1 0.8672 (0.8882) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:10:06] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3190 (0.3219) acc@1 0.8984 (0.8885) acc@5 0.9844 (0.9968)
[32m[2022-06-11 11:10:06] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 11:10:06] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:10:07] __main__ INFO: [0mEpoch 8 loss 0.4809 acc@1 0.8474 acc@5 0.9927
[32m[2022-06-11 11:10:07] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:10:07] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:10:11] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3982 (0.3073) acc@1 0.8672 (0.8923) acc@5 0.9922 (0.9978)
[32m[2022-06-11 11:10:15] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2549 (0.3071) acc@1 0.9375 (0.8917) acc@5 1.0000 (0.9977)
[32m[2022-06-11 11:10:19] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3600 (0.3092) acc@1 0.8828 (0.8909) acc@5 0.9844 (0.9973)
[32m[2022-06-11 11:10:22] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2504 (0.3076) acc@1 0.9453 (0.8920) acc@5 0.9922 (0.9971)
[32m[2022-06-11 11:10:22] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 11:10:22] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:10:23] __main__ INFO: [0mEpoch 9 loss 0.4815 acc@1 0.8467 acc@5 0.9951
[32m[2022-06-11 11:10:23] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:10:23] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:10:28] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3211 (0.2920) acc@1 0.8750 (0.8979) acc@5 1.0000 (0.9975)
[32m[2022-06-11 11:10:31] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3215 (0.2973) acc@1 0.8906 (0.8980) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:10:35] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1521 (0.2968) acc@1 0.9609 (0.8976) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:10:39] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2432 (0.3031) acc@1 0.9062 (0.8956) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:10:39] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 11:10:39] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:10:40] __main__ INFO: [0mEpoch 10 loss 0.4984 acc@1 0.8449 acc@5 0.9928
[32m[2022-06-11 11:10:40] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:10:40] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:11:08] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:11:08] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:11:12] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:11:12] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:11:12] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:11:13] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:11:13] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:11:13] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:11:17] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6881 (1.1215) acc@1 0.7891 (0.6053) acc@5 1.0000 (0.9480)
[32m[2022-06-11 11:11:21] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6868 (0.9272) acc@1 0.7422 (0.6771) acc@5 0.9922 (0.9648)
[32m[2022-06-11 11:11:25] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6476 (0.8340) acc@1 0.7344 (0.7090) acc@5 1.0000 (0.9721)
[32m[2022-06-11 11:11:29] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5383 (0.7801) acc@1 0.8203 (0.7280) acc@5 0.9922 (0.9762)
[32m[2022-06-11 11:11:29] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 11:11:29] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:11:30] __main__ INFO: [0mEpoch 1 loss 0.8620 acc@1 0.7167 acc@5 0.9823
[32m[2022-06-11 11:11:30] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:11:30] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:11:34] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6999 (0.5464) acc@1 0.7656 (0.8143) acc@5 0.9844 (0.9912)
[32m[2022-06-11 11:11:38] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.5270 (0.5310) acc@1 0.8281 (0.8179) acc@5 0.9922 (0.9910)
[32m[2022-06-11 11:11:42] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3923 (0.5229) acc@1 0.8906 (0.8205) acc@5 1.0000 (0.9913)
[32m[2022-06-11 11:11:45] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4069 (0.5205) acc@1 0.8359 (0.8212) acc@5 1.0000 (0.9913)
[32m[2022-06-11 11:11:46] __main__ INFO: [0mElapsed 15.89
[32m[2022-06-11 11:11:46] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:11:46] __main__ INFO: [0mEpoch 2 loss 0.7687 acc@1 0.7622 acc@5 0.9843
[32m[2022-06-11 11:11:46] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:11:46] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:11:51] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4542 (0.4567) acc@1 0.8438 (0.8429) acc@5 0.9844 (0.9937)
[32m[2022-06-11 11:11:55] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5747 (0.4598) acc@1 0.7891 (0.8427) acc@5 0.9922 (0.9930)
[32m[2022-06-11 11:11:58] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5849 (0.4531) acc@1 0.7734 (0.8438) acc@5 0.9922 (0.9933)
[32m[2022-06-11 11:12:02] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4755 (0.4548) acc@1 0.8203 (0.8441) acc@5 1.0000 (0.9930)
[32m[2022-06-11 11:12:02] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:12:02] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:12:03] __main__ INFO: [0mEpoch 3 loss 0.5518 acc@1 0.8180 acc@5 0.9890
[32m[2022-06-11 11:12:03] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:12:03] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:12:07] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3491 (0.4053) acc@1 0.9141 (0.8606) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:12:11] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4388 (0.4076) acc@1 0.8672 (0.8606) acc@5 1.0000 (0.9954)
[32m[2022-06-11 11:12:15] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4700 (0.4125) acc@1 0.8672 (0.8586) acc@5 0.9922 (0.9949)
[32m[2022-06-11 11:12:19] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3007 (0.4121) acc@1 0.8984 (0.8575) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:12:19] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 11:12:19] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:12:20] __main__ INFO: [0mEpoch 4 loss 0.6579 acc@1 0.7870 acc@5 0.9881
[32m[2022-06-11 11:12:20] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:12:20] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:12:24] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3672 (0.3731) acc@1 0.8828 (0.8707) acc@5 1.0000 (0.9949)
[32m[2022-06-11 11:12:28] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3230 (0.3762) acc@1 0.8984 (0.8693) acc@5 0.9922 (0.9952)
[32m[2022-06-11 11:12:32] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2219 (0.3773) acc@1 0.9453 (0.8705) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:12:35] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3911 (0.3806) acc@1 0.8984 (0.8685) acc@5 0.9844 (0.9951)
[32m[2022-06-11 11:12:36] __main__ INFO: [0mElapsed 15.59
[32m[2022-06-11 11:12:36] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:12:36] __main__ INFO: [0mEpoch 5 loss 0.6748 acc@1 0.7864 acc@5 0.9885
[32m[2022-06-11 11:12:36] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:12:36] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:12:41] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4149 (0.3637) acc@1 0.8750 (0.8734) acc@5 1.0000 (0.9965)
[32m[2022-06-11 11:12:45] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2633 (0.3619) acc@1 0.9297 (0.8749) acc@5 1.0000 (0.9963)
[32m[2022-06-11 11:12:49] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3190 (0.3587) acc@1 0.8750 (0.8758) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:12:52] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.2982 (0.3598) acc@1 0.8828 (0.8750) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:12:52] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 11:12:52] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:12:53] __main__ INFO: [0mEpoch 6 loss 0.4413 acc@1 0.8534 acc@5 0.9935
[32m[2022-06-11 11:12:53] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:12:53] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:12:58] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4156 (0.3303) acc@1 0.8594 (0.8850) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:13:02] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2663 (0.3403) acc@1 0.9141 (0.8829) acc@5 0.9922 (0.9955)
[32m[2022-06-11 11:13:06] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3548 (0.3376) acc@1 0.8906 (0.8838) acc@5 1.0000 (0.9959)
[32m[2022-06-11 11:13:09] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2980 (0.3371) acc@1 0.8906 (0.8839) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:13:09] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 11:13:09] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:13:10] __main__ INFO: [0mEpoch 7 loss 0.5129 acc@1 0.8314 acc@5 0.9914
[32m[2022-06-11 11:13:10] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:13:10] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:13:14] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4732 (0.3177) acc@1 0.8359 (0.8915) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:13:18] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3651 (0.3274) acc@1 0.8359 (0.8882) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:13:22] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3525 (0.3278) acc@1 0.8828 (0.8876) acc@5 0.9922 (0.9965)
[32m[2022-06-11 11:13:26] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3310 (0.3252) acc@1 0.8906 (0.8879) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:13:26] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 11:13:26] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:13:27] __main__ INFO: [0mEpoch 8 loss 0.4486 acc@1 0.8552 acc@5 0.9947
[32m[2022-06-11 11:13:27] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:13:27] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:13:31] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3911 (0.3088) acc@1 0.8672 (0.8948) acc@5 0.9844 (0.9970)
[32m[2022-06-11 11:13:35] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2668 (0.3079) acc@1 0.9062 (0.8941) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:13:39] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3345 (0.3118) acc@1 0.8984 (0.8935) acc@5 0.9922 (0.9967)
[32m[2022-06-11 11:13:43] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2954 (0.3126) acc@1 0.9297 (0.8929) acc@5 1.0000 (0.9965)
[32m[2022-06-11 11:13:43] __main__ INFO: [0mElapsed 16.03
[32m[2022-06-11 11:13:43] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:13:44] __main__ INFO: [0mEpoch 9 loss 0.4958 acc@1 0.8402 acc@5 0.9917
[32m[2022-06-11 11:13:44] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 11:13:44] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:13:48] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.2592 (0.2875) acc@1 0.9297 (0.9017) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:13:52] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3328 (0.2966) acc@1 0.8906 (0.8982) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:13:56] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1916 (0.2963) acc@1 0.9375 (0.8990) acc@5 1.0000 (0.9973)
[32m[2022-06-11 11:13:59] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2386 (0.3004) acc@1 0.8984 (0.8967) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:13:59] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:13:59] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:14:00] __main__ INFO: [0mEpoch 10 loss 0.4900 acc@1 0.8455 acc@5 0.9924
[32m[2022-06-11 11:14:00] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:14:00] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:27:26] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:27:26] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:27:30] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:27:30] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:27:30] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:27:31] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:27:31] __main__ INFO: [0mElapsed 1.05
[32m[2022-06-11 11:27:31] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:27:35] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6703 (1.1210) acc@1 0.8047 (0.6047) acc@5 0.9844 (0.9472)
[32m[2022-06-11 11:27:39] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7222 (0.9280) acc@1 0.7422 (0.6745) acc@5 0.9922 (0.9645)
[32m[2022-06-11 11:27:43] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6236 (0.8361) acc@1 0.7344 (0.7081) acc@5 1.0000 (0.9722)
[32m[2022-06-11 11:27:47] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5172 (0.7813) acc@1 0.8438 (0.7278) acc@5 0.9922 (0.9760)
[32m[2022-06-11 11:27:47] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 11:27:47] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:27:48] __main__ INFO: [0mEpoch 1 loss 0.8147 acc@1 0.7362 acc@5 0.9789
[32m[2022-06-11 11:27:48] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:27:48] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:27:52] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6497 (0.5428) acc@1 0.7812 (0.8155) acc@5 0.9766 (0.9916)
[32m[2022-06-11 11:27:56] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4312 (0.5311) acc@1 0.8516 (0.8182) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:28:00] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3347 (0.5251) acc@1 0.8984 (0.8199) acc@5 0.9922 (0.9915)
[32m[2022-06-11 11:28:03] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4081 (0.5213) acc@1 0.8438 (0.8206) acc@5 1.0000 (0.9917)
[32m[2022-06-11 11:28:03] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 11:28:03] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:28:04] __main__ INFO: [0mEpoch 2 loss 0.6768 acc@1 0.7845 acc@5 0.9879
[32m[2022-06-11 11:28:04] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:28:04] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:28:08] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4239 (0.4556) acc@1 0.8594 (0.8435) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:12] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4784 (0.4589) acc@1 0.8281 (0.8427) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:16] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6112 (0.4546) acc@1 0.7891 (0.8441) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:20] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4878 (0.4547) acc@1 0.8359 (0.8434) acc@5 1.0000 (0.9933)
[32m[2022-06-11 11:28:20] __main__ INFO: [0mElapsed 15.48
[32m[2022-06-11 11:28:20] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:28:21] __main__ INFO: [0mEpoch 3 loss 0.6242 acc@1 0.8021 acc@5 0.9880
[32m[2022-06-11 11:28:21] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:28:21] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:28:25] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3409 (0.4014) acc@1 0.9141 (0.8616) acc@5 1.0000 (0.9958)
[32m[2022-06-11 11:28:29] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.3867 (0.4082) acc@1 0.8828 (0.8592) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:28:33] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4383 (0.4112) acc@1 0.8906 (0.8586) acc@5 0.9922 (0.9948)
[32m[2022-06-11 11:28:36] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3536 (0.4104) acc@1 0.8828 (0.8591) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:28:36] __main__ INFO: [0mElapsed 15.52
[32m[2022-06-11 11:28:36] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:28:37] __main__ INFO: [0mEpoch 4 loss 0.5941 acc@1 0.8077 acc@5 0.9905
[32m[2022-06-11 11:28:37] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:28:37] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:28:41] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3732 (0.3712) acc@1 0.8516 (0.8715) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:28:45] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3087 (0.3722) acc@1 0.9062 (0.8719) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:28:49] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2765 (0.3759) acc@1 0.9219 (0.8697) acc@5 1.0000 (0.9958)
[32m[2022-06-11 11:28:53] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4014 (0.3771) acc@1 0.8828 (0.8703) acc@5 0.9922 (0.9955)
[32m[2022-06-11 11:28:53] __main__ INFO: [0mElapsed 16.21
[32m[2022-06-11 11:28:53] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:28:54] __main__ INFO: [0mEpoch 5 loss 0.5608 acc@1 0.8170 acc@5 0.9902
[32m[2022-06-11 11:28:54] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:28:54] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:28:59] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4154 (0.3587) acc@1 0.8828 (0.8772) acc@5 0.9844 (0.9955)
[32m[2022-06-11 11:29:02] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2614 (0.3568) acc@1 0.8828 (0.8778) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:29:06] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3376 (0.3562) acc@1 0.8828 (0.8774) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:29:10] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3081 (0.3559) acc@1 0.8906 (0.8776) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:29:10] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 11:29:10] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:29:11] __main__ INFO: [0mEpoch 6 loss 0.5310 acc@1 0.8204 acc@5 0.9908
[32m[2022-06-11 11:29:11] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:29:11] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:29:15] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4543 (0.3390) acc@1 0.8203 (0.8825) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:29:19] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2390 (0.3413) acc@1 0.9219 (0.8832) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:29:23] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3725 (0.3419) acc@1 0.8750 (0.8827) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:27] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2497 (0.3394) acc@1 0.9219 (0.8829) acc@5 0.9922 (0.9963)
[32m[2022-06-11 11:29:27] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 11:29:27] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:29:28] __main__ INFO: [0mEpoch 7 loss 0.5983 acc@1 0.8205 acc@5 0.9866
[32m[2022-06-11 11:29:28] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:29:28] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:29:32] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.5077 (0.3133) acc@1 0.8203 (0.8886) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:29:36] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3406 (0.3232) acc@1 0.8828 (0.8873) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:40] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.2572 (0.3243) acc@1 0.9219 (0.8881) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:44] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3474 (0.3239) acc@1 0.9062 (0.8881) acc@5 0.9922 (0.9965)
[32m[2022-06-11 11:29:44] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 11:29:44] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:29:45] __main__ INFO: [0mEpoch 8 loss 0.4387 acc@1 0.8590 acc@5 0.9939
[32m[2022-06-11 11:29:45] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:29:45] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:29:49] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4169 (0.3055) acc@1 0.8516 (0.8938) acc@5 0.9844 (0.9975)
[32m[2022-06-11 11:29:53] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2892 (0.3029) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9974)
[32m[2022-06-11 11:29:57] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4639 (0.3071) acc@1 0.8359 (0.8943) acc@5 0.9922 (0.9972)
[32m[2022-06-11 11:30:00] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2928 (0.3071) acc@1 0.9297 (0.8946) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:30:00] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 11:30:00] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:30:01] __main__ INFO: [0mEpoch 9 loss 0.5721 acc@1 0.8158 acc@5 0.9908
[32m[2022-06-11 11:30:01] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:30:01] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:30:05] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3427 (0.2947) acc@1 0.8906 (0.8985) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:30:09] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3172 (0.2975) acc@1 0.8828 (0.8981) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:30:13] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2174 (0.2962) acc@1 0.9375 (0.8975) acc@5 0.9922 (0.9971)
[32m[2022-06-11 11:30:17] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2691 (0.3025) acc@1 0.9062 (0.8953) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:30:17] __main__ INFO: [0mElapsed 15.39
[32m[2022-06-11 11:30:17] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:30:18] __main__ INFO: [0mEpoch 10 loss 0.5443 acc@1 0.8378 acc@5 0.9919
[32m[2022-06-11 11:30:18] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:30:18] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:32:53] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:32:53] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:14] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:33:14] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:18] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:33:18] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:33:18] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:33:19] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:33:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:33:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:33:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:33:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:33:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:33:34] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:33:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:33:39] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6751 (1.1220) acc@1 0.7812 (0.6027) acc@5 1.0000 (0.9478)
[32m[2022-06-11 11:33:43] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7131 (0.9283) acc@1 0.7500 (0.6738) acc@5 0.9844 (0.9642)
[32m[2022-06-11 11:33:46] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6397 (0.8345) acc@1 0.7422 (0.7076) acc@5 1.0000 (0.9721)
[32m[2022-06-11 11:33:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5589 (0.7804) acc@1 0.8203 (0.7277) acc@5 0.9766 (0.9760)
[32m[2022-06-11 11:33:50] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:33:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:33:51] __main__ INFO: [0mEpoch 1 loss 0.6942 acc@1 0.7607 acc@5 0.9840
[32m[2022-06-11 11:33:51] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:33:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:33:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6618 (0.5374) acc@1 0.7500 (0.8174) acc@5 0.9922 (0.9913)
[32m[2022-06-11 11:33:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.5240 (0.5284) acc@1 0.8203 (0.8186) acc@5 1.0000 (0.9910)
[32m[2022-06-11 11:34:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3815 (0.5242) acc@1 0.8750 (0.8194) acc@5 0.9922 (0.9911)
[32m[2022-06-11 11:34:06] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4191 (0.5212) acc@1 0.8359 (0.8203) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:34:07] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 11:34:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:34:07] __main__ INFO: [0mEpoch 2 loss 0.7611 acc@1 0.7603 acc@5 0.9845
[32m[2022-06-11 11:34:07] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:07] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:34:11] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4705 (0.4533) acc@1 0.8281 (0.8444) acc@5 0.9922 (0.9933)
[32m[2022-06-11 11:34:15] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5197 (0.4571) acc@1 0.7969 (0.8413) acc@5 0.9922 (0.9930)
[32m[2022-06-11 11:34:19] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5835 (0.4506) acc@1 0.7969 (0.8434) acc@5 0.9922 (0.9934)
[32m[2022-06-11 11:34:23] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4464 (0.4526) acc@1 0.8281 (0.8429) acc@5 1.0000 (0.9932)
[32m[2022-06-11 11:34:23] __main__ INFO: [0mElapsed 15.44
[32m[2022-06-11 11:34:23] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:34:24] __main__ INFO: [0mEpoch 3 loss 0.5718 acc@1 0.8130 acc@5 0.9891
[32m[2022-06-11 11:34:24] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:24] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:34:28] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4051 (0.4032) acc@1 0.8750 (0.8591) acc@5 0.9844 (0.9955)
[32m[2022-06-11 11:34:32] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4391 (0.4073) acc@1 0.8281 (0.8590) acc@5 1.0000 (0.9953)
[32m[2022-06-11 11:34:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4881 (0.4133) acc@1 0.8203 (0.8578) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:34:39] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3223 (0.4137) acc@1 0.8906 (0.8577) acc@5 1.0000 (0.9946)
[32m[2022-06-11 11:34:39] __main__ INFO: [0mElapsed 15.49
[32m[2022-06-11 11:34:39] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:34:40] __main__ INFO: [0mEpoch 4 loss 0.5389 acc@1 0.8208 acc@5 0.9917
[32m[2022-06-11 11:34:40] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:34:40] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:34:44] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3861 (0.3711) acc@1 0.8594 (0.8691) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:34:48] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2983 (0.3729) acc@1 0.9062 (0.8700) acc@5 0.9844 (0.9956)
[32m[2022-06-11 11:34:52] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2727 (0.3737) acc@1 0.9062 (0.8699) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:34:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3270 (0.3734) acc@1 0.8984 (0.8701) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:34:56] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 11:34:56] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:34:57] __main__ INFO: [0mEpoch 5 loss 0.5079 acc@1 0.8316 acc@5 0.9918
[32m[2022-06-11 11:34:57] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:35:01] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4298 (0.3571) acc@1 0.8594 (0.8766) acc@5 0.9922 (0.9960)
[32m[2022-06-11 11:35:05] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2715 (0.3590) acc@1 0.9141 (0.8746) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:35:09] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3308 (0.3558) acc@1 0.8594 (0.8752) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:35:12] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.4591 (0.3577) acc@1 0.8281 (0.8746) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:35:12] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 11:35:12] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:35:13] __main__ INFO: [0mEpoch 6 loss 0.4822 acc@1 0.8396 acc@5 0.9937
[32m[2022-06-11 11:35:13] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:35:13] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:35:17] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4135 (0.3379) acc@1 0.8594 (0.8837) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:35:21] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2655 (0.3424) acc@1 0.8984 (0.8819) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:35:25] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3765 (0.3425) acc@1 0.8828 (0.8811) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:35:29] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2733 (0.3410) acc@1 0.8828 (0.8814) acc@5 1.0000 (0.9961)
[32m[2022-06-11 11:35:29] __main__ INFO: [0mElapsed 15.47
[32m[2022-06-11 11:35:29] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:35:30] __main__ INFO: [0mEpoch 7 loss 0.4863 acc@1 0.8432 acc@5 0.9916
[32m[2022-06-11 11:35:30] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:35:30] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:35:34] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.3991 (0.3068) acc@1 0.8125 (0.8939) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:35:38] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3476 (0.3234) acc@1 0.8984 (0.8891) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:35:42] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3212 (0.3239) acc@1 0.8906 (0.8890) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:35:45] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.2679 (0.3236) acc@1 0.9062 (0.8885) acc@5 0.9922 (0.9967)
[32m[2022-06-11 11:35:45] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 11:35:45] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:35:46] __main__ INFO: [0mEpoch 8 loss 0.4820 acc@1 0.8479 acc@5 0.9936
[32m[2022-06-11 11:35:46] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:35:46] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:35:50] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4427 (0.3077) acc@1 0.8828 (0.8927) acc@5 0.9844 (0.9970)
[32m[2022-06-11 11:35:54] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2354 (0.3048) acc@1 0.9609 (0.8939) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:35:58] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3996 (0.3074) acc@1 0.8438 (0.8931) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:36:02] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.3134 (0.3090) acc@1 0.9062 (0.8928) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:36:02] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 11:36:02] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:36:03] __main__ INFO: [0mEpoch 9 loss 0.4614 acc@1 0.8524 acc@5 0.9929
[32m[2022-06-11 11:36:03] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:36:03] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:36:07] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.2864 (0.2892) acc@1 0.8984 (0.8998) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:36:11] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3060 (0.3012) acc@1 0.8750 (0.8959) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:36:15] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2197 (0.2992) acc@1 0.9062 (0.8962) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:36:19] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2509 (0.3031) acc@1 0.8984 (0.8944) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:36:19] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 11:36:19] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:36:20] __main__ INFO: [0mEpoch 10 loss 0.7019 acc@1 0.8042 acc@5 0.9815
[32m[2022-06-11 11:36:20] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:36:20] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:37:40] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:37:40] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:37:44] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:37:44] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:37:44] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:37:45] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:39:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:39:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:39:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:39:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:39:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:39:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:39:34] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:39:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:39:38] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6560 (1.1208) acc@1 0.7969 (0.6029) acc@5 0.9922 (0.9484)
[32m[2022-06-11 11:39:42] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6912 (0.9272) acc@1 0.7500 (0.6748) acc@5 0.9844 (0.9650)
[32m[2022-06-11 11:39:47] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.5721 (0.8329) acc@1 0.7969 (0.7089) acc@5 0.9922 (0.9728)
[32m[2022-06-11 11:39:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5301 (0.7798) acc@1 0.8125 (0.7275) acc@5 0.9922 (0.9767)
[32m[2022-06-11 11:39:50] __main__ INFO: [0mElapsed 16.30
[32m[2022-06-11 11:39:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:39:51] __main__ INFO: [0mEpoch 1 loss 0.8266 acc@1 0.7217 acc@5 0.9845
[32m[2022-06-11 11:39:51] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 11:39:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:39:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6631 (0.5386) acc@1 0.7891 (0.8181) acc@5 0.9922 (0.9905)
[32m[2022-06-11 11:39:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4213 (0.5260) acc@1 0.8516 (0.8202) acc@5 1.0000 (0.9910)
[32m[2022-06-11 11:40:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.4339 (0.5216) acc@1 0.8359 (0.8199) acc@5 0.9844 (0.9910)
[32m[2022-06-11 11:40:06] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4238 (0.5171) acc@1 0.8594 (0.8215) acc@5 0.9922 (0.9908)
[32m[2022-06-11 11:40:07] __main__ INFO: [0mElapsed 15.49
[32m[2022-06-11 11:40:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:40:07] __main__ INFO: [0mEpoch 2 loss 0.7564 acc@1 0.7634 acc@5 0.9817
[32m[2022-06-11 11:40:07] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:40:07] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:40:12] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4271 (0.4522) acc@1 0.8438 (0.8474) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:40:16] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4912 (0.4587) acc@1 0.8281 (0.8420) acc@5 1.0000 (0.9938)
[32m[2022-06-11 11:40:19] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5944 (0.4537) acc@1 0.7812 (0.8430) acc@5 0.9922 (0.9939)
[32m[2022-06-11 11:40:23] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4324 (0.4562) acc@1 0.8516 (0.8425) acc@5 0.9922 (0.9937)
[32m[2022-06-11 11:40:23] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 11:40:23] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:40:24] __main__ INFO: [0mEpoch 3 loss 0.5576 acc@1 0.8108 acc@5 0.9906
[32m[2022-06-11 11:40:24] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:40:24] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:40:28] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3417 (0.4003) acc@1 0.8750 (0.8628) acc@5 1.0000 (0.9959)
[32m[2022-06-11 11:40:32] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4416 (0.4058) acc@1 0.8359 (0.8599) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:40:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4186 (0.4105) acc@1 0.8516 (0.8592) acc@5 1.0000 (0.9947)
[32m[2022-06-11 11:40:40] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3404 (0.4104) acc@1 0.8672 (0.8595) acc@5 0.9922 (0.9945)
[32m[2022-06-11 11:40:40] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 11:40:40] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:40:41] __main__ INFO: [0mEpoch 4 loss 0.6213 acc@1 0.8007 acc@5 0.9880
[32m[2022-06-11 11:40:41] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:40:41] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:40:45] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4079 (0.3747) acc@1 0.8359 (0.8704) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:40:49] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2575 (0.3763) acc@1 0.9219 (0.8705) acc@5 0.9922 (0.9960)
[32m[2022-06-11 11:40:53] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2716 (0.3793) acc@1 0.9219 (0.8702) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:40:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3944 (0.3779) acc@1 0.8984 (0.8708) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:40:56] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 11:40:56] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:40:57] __main__ INFO: [0mEpoch 5 loss 0.6340 acc@1 0.7983 acc@5 0.9882
[32m[2022-06-11 11:40:57] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:40:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:41:01] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.3681 (0.3611) acc@1 0.8984 (0.8734) acc@5 1.0000 (0.9956)
[32m[2022-06-11 11:41:05] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2942 (0.3556) acc@1 0.8828 (0.8760) acc@5 1.0000 (0.9954)
[32m[2022-06-11 11:41:09] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2841 (0.3535) acc@1 0.8828 (0.8767) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:41:13] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3543 (0.3569) acc@1 0.8984 (0.8756) acc@5 1.0000 (0.9956)
[32m[2022-06-11 11:41:13] __main__ INFO: [0mElapsed 15.90
[32m[2022-06-11 11:41:13] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:41:14] __main__ INFO: [0mEpoch 6 loss 0.4887 acc@1 0.8397 acc@5 0.9926
[32m[2022-06-11 11:41:14] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:41:14] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:41:18] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.3626 (0.3323) acc@1 0.8750 (0.8843) acc@5 0.9922 (0.9970)
[32m[2022-06-11 11:41:22] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2886 (0.3423) acc@1 0.8906 (0.8816) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:41:26] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4444 (0.3420) acc@1 0.8516 (0.8821) acc@5 0.9766 (0.9964)
[32m[2022-06-11 11:41:30] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2477 (0.3417) acc@1 0.9141 (0.8825) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:41:30] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 11:41:30] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:41:31] __main__ INFO: [0mEpoch 7 loss 0.5324 acc@1 0.8294 acc@5 0.9917
[32m[2022-06-11 11:41:31] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:41:31] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:41:35] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4255 (0.3164) acc@1 0.8672 (0.8939) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:41:39] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3388 (0.3273) acc@1 0.8984 (0.8889) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:41:43] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3674 (0.3291) acc@1 0.8516 (0.8886) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:41:47] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.2771 (0.3262) acc@1 0.9297 (0.8883) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:41:47] __main__ INFO: [0mElapsed 15.87
[32m[2022-06-11 11:41:47] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:41:48] __main__ INFO: [0mEpoch 8 loss 0.4212 acc@1 0.8588 acc@5 0.9951
[32m[2022-06-11 11:41:48] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:41:48] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:41:52] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3391 (0.3046) acc@1 0.8906 (0.8966) acc@5 1.0000 (0.9978)
[32m[2022-06-11 11:41:56] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2622 (0.3039) acc@1 0.9375 (0.8954) acc@5 1.0000 (0.9977)
[32m[2022-06-11 11:42:00] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4118 (0.3096) acc@1 0.8750 (0.8928) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:42:03] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2930 (0.3094) acc@1 0.9219 (0.8930) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:42:03] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 11:42:03] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:42:04] __main__ INFO: [0mEpoch 9 loss 0.5741 acc@1 0.8195 acc@5 0.9928
[32m[2022-06-11 11:42:04] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:42:04] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:42:08] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3077 (0.2956) acc@1 0.8594 (0.8976) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:42:13] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3786 (0.3034) acc@1 0.8750 (0.8950) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:42:16] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1840 (0.3018) acc@1 0.9375 (0.8956) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:42:20] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2419 (0.3055) acc@1 0.8906 (0.8938) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:42:20] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 11:42:20] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:42:21] __main__ INFO: [0mEpoch 10 loss 0.6033 acc@1 0.8143 acc@5 0.9891
[32m[2022-06-11 11:42:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:42:21] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:43:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:43:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:45:19] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:45:19] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:45:47] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:45:47] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:46:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:46:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:47:09] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:47:09] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:47:13] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:47:13] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:47:13] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:47:14] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:47:14] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 11:47:14] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:47:16] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 1.1085 (1.4677) acc@1 0.6094 (0.4816) acc@5 0.9766 (0.9099)
[32m[2022-06-11 11:47:16] __main__ INFO: [0mElapsed 2.00
[32m[2022-06-11 11:47:16] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:47:17] __main__ INFO: [0mEpoch 1 loss 1.9991 acc@1 0.4416 acc@5 0.8211
[32m[2022-06-11 11:47:17] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:47:17] __main__ INFO: [0mTrain 2 39
[32m[2022-06-11 11:47:19] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 0.8281 (0.8931) acc@1 0.6641 (0.6855) acc@5 0.9844 (0.9764)
[32m[2022-06-11 11:47:19] __main__ INFO: [0mElapsed 1.82
[32m[2022-06-11 11:47:19] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:47:20] __main__ INFO: [0mEpoch 2 loss 1.1504 acc@1 0.6234 acc@5 0.9625
[32m[2022-06-11 11:47:20] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:47:20] __main__ INFO: [0mTrain 3 78
[32m[2022-06-11 11:47:22] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 0.7418 (0.7268) acc@1 0.7188 (0.7442) acc@5 0.9844 (0.9874)
[32m[2022-06-11 11:47:22] __main__ INFO: [0mElapsed 1.88
[32m[2022-06-11 11:47:22] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:47:23] __main__ INFO: [0mEpoch 3 loss 1.0344 acc@1 0.6665 acc@5 0.9723
[32m[2022-06-11 11:47:23] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:47:23] __main__ INFO: [0mTrain 4 117
[32m[2022-06-11 11:47:25] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 0.7325 (0.6317) acc@1 0.7266 (0.7788) acc@5 0.9922 (0.9878)
[32m[2022-06-11 11:47:25] __main__ INFO: [0mElapsed 1.92
[32m[2022-06-11 11:47:25] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:47:26] __main__ INFO: [0mEpoch 4 loss 1.1381 acc@1 0.6523 acc@5 0.9468
[32m[2022-06-11 11:47:26] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:47:26] __main__ INFO: [0mTrain 5 156
[32m[2022-06-11 11:47:28] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 0.4686 (0.5484) acc@1 0.8594 (0.8089) acc@5 0.9844 (0.9878)
[32m[2022-06-11 11:47:28] __main__ INFO: [0mElapsed 1.90
[32m[2022-06-11 11:47:28] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:47:29] __main__ INFO: [0mEpoch 5 loss 1.1331 acc@1 0.6604 acc@5 0.9684
[32m[2022-06-11 11:47:29] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 11:47:29] __main__ INFO: [0mTrain 6 195
[32m[2022-06-11 11:47:31] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 0.5048 (0.5052) acc@1 0.8281 (0.8247) acc@5 0.9922 (0.9914)
[32m[2022-06-11 11:47:31] __main__ INFO: [0mElapsed 1.89
[32m[2022-06-11 11:47:31] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:47:32] __main__ INFO: [0mEpoch 6 loss 1.1472 acc@1 0.6510 acc@5 0.9723
[32m[2022-06-11 11:47:32] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:32] __main__ INFO: [0mTrain 7 234
[32m[2022-06-11 11:47:33] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 0.5296 (0.4943) acc@1 0.8125 (0.8309) acc@5 0.9922 (0.9924)
[32m[2022-06-11 11:47:33] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:33] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:47:34] __main__ INFO: [0mEpoch 7 loss 1.0596 acc@1 0.6989 acc@5 0.9757
[32m[2022-06-11 11:47:34] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:34] __main__ INFO: [0mTrain 8 273
[32m[2022-06-11 11:47:36] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 0.5585 (0.4186) acc@1 0.7969 (0.8544) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:47:36] __main__ INFO: [0mElapsed 1.82
[32m[2022-06-11 11:47:36] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:47:37] __main__ INFO: [0mEpoch 8 loss 0.8895 acc@1 0.7261 acc@5 0.9779
[32m[2022-06-11 11:47:37] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:47:37] __main__ INFO: [0mTrain 9 312
[32m[2022-06-11 11:47:39] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 0.3663 (0.3945) acc@1 0.8594 (0.8620) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:47:39] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:39] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:47:40] __main__ INFO: [0mEpoch 9 loss 1.0373 acc@1 0.7009 acc@5 0.9689
[32m[2022-06-11 11:47:40] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:47:40] __main__ INFO: [0mTrain 10 351
[32m[2022-06-11 11:47:42] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 0.4399 (0.3806) acc@1 0.8594 (0.8652) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:47:42] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:42] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:47:43] __main__ INFO: [0mEpoch 10 loss 1.0641 acc@1 0.7062 acc@5 0.9784
[32m[2022-06-11 11:47:43] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:43] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth

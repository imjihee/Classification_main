[32m[2022-06-11 09:30:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:30:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:30:29] __main__ INFO: [0mMACs   : 255.27M
[32m[2022-06-11 09:30:29] __main__ INFO: [0m#params: 1.73M
[32m[2022-06-11 09:31:23] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:31:23] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:31:27] __main__ INFO: [0mMACs   : 255.27M
[32m[2022-06-11 09:31:27] __main__ INFO: [0m#params: 1.73M
[32m[2022-06-11 09:31:49] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:31:49] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:31:52] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:31:52] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:40:40] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:40:40] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:40:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:40:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:41:50] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:41:50] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:41:53] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:41:53] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:41:54] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:46:24] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:46:24] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:46:28] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:46:28] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:48:39] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:48:39] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:48:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:48:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:49:27] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:49:27] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:49:31] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:49:31] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:49:56] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:49:56] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:50:00] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:50:00] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:50:00] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:50:01] __main__ INFO: [0mEpoch 0 loss 16761.8818 acc@1 0.1000 acc@5 0.5000
[32m[2022-06-11 09:50:01] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 09:50:01] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 09:51:35] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:51:35] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:51:39] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:51:39] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:51:39] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:52:14] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:52:14] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:52:22] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:52:22] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:52:26] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:52:26] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:53:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 160
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 09:53:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 09:53:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 09:53:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 09:53:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 09:53:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 09:53:34] __main__ INFO: [0mElapsed 1.07
[32m[2022-06-11 09:53:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 09:53:38] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6737 (1.1222) acc@1 0.8047 (0.6043) acc@5 0.9922 (0.9480)
[32m[2022-06-11 09:53:42] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6866 (0.9273) acc@1 0.7734 (0.6747) acc@5 0.9922 (0.9646)
[32m[2022-06-11 09:53:46] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6710 (0.8345) acc@1 0.7500 (0.7083) acc@5 1.0000 (0.9722)
[32m[2022-06-11 09:53:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5345 (0.7789) acc@1 0.8516 (0.7280) acc@5 0.9922 (0.9758)
[32m[2022-06-11 09:53:50] __main__ INFO: [0mElapsed 16.10
[32m[2022-06-11 09:53:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 09:53:51] __main__ INFO: [0mEpoch 1 loss 0.7673 acc@1 0.7416 acc@5 0.9840
[32m[2022-06-11 09:53:51] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:53:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 09:53:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6133 (0.5385) acc@1 0.7891 (0.8152) acc@5 0.9922 (0.9912)
[32m[2022-06-11 09:53:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4462 (0.5285) acc@1 0.8594 (0.8192) acc@5 1.0000 (0.9910)
[32m[2022-06-11 09:54:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3723 (0.5239) acc@1 0.8672 (0.8203) acc@5 0.9922 (0.9910)
[32m[2022-06-11 09:54:07] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4450 (0.5197) acc@1 0.8047 (0.8212) acc@5 1.0000 (0.9911)
[32m[2022-06-11 09:54:07] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 09:54:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 09:54:08] __main__ INFO: [0mEpoch 2 loss 0.6593 acc@1 0.7904 acc@5 0.9852
[32m[2022-06-11 09:54:08] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:54:08] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 09:54:12] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.3870 (0.4540) acc@1 0.8359 (0.8427) acc@5 0.9766 (0.9943)
[32m[2022-06-11 09:54:16] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4824 (0.4590) acc@1 0.8359 (0.8407) acc@5 0.9922 (0.9936)
[32m[2022-06-11 09:54:20] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6466 (0.4524) acc@1 0.7578 (0.8429) acc@5 0.9844 (0.9936)
[32m[2022-06-11 09:54:24] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5034 (0.4538) acc@1 0.8281 (0.8420) acc@5 1.0000 (0.9934)
[32m[2022-06-11 09:54:24] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 09:54:24] __main__ INFO: [0mVal 3
[32m[2022-06-11 09:54:25] __main__ INFO: [0mEpoch 3 loss 0.5483 acc@1 0.8188 acc@5 0.9891
[32m[2022-06-11 09:54:25] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:54:25] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 09:54:29] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3638 (0.4060) acc@1 0.8828 (0.8602) acc@5 1.0000 (0.9956)
[32m[2022-06-11 09:54:33] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4588 (0.4115) acc@1 0.8438 (0.8584) acc@5 1.0000 (0.9953)
[32m[2022-06-11 09:54:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.5021 (0.4133) acc@1 0.8203 (0.8588) acc@5 1.0000 (0.9948)
[32m[2022-06-11 09:54:40] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3403 (0.4129) acc@1 0.8750 (0.8584) acc@5 1.0000 (0.9943)
[32m[2022-06-11 09:54:40] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 09:54:40] __main__ INFO: [0mVal 4
[32m[2022-06-11 09:54:41] __main__ INFO: [0mEpoch 4 loss 0.5714 acc@1 0.8152 acc@5 0.9914
[32m[2022-06-11 09:54:41] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:54:41] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 09:54:45] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3706 (0.3736) acc@1 0.8750 (0.8724) acc@5 0.9922 (0.9960)
[32m[2022-06-11 09:54:49] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2914 (0.3719) acc@1 0.8984 (0.8723) acc@5 0.9922 (0.9961)
[32m[2022-06-11 09:54:53] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2328 (0.3769) acc@1 0.9453 (0.8708) acc@5 0.9922 (0.9955)
[32m[2022-06-11 09:54:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4291 (0.3776) acc@1 0.8594 (0.8705) acc@5 1.0000 (0.9954)
[32m[2022-06-11 09:54:57] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 09:54:57] __main__ INFO: [0mVal 5
[32m[2022-06-11 09:54:57] __main__ INFO: [0mEpoch 5 loss 0.5110 acc@1 0.8320 acc@5 0.9931
[32m[2022-06-11 09:54:57] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 09:54:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 09:55:02] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4245 (0.3538) acc@1 0.8203 (0.8777) acc@5 1.0000 (0.9963)
[32m[2022-06-11 09:55:06] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2674 (0.3568) acc@1 0.8984 (0.8763) acc@5 1.0000 (0.9962)
[32m[2022-06-11 09:55:10] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2773 (0.3548) acc@1 0.8828 (0.8771) acc@5 1.0000 (0.9961)
[32m[2022-06-11 09:55:13] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3538 (0.3564) acc@1 0.8906 (0.8764) acc@5 1.0000 (0.9960)
[32m[2022-06-11 09:55:13] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 09:55:13] __main__ INFO: [0mVal 6
[32m[2022-06-11 09:55:14] __main__ INFO: [0mEpoch 6 loss 0.5229 acc@1 0.8319 acc@5 0.9906
[32m[2022-06-11 09:55:14] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:55:14] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 09:55:18] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4397 (0.3269) acc@1 0.8516 (0.8870) acc@5 0.9922 (0.9964)
[32m[2022-06-11 09:55:22] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2563 (0.3368) acc@1 0.9297 (0.8845) acc@5 0.9922 (0.9961)
[32m[2022-06-11 09:55:26] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3956 (0.3374) acc@1 0.8750 (0.8837) acc@5 0.9922 (0.9963)
[32m[2022-06-11 09:55:30] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2600 (0.3372) acc@1 0.9141 (0.8831) acc@5 0.9922 (0.9964)
[32m[2022-06-11 09:55:30] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 09:55:30] __main__ INFO: [0mVal 7
[32m[2022-06-11 09:55:31] __main__ INFO: [0mEpoch 7 loss 0.6200 acc@1 0.8104 acc@5 0.9874
[32m[2022-06-11 09:55:31] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:55:31] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 09:55:35] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4133 (0.3188) acc@1 0.8359 (0.8893) acc@5 0.9844 (0.9966)
[32m[2022-06-11 09:55:39] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3322 (0.3282) acc@1 0.8750 (0.8873) acc@5 1.0000 (0.9964)
[32m[2022-06-11 09:55:43] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3693 (0.3287) acc@1 0.8828 (0.8868) acc@5 0.9922 (0.9963)
[32m[2022-06-11 09:55:46] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3040 (0.3263) acc@1 0.9375 (0.8875) acc@5 0.9922 (0.9965)
[32m[2022-06-11 09:55:46] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 09:55:46] __main__ INFO: [0mVal 8
[32m[2022-06-11 09:55:47] __main__ INFO: [0mEpoch 8 loss 0.4959 acc@1 0.8433 acc@5 0.9915
[32m[2022-06-11 09:55:47] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:55:47] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 09:55:51] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3766 (0.2999) acc@1 0.8828 (0.8962) acc@5 0.9844 (0.9974)
[32m[2022-06-11 09:55:56] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2971 (0.3073) acc@1 0.9219 (0.8925) acc@5 1.0000 (0.9973)
[32m[2022-06-11 09:55:59] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4753 (0.3109) acc@1 0.8438 (0.8920) acc@5 1.0000 (0.9970)
[32m[2022-06-11 09:56:03] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2710 (0.3105) acc@1 0.8984 (0.8926) acc@5 1.0000 (0.9968)
[32m[2022-06-11 09:56:03] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 09:56:03] __main__ INFO: [0mVal 9
[32m[2022-06-11 09:56:04] __main__ INFO: [0mEpoch 9 loss 0.4733 acc@1 0.8490 acc@5 0.9934
[32m[2022-06-11 09:56:04] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 09:56:04] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 09:56:08] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3147 (0.2934) acc@1 0.8984 (0.8985) acc@5 0.9844 (0.9973)
[32m[2022-06-11 09:56:12] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3431 (0.2985) acc@1 0.9062 (0.8978) acc@5 0.9922 (0.9970)
[32m[2022-06-11 09:56:16] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2463 (0.2971) acc@1 0.9219 (0.8973) acc@5 1.0000 (0.9971)
[32m[2022-06-11 09:56:19] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2263 (0.3026) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9969)
[32m[2022-06-11 09:56:20] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 09:56:20] __main__ INFO: [0mVal 10
[32m[2022-06-11 09:56:20] __main__ INFO: [0mEpoch 10 loss 0.5039 acc@1 0.8431 acc@5 0.9935
[32m[2022-06-11 09:56:20] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:56:20] __main__ INFO: [0mTrain 11 3900
[32m[2022-06-11 09:56:25] __main__ INFO: [0mEpoch 11 Step 100/390 lr 0.100000 loss 0.3778 (0.2642) acc@1 0.8359 (0.9076) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:56:29] __main__ INFO: [0mEpoch 11 Step 200/390 lr 0.100000 loss 0.3571 (0.2753) acc@1 0.8984 (0.9041) acc@5 0.9922 (0.9979)
[32m[2022-06-11 09:56:33] __main__ INFO: [0mEpoch 11 Step 300/390 lr 0.100000 loss 0.2886 (0.2799) acc@1 0.8984 (0.9030) acc@5 1.0000 (0.9976)
[32m[2022-06-11 09:56:36] __main__ INFO: [0mEpoch 11 Step 390/390 lr 0.100000 loss 0.4592 (0.2862) acc@1 0.8281 (0.9007) acc@5 1.0000 (0.9974)
[32m[2022-06-11 09:56:36] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 09:56:36] __main__ INFO: [0mVal 11
[32m[2022-06-11 09:56:37] __main__ INFO: [0mEpoch 11 loss 0.4441 acc@1 0.8593 acc@5 0.9932
[32m[2022-06-11 09:56:37] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:56:37] __main__ INFO: [0mTrain 12 4290
[32m[2022-06-11 09:56:41] __main__ INFO: [0mEpoch 12 Step 100/390 lr 0.100000 loss 0.2452 (0.2715) acc@1 0.9219 (0.9035) acc@5 1.0000 (0.9972)
[32m[2022-06-11 09:56:45] __main__ INFO: [0mEpoch 12 Step 200/390 lr 0.100000 loss 0.3847 (0.2758) acc@1 0.8750 (0.9046) acc@5 1.0000 (0.9969)
[32m[2022-06-11 09:56:49] __main__ INFO: [0mEpoch 12 Step 300/390 lr 0.100000 loss 0.2670 (0.2776) acc@1 0.8984 (0.9045) acc@5 0.9922 (0.9969)
[32m[2022-06-11 09:56:53] __main__ INFO: [0mEpoch 12 Step 390/390 lr 0.100000 loss 0.2926 (0.2829) acc@1 0.9141 (0.9030) acc@5 1.0000 (0.9968)
[32m[2022-06-11 09:56:53] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 09:56:53] __main__ INFO: [0mVal 12
[32m[2022-06-11 09:56:54] __main__ INFO: [0mEpoch 12 loss 0.4671 acc@1 0.8482 acc@5 0.9934
[32m[2022-06-11 09:56:54] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 09:56:54] __main__ INFO: [0mTrain 13 4680
[32m[2022-06-11 09:56:58] __main__ INFO: [0mEpoch 13 Step 100/390 lr 0.100000 loss 0.2534 (0.2630) acc@1 0.9062 (0.9101) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:02] __main__ INFO: [0mEpoch 13 Step 200/390 lr 0.100000 loss 0.3493 (0.2658) acc@1 0.8906 (0.9078) acc@5 0.9922 (0.9978)
[32m[2022-06-11 09:57:06] __main__ INFO: [0mEpoch 13 Step 300/390 lr 0.100000 loss 0.2027 (0.2701) acc@1 0.9297 (0.9066) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:10] __main__ INFO: [0mEpoch 13 Step 390/390 lr 0.100000 loss 0.3353 (0.2731) acc@1 0.8672 (0.9056) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:10] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 09:57:10] __main__ INFO: [0mVal 13
[32m[2022-06-11 09:57:11] __main__ INFO: [0mEpoch 13 loss 0.4527 acc@1 0.8561 acc@5 0.9943
[32m[2022-06-11 09:57:11] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:57:11] __main__ INFO: [0mTrain 14 5070
[32m[2022-06-11 09:57:15] __main__ INFO: [0mEpoch 14 Step 100/390 lr 0.100000 loss 0.1080 (0.2505) acc@1 0.9688 (0.9129) acc@5 1.0000 (0.9976)
[32m[2022-06-11 09:57:19] __main__ INFO: [0mEpoch 14 Step 200/390 lr 0.100000 loss 0.2212 (0.2575) acc@1 0.9297 (0.9107) acc@5 0.9922 (0.9977)
[32m[2022-06-11 09:57:23] __main__ INFO: [0mEpoch 14 Step 300/390 lr 0.100000 loss 0.1798 (0.2613) acc@1 0.9453 (0.9097) acc@5 1.0000 (0.9977)
[32m[2022-06-11 09:57:26] __main__ INFO: [0mEpoch 14 Step 390/390 lr 0.100000 loss 0.3119 (0.2643) acc@1 0.8906 (0.9083) acc@5 0.9922 (0.9975)
[32m[2022-06-11 09:57:26] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 09:57:26] __main__ INFO: [0mVal 14
[32m[2022-06-11 09:57:27] __main__ INFO: [0mEpoch 14 loss 0.4985 acc@1 0.8424 acc@5 0.9919
[32m[2022-06-11 09:57:27] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:57:27] __main__ INFO: [0mTrain 15 5460
[32m[2022-06-11 09:57:31] __main__ INFO: [0mEpoch 15 Step 100/390 lr 0.100000 loss 0.2765 (0.2426) acc@1 0.9297 (0.9161) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:57:35] __main__ INFO: [0mEpoch 15 Step 200/390 lr 0.100000 loss 0.2194 (0.2493) acc@1 0.9219 (0.9147) acc@5 1.0000 (0.9981)
[32m[2022-06-11 09:57:39] __main__ INFO: [0mEpoch 15 Step 300/390 lr 0.100000 loss 0.2947 (0.2537) acc@1 0.9141 (0.9124) acc@5 0.9922 (0.9979)
[32m[2022-06-11 09:57:43] __main__ INFO: [0mEpoch 15 Step 390/390 lr 0.100000 loss 0.2358 (0.2571) acc@1 0.9062 (0.9114) acc@5 1.0000 (0.9980)
[32m[2022-06-11 09:57:43] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 09:57:43] __main__ INFO: [0mVal 15
[32m[2022-06-11 09:57:44] __main__ INFO: [0mEpoch 15 loss 0.4242 acc@1 0.8656 acc@5 0.9938
[32m[2022-06-11 09:57:44] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:57:44] __main__ INFO: [0mTrain 16 5850
[32m[2022-06-11 09:57:48] __main__ INFO: [0mEpoch 16 Step 100/390 lr 0.100000 loss 0.2836 (0.2382) acc@1 0.9062 (0.9158) acc@5 0.9922 (0.9978)
[32m[2022-06-11 09:57:52] __main__ INFO: [0mEpoch 16 Step 200/390 lr 0.100000 loss 0.2538 (0.2501) acc@1 0.8984 (0.9114) acc@5 0.9922 (0.9976)
[32m[2022-06-11 09:57:56] __main__ INFO: [0mEpoch 16 Step 300/390 lr 0.100000 loss 0.1840 (0.2512) acc@1 0.9297 (0.9117) acc@5 1.0000 (0.9978)
[32m[2022-06-11 09:57:59] __main__ INFO: [0mEpoch 16 Step 390/390 lr 0.100000 loss 0.2013 (0.2529) acc@1 0.9297 (0.9113) acc@5 1.0000 (0.9978)
[32m[2022-06-11 09:58:00] __main__ INFO: [0mElapsed 15.56
[32m[2022-06-11 09:58:00] __main__ INFO: [0mVal 16
[32m[2022-06-11 09:58:01] __main__ INFO: [0mEpoch 16 loss 0.5293 acc@1 0.8414 acc@5 0.9895
[32m[2022-06-11 09:58:01] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:58:01] __main__ INFO: [0mTrain 17 6240
[32m[2022-06-11 09:58:05] __main__ INFO: [0mEpoch 17 Step 100/390 lr 0.100000 loss 0.3087 (0.2463) acc@1 0.9141 (0.9148) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:58:09] __main__ INFO: [0mEpoch 17 Step 200/390 lr 0.100000 loss 0.3197 (0.2479) acc@1 0.8984 (0.9148) acc@5 0.9922 (0.9980)
[32m[2022-06-11 09:58:13] __main__ INFO: [0mEpoch 17 Step 300/390 lr 0.100000 loss 0.5097 (0.2531) acc@1 0.8125 (0.9122) acc@5 1.0000 (0.9981)
[32m[2022-06-11 09:58:16] __main__ INFO: [0mEpoch 17 Step 390/390 lr 0.100000 loss 0.1541 (0.2525) acc@1 0.9609 (0.9124) acc@5 0.9922 (0.9981)
[32m[2022-06-11 09:58:16] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 09:58:16] __main__ INFO: [0mVal 17
[32m[2022-06-11 09:58:17] __main__ INFO: [0mEpoch 17 loss 0.4396 acc@1 0.8584 acc@5 0.9936
[32m[2022-06-11 09:58:17] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:58:17] __main__ INFO: [0mTrain 18 6630
[32m[2022-06-11 09:58:21] __main__ INFO: [0mEpoch 18 Step 100/390 lr 0.100000 loss 0.3825 (0.2298) acc@1 0.8828 (0.9193) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:58:25] __main__ INFO: [0mEpoch 18 Step 200/390 lr 0.100000 loss 0.3288 (0.2344) acc@1 0.8984 (0.9167) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:58:29] __main__ INFO: [0mEpoch 18 Step 300/390 lr 0.100000 loss 0.2586 (0.2370) acc@1 0.8906 (0.9166) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:58:33] __main__ INFO: [0mEpoch 18 Step 390/390 lr 0.100000 loss 0.2421 (0.2443) acc@1 0.9453 (0.9141) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:58:33] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:58:33] __main__ INFO: [0mVal 18
[32m[2022-06-11 09:58:34] __main__ INFO: [0mEpoch 18 loss 0.4365 acc@1 0.8644 acc@5 0.9945
[32m[2022-06-11 09:58:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 09:58:34] __main__ INFO: [0mTrain 19 7020
[32m[2022-06-11 09:58:38] __main__ INFO: [0mEpoch 19 Step 100/390 lr 0.100000 loss 0.1901 (0.2104) acc@1 0.9141 (0.9274) acc@5 1.0000 (0.9987)
[32m[2022-06-11 09:58:42] __main__ INFO: [0mEpoch 19 Step 200/390 lr 0.100000 loss 0.3619 (0.2215) acc@1 0.8750 (0.9235) acc@5 0.9922 (0.9985)
[32m[2022-06-11 09:58:46] __main__ INFO: [0mEpoch 19 Step 300/390 lr 0.100000 loss 0.2559 (0.2276) acc@1 0.9219 (0.9206) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:58:49] __main__ INFO: [0mEpoch 19 Step 390/390 lr 0.100000 loss 0.3109 (0.2328) acc@1 0.8750 (0.9185) acc@5 0.9922 (0.9982)
[32m[2022-06-11 09:58:49] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 09:58:49] __main__ INFO: [0mVal 19
[32m[2022-06-11 09:58:50] __main__ INFO: [0mEpoch 19 loss 0.3774 acc@1 0.8784 acc@5 0.9946
[32m[2022-06-11 09:58:50] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 09:58:50] __main__ INFO: [0mTrain 20 7410
[32m[2022-06-11 09:58:55] __main__ INFO: [0mEpoch 20 Step 100/390 lr 0.100000 loss 0.2223 (0.2269) acc@1 0.9297 (0.9200) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:58:59] __main__ INFO: [0mEpoch 20 Step 200/390 lr 0.100000 loss 0.2705 (0.2316) acc@1 0.9062 (0.9187) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:59:03] __main__ INFO: [0mEpoch 20 Step 300/390 lr 0.100000 loss 0.1986 (0.2356) acc@1 0.9375 (0.9174) acc@5 0.9922 (0.9982)
[32m[2022-06-11 09:59:07] __main__ INFO: [0mEpoch 20 Step 390/390 lr 0.100000 loss 0.1408 (0.2381) acc@1 0.9531 (0.9170) acc@5 1.0000 (0.9982)
[32m[2022-06-11 09:59:07] __main__ INFO: [0mElapsed 16.32
[32m[2022-06-11 09:59:07] __main__ INFO: [0mVal 20
[32m[2022-06-11 09:59:08] __main__ INFO: [0mEpoch 20 loss 0.4564 acc@1 0.8569 acc@5 0.9947
[32m[2022-06-11 09:59:08] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 09:59:08] __main__ INFO: [0mTrain 21 7800
[32m[2022-06-11 09:59:12] __main__ INFO: [0mEpoch 21 Step 100/390 lr 0.100000 loss 0.1707 (0.2163) acc@1 0.9531 (0.9220) acc@5 1.0000 (0.9983)
[32m[2022-06-11 09:59:16] __main__ INFO: [0mEpoch 21 Step 200/390 lr 0.100000 loss 0.1988 (0.2241) acc@1 0.9219 (0.9199) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:20] __main__ INFO: [0mEpoch 21 Step 300/390 lr 0.100000 loss 0.3306 (0.2283) acc@1 0.9062 (0.9183) acc@5 0.9844 (0.9985)
[32m[2022-06-11 09:59:23] __main__ INFO: [0mEpoch 21 Step 390/390 lr 0.100000 loss 0.3509 (0.2326) acc@1 0.8672 (0.9174) acc@5 1.0000 (0.9984)
[32m[2022-06-11 09:59:23] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:59:23] __main__ INFO: [0mVal 21
[32m[2022-06-11 09:59:24] __main__ INFO: [0mEpoch 21 loss 0.4912 acc@1 0.8528 acc@5 0.9932
[32m[2022-06-11 09:59:24] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 09:59:24] __main__ INFO: [0mTrain 22 8190
[32m[2022-06-11 09:59:28] __main__ INFO: [0mEpoch 22 Step 100/390 lr 0.100000 loss 0.2923 (0.2092) acc@1 0.9062 (0.9288) acc@5 1.0000 (0.9988)
[32m[2022-06-11 09:59:32] __main__ INFO: [0mEpoch 22 Step 200/390 lr 0.100000 loss 0.2052 (0.2269) acc@1 0.9062 (0.9220) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:36] __main__ INFO: [0mEpoch 22 Step 300/390 lr 0.100000 loss 0.1581 (0.2299) acc@1 0.9297 (0.9211) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:40] __main__ INFO: [0mEpoch 22 Step 390/390 lr 0.100000 loss 0.3109 (0.2303) acc@1 0.9297 (0.9210) acc@5 0.9922 (0.9985)
[32m[2022-06-11 09:59:40] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 09:59:40] __main__ INFO: [0mVal 22
[32m[2022-06-11 09:59:41] __main__ INFO: [0mEpoch 22 loss 0.3968 acc@1 0.8791 acc@5 0.9952
[32m[2022-06-11 09:59:41] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 09:59:41] __main__ INFO: [0mTrain 23 8580
[32m[2022-06-11 09:59:45] __main__ INFO: [0mEpoch 23 Step 100/390 lr 0.100000 loss 0.2176 (0.2012) acc@1 0.9219 (0.9317) acc@5 1.0000 (0.9988)
[32m[2022-06-11 09:59:49] __main__ INFO: [0mEpoch 23 Step 200/390 lr 0.100000 loss 0.2428 (0.2105) acc@1 0.9219 (0.9268) acc@5 0.9922 (0.9986)
[32m[2022-06-11 09:59:53] __main__ INFO: [0mEpoch 23 Step 300/390 lr 0.100000 loss 0.3369 (0.2157) acc@1 0.8906 (0.9245) acc@5 1.0000 (0.9986)
[32m[2022-06-11 09:59:56] __main__ INFO: [0mEpoch 23 Step 390/390 lr 0.100000 loss 0.1396 (0.2228) acc@1 0.9219 (0.9221) acc@5 1.0000 (0.9985)
[32m[2022-06-11 09:59:56] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 09:59:56] __main__ INFO: [0mVal 23
[32m[2022-06-11 09:59:57] __main__ INFO: [0mEpoch 23 loss 0.4814 acc@1 0.8582 acc@5 0.9936
[32m[2022-06-11 09:59:57] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 09:59:57] __main__ INFO: [0mTrain 24 8970
[32m[2022-06-11 10:00:01] __main__ INFO: [0mEpoch 24 Step 100/390 lr 0.100000 loss 0.2640 (0.2123) acc@1 0.9219 (0.9257) acc@5 0.9922 (0.9984)
[32m[2022-06-11 10:00:05] __main__ INFO: [0mEpoch 24 Step 200/390 lr 0.100000 loss 0.2256 (0.2186) acc@1 0.8984 (0.9221) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:09] __main__ INFO: [0mEpoch 24 Step 300/390 lr 0.100000 loss 0.2190 (0.2230) acc@1 0.9219 (0.9201) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:13] __main__ INFO: [0mEpoch 24 Step 390/390 lr 0.100000 loss 0.2595 (0.2266) acc@1 0.9141 (0.9193) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:13] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:00:13] __main__ INFO: [0mVal 24
[32m[2022-06-11 10:00:14] __main__ INFO: [0mEpoch 24 loss 0.4320 acc@1 0.8675 acc@5 0.9939
[32m[2022-06-11 10:00:14] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:00:14] __main__ INFO: [0mTrain 25 9360
[32m[2022-06-11 10:00:18] __main__ INFO: [0mEpoch 25 Step 100/390 lr 0.100000 loss 0.1483 (0.2158) acc@1 0.9609 (0.9260) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:22] __main__ INFO: [0mEpoch 25 Step 200/390 lr 0.100000 loss 0.2036 (0.2200) acc@1 0.9375 (0.9241) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:26] __main__ INFO: [0mEpoch 25 Step 300/390 lr 0.100000 loss 0.2547 (0.2236) acc@1 0.8828 (0.9220) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:29] __main__ INFO: [0mEpoch 25 Step 390/390 lr 0.100000 loss 0.2811 (0.2238) acc@1 0.9062 (0.9218) acc@5 0.9922 (0.9984)
[32m[2022-06-11 10:00:29] __main__ INFO: [0mElapsed 15.53
[32m[2022-06-11 10:00:29] __main__ INFO: [0mVal 25
[32m[2022-06-11 10:00:30] __main__ INFO: [0mEpoch 25 loss 0.4351 acc@1 0.8652 acc@5 0.9954
[32m[2022-06-11 10:00:30] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:00:30] __main__ INFO: [0mTrain 26 9750
[32m[2022-06-11 10:00:34] __main__ INFO: [0mEpoch 26 Step 100/390 lr 0.100000 loss 0.2207 (0.1958) acc@1 0.9297 (0.9322) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:00:38] __main__ INFO: [0mEpoch 26 Step 200/390 lr 0.100000 loss 0.2122 (0.2074) acc@1 0.9375 (0.9270) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:00:42] __main__ INFO: [0mEpoch 26 Step 300/390 lr 0.100000 loss 0.2799 (0.2132) acc@1 0.9453 (0.9246) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:00:46] __main__ INFO: [0mEpoch 26 Step 390/390 lr 0.100000 loss 0.1616 (0.2157) acc@1 0.9297 (0.9238) acc@5 1.0000 (0.9985)
[32m[2022-06-11 10:00:46] __main__ INFO: [0mElapsed 15.56
[32m[2022-06-11 10:00:46] __main__ INFO: [0mVal 26
[32m[2022-06-11 10:00:47] __main__ INFO: [0mEpoch 26 loss 0.4064 acc@1 0.8751 acc@5 0.9946
[32m[2022-06-11 10:00:47] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:00:47] __main__ INFO: [0mTrain 27 10140
[32m[2022-06-11 10:00:51] __main__ INFO: [0mEpoch 27 Step 100/390 lr 0.100000 loss 0.2962 (0.1829) acc@1 0.9062 (0.9359) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:00:55] __main__ INFO: [0mEpoch 27 Step 200/390 lr 0.100000 loss 0.2471 (0.1973) acc@1 0.9062 (0.9318) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:00:59] __main__ INFO: [0mEpoch 27 Step 300/390 lr 0.100000 loss 0.2016 (0.2016) acc@1 0.9375 (0.9293) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:01:02] __main__ INFO: [0mEpoch 27 Step 390/390 lr 0.100000 loss 0.2381 (0.2080) acc@1 0.8984 (0.9275) acc@5 1.0000 (0.9987)
[32m[2022-06-11 10:01:02] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 10:01:02] __main__ INFO: [0mVal 27
[32m[2022-06-11 10:01:03] __main__ INFO: [0mEpoch 27 loss 0.4610 acc@1 0.8660 acc@5 0.9921
[32m[2022-06-11 10:01:03] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:01:03] __main__ INFO: [0mTrain 28 10530
[32m[2022-06-11 10:01:07] __main__ INFO: [0mEpoch 28 Step 100/390 lr 0.100000 loss 0.1918 (0.2094) acc@1 0.9609 (0.9268) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:01:11] __main__ INFO: [0mEpoch 28 Step 200/390 lr 0.100000 loss 0.3197 (0.2079) acc@1 0.8750 (0.9261) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:15] __main__ INFO: [0mEpoch 28 Step 300/390 lr 0.100000 loss 0.2019 (0.2101) acc@1 0.9219 (0.9263) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:01:19] __main__ INFO: [0mEpoch 28 Step 390/390 lr 0.100000 loss 0.1922 (0.2099) acc@1 0.9141 (0.9263) acc@5 1.0000 (0.9986)
[32m[2022-06-11 10:01:19] __main__ INFO: [0mElapsed 15.55
[32m[2022-06-11 10:01:19] __main__ INFO: [0mVal 28
[32m[2022-06-11 10:01:20] __main__ INFO: [0mEpoch 28 loss 0.4958 acc@1 0.8564 acc@5 0.9928
[32m[2022-06-11 10:01:20] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:01:20] __main__ INFO: [0mTrain 29 10920
[32m[2022-06-11 10:01:24] __main__ INFO: [0mEpoch 29 Step 100/390 lr 0.100000 loss 0.2178 (0.1924) acc@1 0.9219 (0.9321) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:01:28] __main__ INFO: [0mEpoch 29 Step 200/390 lr 0.100000 loss 0.2210 (0.2002) acc@1 0.9297 (0.9295) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:32] __main__ INFO: [0mEpoch 29 Step 300/390 lr 0.100000 loss 0.3052 (0.2045) acc@1 0.9141 (0.9283) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:01:35] __main__ INFO: [0mEpoch 29 Step 390/390 lr 0.100000 loss 0.2727 (0.2092) acc@1 0.9297 (0.9270) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:35] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:01:35] __main__ INFO: [0mVal 29
[32m[2022-06-11 10:01:36] __main__ INFO: [0mEpoch 29 loss 0.5581 acc@1 0.8409 acc@5 0.9924
[32m[2022-06-11 10:01:36] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:01:36] __main__ INFO: [0mTrain 30 11310
[32m[2022-06-11 10:01:41] __main__ INFO: [0mEpoch 30 Step 100/390 lr 0.100000 loss 0.1827 (0.1978) acc@1 0.9375 (0.9315) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:01:44] __main__ INFO: [0mEpoch 30 Step 200/390 lr 0.100000 loss 0.1548 (0.2004) acc@1 0.9375 (0.9299) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:01:48] __main__ INFO: [0mEpoch 30 Step 300/390 lr 0.100000 loss 0.1607 (0.2051) acc@1 0.9297 (0.9287) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:52] __main__ INFO: [0mEpoch 30 Step 390/390 lr 0.100000 loss 0.2667 (0.2067) acc@1 0.8984 (0.9277) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:01:52] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:01:52] __main__ INFO: [0mVal 30
[32m[2022-06-11 10:01:53] __main__ INFO: [0mEpoch 30 loss 0.4164 acc@1 0.8700 acc@5 0.9945
[32m[2022-06-11 10:01:53] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:01:53] __main__ INFO: [0mTrain 31 11700
[32m[2022-06-11 10:01:57] __main__ INFO: [0mEpoch 31 Step 100/390 lr 0.100000 loss 0.2197 (0.1952) acc@1 0.9375 (0.9316) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:02:01] __main__ INFO: [0mEpoch 31 Step 200/390 lr 0.100000 loss 0.1855 (0.2028) acc@1 0.9297 (0.9300) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:05] __main__ INFO: [0mEpoch 31 Step 300/390 lr 0.100000 loss 0.2148 (0.2064) acc@1 0.9062 (0.9276) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:09] __main__ INFO: [0mEpoch 31 Step 390/390 lr 0.100000 loss 0.1806 (0.2105) acc@1 0.9219 (0.9262) acc@5 1.0000 (0.9988)
[32m[2022-06-11 10:02:09] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 10:02:09] __main__ INFO: [0mVal 31
[32m[2022-06-11 10:02:10] __main__ INFO: [0mEpoch 31 loss 0.3997 acc@1 0.8771 acc@5 0.9951
[32m[2022-06-11 10:02:10] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:02:10] __main__ INFO: [0mTrain 32 12090
[32m[2022-06-11 10:02:14] __main__ INFO: [0mEpoch 32 Step 100/390 lr 0.100000 loss 0.1306 (0.1904) acc@1 0.9531 (0.9348) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:18] __main__ INFO: [0mEpoch 32 Step 200/390 lr 0.100000 loss 0.1924 (0.1948) acc@1 0.9219 (0.9333) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:02:22] __main__ INFO: [0mEpoch 32 Step 300/390 lr 0.100000 loss 0.2958 (0.1998) acc@1 0.9297 (0.9305) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:26] __main__ INFO: [0mEpoch 32 Step 390/390 lr 0.100000 loss 0.1743 (0.2026) acc@1 0.9219 (0.9288) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:02:26] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 10:02:26] __main__ INFO: [0mVal 32
[32m[2022-06-11 10:02:27] __main__ INFO: [0mEpoch 32 loss 0.4223 acc@1 0.8786 acc@5 0.9954
[32m[2022-06-11 10:02:27] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:02:27] __main__ INFO: [0mTrain 33 12480
[32m[2022-06-11 10:02:31] __main__ INFO: [0mEpoch 33 Step 100/390 lr 0.100000 loss 0.1936 (0.1829) acc@1 0.9297 (0.9362) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:35] __main__ INFO: [0mEpoch 33 Step 200/390 lr 0.100000 loss 0.3342 (0.1909) acc@1 0.8984 (0.9341) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:02:39] __main__ INFO: [0mEpoch 33 Step 300/390 lr 0.100000 loss 0.1701 (0.1961) acc@1 0.9375 (0.9311) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:42] __main__ INFO: [0mEpoch 33 Step 390/390 lr 0.100000 loss 0.2334 (0.2034) acc@1 0.9219 (0.9284) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:42] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:02:42] __main__ INFO: [0mVal 33
[32m[2022-06-11 10:02:43] __main__ INFO: [0mEpoch 33 loss 0.4228 acc@1 0.8734 acc@5 0.9954
[32m[2022-06-11 10:02:43] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:02:43] __main__ INFO: [0mTrain 34 12870
[32m[2022-06-11 10:02:47] __main__ INFO: [0mEpoch 34 Step 100/390 lr 0.100000 loss 0.1577 (0.1904) acc@1 0.9375 (0.9362) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:02:51] __main__ INFO: [0mEpoch 34 Step 200/390 lr 0.100000 loss 0.3170 (0.1905) acc@1 0.8672 (0.9330) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:02:55] __main__ INFO: [0mEpoch 34 Step 300/390 lr 0.100000 loss 0.1309 (0.1966) acc@1 0.9453 (0.9306) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:59] __main__ INFO: [0mEpoch 34 Step 390/390 lr 0.100000 loss 0.2791 (0.2001) acc@1 0.8906 (0.9289) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:02:59] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:02:59] __main__ INFO: [0mVal 34
[32m[2022-06-11 10:03:00] __main__ INFO: [0mEpoch 34 loss 0.4272 acc@1 0.8689 acc@5 0.9940
[32m[2022-06-11 10:03:00] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:03:00] __main__ INFO: [0mTrain 35 13260
[32m[2022-06-11 10:03:04] __main__ INFO: [0mEpoch 35 Step 100/390 lr 0.100000 loss 0.2388 (0.1837) acc@1 0.9141 (0.9379) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:03:08] __main__ INFO: [0mEpoch 35 Step 200/390 lr 0.100000 loss 0.2387 (0.1900) acc@1 0.9062 (0.9340) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:12] __main__ INFO: [0mEpoch 35 Step 300/390 lr 0.100000 loss 0.2687 (0.1965) acc@1 0.9453 (0.9315) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:03:16] __main__ INFO: [0mEpoch 35 Step 390/390 lr 0.100000 loss 0.2031 (0.2003) acc@1 0.9141 (0.9301) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:03:16] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 10:03:16] __main__ INFO: [0mVal 35
[32m[2022-06-11 10:03:17] __main__ INFO: [0mEpoch 35 loss 0.4054 acc@1 0.8770 acc@5 0.9956
[32m[2022-06-11 10:03:17] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:03:17] __main__ INFO: [0mTrain 36 13650
[32m[2022-06-11 10:03:21] __main__ INFO: [0mEpoch 36 Step 100/390 lr 0.100000 loss 0.0925 (0.1793) acc@1 0.9531 (0.9370) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:25] __main__ INFO: [0mEpoch 36 Step 200/390 lr 0.100000 loss 0.1553 (0.1852) acc@1 0.9297 (0.9345) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:03:29] __main__ INFO: [0mEpoch 36 Step 300/390 lr 0.100000 loss 0.2535 (0.1913) acc@1 0.9062 (0.9318) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:03:32] __main__ INFO: [0mEpoch 36 Step 390/390 lr 0.100000 loss 0.2743 (0.1955) acc@1 0.8984 (0.9311) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:03:32] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:03:32] __main__ INFO: [0mVal 36
[32m[2022-06-11 10:03:33] __main__ INFO: [0mEpoch 36 loss 0.3772 acc@1 0.8797 acc@5 0.9959
[32m[2022-06-11 10:03:33] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:03:33] __main__ INFO: [0mTrain 37 14040
[32m[2022-06-11 10:03:37] __main__ INFO: [0mEpoch 37 Step 100/390 lr 0.100000 loss 0.1979 (0.1819) acc@1 0.9141 (0.9353) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:03:41] __main__ INFO: [0mEpoch 37 Step 200/390 lr 0.100000 loss 0.1855 (0.1884) acc@1 0.9297 (0.9330) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:45] __main__ INFO: [0mEpoch 37 Step 300/390 lr 0.100000 loss 0.2755 (0.1912) acc@1 0.9219 (0.9326) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:49] __main__ INFO: [0mEpoch 37 Step 390/390 lr 0.100000 loss 0.0967 (0.1929) acc@1 0.9844 (0.9319) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:03:49] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 10:03:49] __main__ INFO: [0mVal 37
[32m[2022-06-11 10:03:50] __main__ INFO: [0mEpoch 37 loss 0.4156 acc@1 0.8763 acc@5 0.9949
[32m[2022-06-11 10:03:50] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:03:50] __main__ INFO: [0mTrain 38 14430
[32m[2022-06-11 10:03:54] __main__ INFO: [0mEpoch 38 Step 100/390 lr 0.100000 loss 0.1796 (0.1760) acc@1 0.9297 (0.9382) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:03:59] __main__ INFO: [0mEpoch 38 Step 200/390 lr 0.100000 loss 0.1583 (0.1833) acc@1 0.9453 (0.9358) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:04:03] __main__ INFO: [0mEpoch 38 Step 300/390 lr 0.100000 loss 0.2516 (0.1901) acc@1 0.9297 (0.9332) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:04:06] __main__ INFO: [0mEpoch 38 Step 390/390 lr 0.100000 loss 0.1651 (0.1965) acc@1 0.9453 (0.9308) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:06] __main__ INFO: [0mElapsed 16.26
[32m[2022-06-11 10:04:06] __main__ INFO: [0mVal 38
[32m[2022-06-11 10:04:07] __main__ INFO: [0mEpoch 38 loss 0.4688 acc@1 0.8599 acc@5 0.9940
[32m[2022-06-11 10:04:07] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:04:07] __main__ INFO: [0mTrain 39 14820
[32m[2022-06-11 10:04:12] __main__ INFO: [0mEpoch 39 Step 100/390 lr 0.100000 loss 0.1424 (0.1797) acc@1 0.9453 (0.9363) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:16] __main__ INFO: [0mEpoch 39 Step 200/390 lr 0.100000 loss 0.3179 (0.1899) acc@1 0.8594 (0.9323) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:04:20] __main__ INFO: [0mEpoch 39 Step 300/390 lr 0.100000 loss 0.1436 (0.1925) acc@1 0.9375 (0.9316) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:04:23] __main__ INFO: [0mEpoch 39 Step 390/390 lr 0.100000 loss 0.2037 (0.1955) acc@1 0.9453 (0.9310) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:04:23] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:04:23] __main__ INFO: [0mVal 39
[32m[2022-06-11 10:04:24] __main__ INFO: [0mEpoch 39 loss 0.4232 acc@1 0.8701 acc@5 0.9951
[32m[2022-06-11 10:04:24] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:04:24] __main__ INFO: [0mTrain 40 15210
[32m[2022-06-11 10:04:28] __main__ INFO: [0mEpoch 40 Step 100/390 lr 0.100000 loss 0.2878 (0.1744) acc@1 0.8984 (0.9397) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:04:32] __main__ INFO: [0mEpoch 40 Step 200/390 lr 0.100000 loss 0.2188 (0.1856) acc@1 0.9297 (0.9358) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:36] __main__ INFO: [0mEpoch 40 Step 300/390 lr 0.100000 loss 0.1971 (0.1897) acc@1 0.9375 (0.9339) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:04:40] __main__ INFO: [0mEpoch 40 Step 390/390 lr 0.100000 loss 0.2149 (0.1933) acc@1 0.9297 (0.9326) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:40] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:04:40] __main__ INFO: [0mVal 40
[32m[2022-06-11 10:04:41] __main__ INFO: [0mEpoch 40 loss 0.3929 acc@1 0.8760 acc@5 0.9955
[32m[2022-06-11 10:04:41] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:04:41] __main__ INFO: [0mTrain 41 15600
[32m[2022-06-11 10:04:45] __main__ INFO: [0mEpoch 41 Step 100/390 lr 0.100000 loss 0.1115 (0.1816) acc@1 0.9766 (0.9355) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:04:49] __main__ INFO: [0mEpoch 41 Step 200/390 lr 0.100000 loss 0.1483 (0.1864) acc@1 0.9453 (0.9334) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:04:53] __main__ INFO: [0mEpoch 41 Step 300/390 lr 0.100000 loss 0.2876 (0.1903) acc@1 0.8672 (0.9323) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:04:57] __main__ INFO: [0mEpoch 41 Step 390/390 lr 0.100000 loss 0.3327 (0.1921) acc@1 0.9219 (0.9317) acc@5 0.9922 (0.9989)
[32m[2022-06-11 10:04:57] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:04:57] __main__ INFO: [0mVal 41
[32m[2022-06-11 10:04:58] __main__ INFO: [0mEpoch 41 loss 0.4218 acc@1 0.8714 acc@5 0.9947
[32m[2022-06-11 10:04:58] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:04:58] __main__ INFO: [0mTrain 42 15990
[32m[2022-06-11 10:05:02] __main__ INFO: [0mEpoch 42 Step 100/390 lr 0.100000 loss 0.3850 (0.1839) acc@1 0.8359 (0.9380) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:05:06] __main__ INFO: [0mEpoch 42 Step 200/390 lr 0.100000 loss 0.1581 (0.1765) acc@1 0.9453 (0.9396) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:05:10] __main__ INFO: [0mEpoch 42 Step 300/390 lr 0.100000 loss 0.2368 (0.1817) acc@1 0.9297 (0.9372) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:05:13] __main__ INFO: [0mEpoch 42 Step 390/390 lr 0.100000 loss 0.2493 (0.1878) acc@1 0.9219 (0.9345) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:05:13] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 10:05:13] __main__ INFO: [0mVal 42
[32m[2022-06-11 10:05:14] __main__ INFO: [0mEpoch 42 loss 0.4103 acc@1 0.8779 acc@5 0.9953
[32m[2022-06-11 10:05:14] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:05:14] __main__ INFO: [0mTrain 43 16380
[32m[2022-06-11 10:05:19] __main__ INFO: [0mEpoch 43 Step 100/390 lr 0.100000 loss 0.2776 (0.1786) acc@1 0.9297 (0.9345) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:05:23] __main__ INFO: [0mEpoch 43 Step 200/390 lr 0.100000 loss 0.2200 (0.1868) acc@1 0.9297 (0.9334) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:26] __main__ INFO: [0mEpoch 43 Step 300/390 lr 0.100000 loss 0.2154 (0.1880) acc@1 0.9062 (0.9334) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:05:30] __main__ INFO: [0mEpoch 43 Step 390/390 lr 0.100000 loss 0.2582 (0.1914) acc@1 0.8984 (0.9320) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:05:30] __main__ INFO: [0mElapsed 15.87
[32m[2022-06-11 10:05:30] __main__ INFO: [0mVal 43
[32m[2022-06-11 10:05:31] __main__ INFO: [0mEpoch 43 loss 0.5084 acc@1 0.8622 acc@5 0.9936
[32m[2022-06-11 10:05:31] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:05:31] __main__ INFO: [0mTrain 44 16770
[32m[2022-06-11 10:05:35] __main__ INFO: [0mEpoch 44 Step 100/390 lr 0.100000 loss 0.1208 (0.1703) acc@1 0.9453 (0.9409) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:39] __main__ INFO: [0mEpoch 44 Step 200/390 lr 0.100000 loss 0.1179 (0.1782) acc@1 0.9688 (0.9377) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:05:43] __main__ INFO: [0mEpoch 44 Step 300/390 lr 0.100000 loss 0.1647 (0.1836) acc@1 0.9688 (0.9357) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:05:47] __main__ INFO: [0mEpoch 44 Step 390/390 lr 0.100000 loss 0.2235 (0.1863) acc@1 0.9297 (0.9347) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:05:47] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:05:47] __main__ INFO: [0mVal 44
[32m[2022-06-11 10:05:48] __main__ INFO: [0mEpoch 44 loss 0.4580 acc@1 0.8690 acc@5 0.9946
[32m[2022-06-11 10:05:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:05:48] __main__ INFO: [0mTrain 45 17160
[32m[2022-06-11 10:05:52] __main__ INFO: [0mEpoch 45 Step 100/390 lr 0.100000 loss 0.1519 (0.1650) acc@1 0.9375 (0.9432) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:05:56] __main__ INFO: [0mEpoch 45 Step 200/390 lr 0.100000 loss 0.1957 (0.1771) acc@1 0.9219 (0.9378) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:06:00] __main__ INFO: [0mEpoch 45 Step 300/390 lr 0.100000 loss 0.2230 (0.1845) acc@1 0.9141 (0.9360) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:04] __main__ INFO: [0mEpoch 45 Step 390/390 lr 0.100000 loss 0.1999 (0.1852) acc@1 0.9297 (0.9358) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:06:04] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:06:04] __main__ INFO: [0mVal 45
[32m[2022-06-11 10:06:05] __main__ INFO: [0mEpoch 45 loss 0.3907 acc@1 0.8825 acc@5 0.9967
[32m[2022-06-11 10:06:05] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:06:05] __main__ INFO: [0mTrain 46 17550
[32m[2022-06-11 10:06:09] __main__ INFO: [0mEpoch 46 Step 100/390 lr 0.100000 loss 0.1677 (0.1566) acc@1 0.9453 (0.9447) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:06:13] __main__ INFO: [0mEpoch 46 Step 200/390 lr 0.100000 loss 0.2985 (0.1689) acc@1 0.9062 (0.9402) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:06:17] __main__ INFO: [0mEpoch 46 Step 300/390 lr 0.100000 loss 0.0896 (0.1797) acc@1 0.9531 (0.9368) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:20] __main__ INFO: [0mEpoch 46 Step 390/390 lr 0.100000 loss 0.2303 (0.1832) acc@1 0.9219 (0.9353) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:20] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 10:06:20] __main__ INFO: [0mVal 46
[32m[2022-06-11 10:06:21] __main__ INFO: [0mEpoch 46 loss 0.4425 acc@1 0.8647 acc@5 0.9939
[32m[2022-06-11 10:06:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:06:21] __main__ INFO: [0mTrain 47 17940
[32m[2022-06-11 10:06:25] __main__ INFO: [0mEpoch 47 Step 100/390 lr 0.100000 loss 0.2178 (0.1695) acc@1 0.9141 (0.9415) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:29] __main__ INFO: [0mEpoch 47 Step 200/390 lr 0.100000 loss 0.1933 (0.1816) acc@1 0.9297 (0.9379) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:33] __main__ INFO: [0mEpoch 47 Step 300/390 lr 0.100000 loss 0.3105 (0.1862) acc@1 0.9062 (0.9351) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:37] __main__ INFO: [0mEpoch 47 Step 390/390 lr 0.100000 loss 0.1814 (0.1886) acc@1 0.9375 (0.9341) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:37] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:06:37] __main__ INFO: [0mVal 47
[32m[2022-06-11 10:06:38] __main__ INFO: [0mEpoch 47 loss 0.4524 acc@1 0.8668 acc@5 0.9920
[32m[2022-06-11 10:06:38] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:06:38] __main__ INFO: [0mTrain 48 18330
[32m[2022-06-11 10:06:42] __main__ INFO: [0mEpoch 48 Step 100/390 lr 0.100000 loss 0.1483 (0.1804) acc@1 0.9453 (0.9360) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:06:46] __main__ INFO: [0mEpoch 48 Step 200/390 lr 0.100000 loss 0.1792 (0.1800) acc@1 0.9375 (0.9362) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:50] __main__ INFO: [0mEpoch 48 Step 300/390 lr 0.100000 loss 0.1676 (0.1832) acc@1 0.9375 (0.9355) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:06:54] __main__ INFO: [0mEpoch 48 Step 390/390 lr 0.100000 loss 0.1512 (0.1830) acc@1 0.9453 (0.9358) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:06:54] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:06:54] __main__ INFO: [0mVal 48
[32m[2022-06-11 10:06:55] __main__ INFO: [0mEpoch 48 loss 0.4523 acc@1 0.8715 acc@5 0.9946
[32m[2022-06-11 10:06:55] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:06:55] __main__ INFO: [0mTrain 49 18720
[32m[2022-06-11 10:06:59] __main__ INFO: [0mEpoch 49 Step 100/390 lr 0.100000 loss 0.1473 (0.1686) acc@1 0.9531 (0.9405) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:03] __main__ INFO: [0mEpoch 49 Step 200/390 lr 0.100000 loss 0.2297 (0.1722) acc@1 0.8906 (0.9387) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:07] __main__ INFO: [0mEpoch 49 Step 300/390 lr 0.100000 loss 0.2212 (0.1798) acc@1 0.9141 (0.9367) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:10] __main__ INFO: [0mEpoch 49 Step 390/390 lr 0.100000 loss 0.1897 (0.1804) acc@1 0.9297 (0.9364) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:10] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:07:10] __main__ INFO: [0mVal 49
[32m[2022-06-11 10:07:11] __main__ INFO: [0mEpoch 49 loss 0.4338 acc@1 0.8710 acc@5 0.9948
[32m[2022-06-11 10:07:11] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:07:11] __main__ INFO: [0mTrain 50 19110
[32m[2022-06-11 10:07:15] __main__ INFO: [0mEpoch 50 Step 100/390 lr 0.100000 loss 0.1651 (0.1608) acc@1 0.9219 (0.9437) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:19] __main__ INFO: [0mEpoch 50 Step 200/390 lr 0.100000 loss 0.0937 (0.1710) acc@1 0.9609 (0.9393) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:23] __main__ INFO: [0mEpoch 50 Step 300/390 lr 0.100000 loss 0.2250 (0.1719) acc@1 0.9297 (0.9389) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:27] __main__ INFO: [0mEpoch 50 Step 390/390 lr 0.100000 loss 0.2063 (0.1785) acc@1 0.9219 (0.9366) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:27] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:07:27] __main__ INFO: [0mVal 50
[32m[2022-06-11 10:07:28] __main__ INFO: [0mEpoch 50 loss 0.4181 acc@1 0.8736 acc@5 0.9954
[32m[2022-06-11 10:07:28] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:07:28] __main__ INFO: [0mTrain 51 19500
[32m[2022-06-11 10:07:32] __main__ INFO: [0mEpoch 51 Step 100/390 lr 0.100000 loss 0.0999 (0.1558) acc@1 0.9609 (0.9446) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:36] __main__ INFO: [0mEpoch 51 Step 200/390 lr 0.100000 loss 0.1540 (0.1622) acc@1 0.9453 (0.9429) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:07:40] __main__ INFO: [0mEpoch 51 Step 300/390 lr 0.100000 loss 0.1172 (0.1710) acc@1 0.9688 (0.9401) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:07:44] __main__ INFO: [0mEpoch 51 Step 390/390 lr 0.100000 loss 0.1296 (0.1752) acc@1 0.9531 (0.9381) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:07:44] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:07:44] __main__ INFO: [0mVal 51
[32m[2022-06-11 10:07:44] __main__ INFO: [0mEpoch 51 loss 0.5047 acc@1 0.8587 acc@5 0.9935
[32m[2022-06-11 10:07:44] __main__ INFO: [0mElapsed 0.88
[32m[2022-06-11 10:07:44] __main__ INFO: [0mTrain 52 19890
[32m[2022-06-11 10:07:49] __main__ INFO: [0mEpoch 52 Step 100/390 lr 0.100000 loss 0.1697 (0.1621) acc@1 0.9531 (0.9424) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:07:53] __main__ INFO: [0mEpoch 52 Step 200/390 lr 0.100000 loss 0.1860 (0.1693) acc@1 0.9375 (0.9396) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:07:56] __main__ INFO: [0mEpoch 52 Step 300/390 lr 0.100000 loss 0.2052 (0.1763) acc@1 0.9453 (0.9371) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:00] __main__ INFO: [0mEpoch 52 Step 390/390 lr 0.100000 loss 0.2328 (0.1786) acc@1 0.9219 (0.9365) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:00] __main__ INFO: [0mElapsed 15.53
[32m[2022-06-11 10:08:00] __main__ INFO: [0mVal 52
[32m[2022-06-11 10:08:01] __main__ INFO: [0mEpoch 52 loss 0.5347 acc@1 0.8564 acc@5 0.9940
[32m[2022-06-11 10:08:01] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:08:01] __main__ INFO: [0mTrain 53 20280
[32m[2022-06-11 10:08:05] __main__ INFO: [0mEpoch 53 Step 100/390 lr 0.100000 loss 0.0901 (0.1650) acc@1 0.9688 (0.9424) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:08:09] __main__ INFO: [0mEpoch 53 Step 200/390 lr 0.100000 loss 0.1687 (0.1689) acc@1 0.9453 (0.9408) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:13] __main__ INFO: [0mEpoch 53 Step 300/390 lr 0.100000 loss 0.1484 (0.1790) acc@1 0.9453 (0.9369) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:17] __main__ INFO: [0mEpoch 53 Step 390/390 lr 0.100000 loss 0.2219 (0.1822) acc@1 0.9062 (0.9356) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:17] __main__ INFO: [0mElapsed 16.00
[32m[2022-06-11 10:08:17] __main__ INFO: [0mVal 53
[32m[2022-06-11 10:08:18] __main__ INFO: [0mEpoch 53 loss 0.4402 acc@1 0.8657 acc@5 0.9958
[32m[2022-06-11 10:08:18] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:08:18] __main__ INFO: [0mTrain 54 20670
[32m[2022-06-11 10:08:22] __main__ INFO: [0mEpoch 54 Step 100/390 lr 0.100000 loss 0.2007 (0.1632) acc@1 0.9375 (0.9425) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:26] __main__ INFO: [0mEpoch 54 Step 200/390 lr 0.100000 loss 0.1342 (0.1673) acc@1 0.9609 (0.9421) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:30] __main__ INFO: [0mEpoch 54 Step 300/390 lr 0.100000 loss 0.2482 (0.1771) acc@1 0.9219 (0.9384) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:08:33] __main__ INFO: [0mEpoch 54 Step 390/390 lr 0.100000 loss 0.1585 (0.1794) acc@1 0.9375 (0.9371) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:08:33] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:08:33] __main__ INFO: [0mVal 54
[32m[2022-06-11 10:08:34] __main__ INFO: [0mEpoch 54 loss 0.3966 acc@1 0.8816 acc@5 0.9946
[32m[2022-06-11 10:08:34] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:08:34] __main__ INFO: [0mTrain 55 21060
[32m[2022-06-11 10:08:39] __main__ INFO: [0mEpoch 55 Step 100/390 lr 0.100000 loss 0.1921 (0.1562) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:43] __main__ INFO: [0mEpoch 55 Step 200/390 lr 0.100000 loss 0.1993 (0.1639) acc@1 0.9141 (0.9417) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:08:46] __main__ INFO: [0mEpoch 55 Step 300/390 lr 0.100000 loss 0.1708 (0.1721) acc@1 0.9453 (0.9389) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:08:50] __main__ INFO: [0mEpoch 55 Step 390/390 lr 0.100000 loss 0.1495 (0.1741) acc@1 0.9531 (0.9384) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:08:50] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:08:50] __main__ INFO: [0mVal 55
[32m[2022-06-11 10:08:51] __main__ INFO: [0mEpoch 55 loss 0.4541 acc@1 0.8705 acc@5 0.9954
[32m[2022-06-11 10:08:51] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:08:51] __main__ INFO: [0mTrain 56 21450
[32m[2022-06-11 10:08:55] __main__ INFO: [0mEpoch 56 Step 100/390 lr 0.100000 loss 0.1482 (0.1601) acc@1 0.9453 (0.9433) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:08:59] __main__ INFO: [0mEpoch 56 Step 200/390 lr 0.100000 loss 0.1875 (0.1660) acc@1 0.9375 (0.9413) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:03] __main__ INFO: [0mEpoch 56 Step 300/390 lr 0.100000 loss 0.2170 (0.1720) acc@1 0.9062 (0.9394) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:09:07] __main__ INFO: [0mEpoch 56 Step 390/390 lr 0.100000 loss 0.2959 (0.1779) acc@1 0.8594 (0.9374) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:07] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:09:07] __main__ INFO: [0mVal 56
[32m[2022-06-11 10:09:08] __main__ INFO: [0mEpoch 56 loss 0.5320 acc@1 0.8482 acc@5 0.9941
[32m[2022-06-11 10:09:08] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:09:08] __main__ INFO: [0mTrain 57 21840
[32m[2022-06-11 10:09:12] __main__ INFO: [0mEpoch 57 Step 100/390 lr 0.100000 loss 0.0682 (0.1587) acc@1 0.9688 (0.9470) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:16] __main__ INFO: [0mEpoch 57 Step 200/390 lr 0.100000 loss 0.1411 (0.1619) acc@1 0.9453 (0.9455) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:20] __main__ INFO: [0mEpoch 57 Step 300/390 lr 0.100000 loss 0.2608 (0.1711) acc@1 0.9062 (0.9416) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:23] __main__ INFO: [0mEpoch 57 Step 390/390 lr 0.100000 loss 0.1162 (0.1737) acc@1 0.9609 (0.9406) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:09:23] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:09:23] __main__ INFO: [0mVal 57
[32m[2022-06-11 10:09:24] __main__ INFO: [0mEpoch 57 loss 0.4003 acc@1 0.8831 acc@5 0.9942
[32m[2022-06-11 10:09:24] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:09:24] __main__ INFO: [0mTrain 58 22230
[32m[2022-06-11 10:09:28] __main__ INFO: [0mEpoch 58 Step 100/390 lr 0.100000 loss 0.1705 (0.1586) acc@1 0.9375 (0.9434) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:09:32] __main__ INFO: [0mEpoch 58 Step 200/390 lr 0.100000 loss 0.1757 (0.1637) acc@1 0.9297 (0.9416) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:09:36] __main__ INFO: [0mEpoch 58 Step 300/390 lr 0.100000 loss 0.3046 (0.1701) acc@1 0.9141 (0.9399) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:09:40] __main__ INFO: [0mEpoch 58 Step 390/390 lr 0.100000 loss 0.1266 (0.1733) acc@1 0.9609 (0.9391) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:09:40] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 10:09:40] __main__ INFO: [0mVal 58
[32m[2022-06-11 10:09:41] __main__ INFO: [0mEpoch 58 loss 0.5951 acc@1 0.8389 acc@5 0.9862
[32m[2022-06-11 10:09:41] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:09:41] __main__ INFO: [0mTrain 59 22620
[32m[2022-06-11 10:09:45] __main__ INFO: [0mEpoch 59 Step 100/390 lr 0.100000 loss 0.0636 (0.1499) acc@1 0.9922 (0.9469) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:49] __main__ INFO: [0mEpoch 59 Step 200/390 lr 0.100000 loss 0.2237 (0.1619) acc@1 0.9141 (0.9429) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:53] __main__ INFO: [0mEpoch 59 Step 300/390 lr 0.100000 loss 0.1630 (0.1697) acc@1 0.9297 (0.9405) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:09:57] __main__ INFO: [0mEpoch 59 Step 390/390 lr 0.100000 loss 0.2786 (0.1749) acc@1 0.8984 (0.9385) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:09:57] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:09:57] __main__ INFO: [0mVal 59
[32m[2022-06-11 10:09:58] __main__ INFO: [0mEpoch 59 loss 0.4630 acc@1 0.8669 acc@5 0.9956
[32m[2022-06-11 10:09:58] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:09:58] __main__ INFO: [0mTrain 60 23010
[32m[2022-06-11 10:10:02] __main__ INFO: [0mEpoch 60 Step 100/390 lr 0.100000 loss 0.1661 (0.1598) acc@1 0.9297 (0.9427) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:10:06] __main__ INFO: [0mEpoch 60 Step 200/390 lr 0.100000 loss 0.1581 (0.1668) acc@1 0.9531 (0.9397) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:10:10] __main__ INFO: [0mEpoch 60 Step 300/390 lr 0.100000 loss 0.2078 (0.1707) acc@1 0.9297 (0.9392) acc@5 0.9922 (0.9990)
[32m[2022-06-11 10:10:14] __main__ INFO: [0mEpoch 60 Step 390/390 lr 0.100000 loss 0.1692 (0.1724) acc@1 0.9141 (0.9387) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:10:14] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:10:14] __main__ INFO: [0mVal 60
[32m[2022-06-11 10:10:15] __main__ INFO: [0mEpoch 60 loss 0.4576 acc@1 0.8678 acc@5 0.9952
[32m[2022-06-11 10:10:15] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:10:15] __main__ INFO: [0mTrain 61 23400
[32m[2022-06-11 10:10:19] __main__ INFO: [0mEpoch 61 Step 100/390 lr 0.100000 loss 0.0885 (0.1610) acc@1 0.9766 (0.9437) acc@5 0.9922 (0.9992)
[32m[2022-06-11 10:10:23] __main__ INFO: [0mEpoch 61 Step 200/390 lr 0.100000 loss 0.1754 (0.1645) acc@1 0.9375 (0.9424) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:27] __main__ INFO: [0mEpoch 61 Step 300/390 lr 0.100000 loss 0.0850 (0.1688) acc@1 0.9688 (0.9408) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:30] __main__ INFO: [0mEpoch 61 Step 390/390 lr 0.100000 loss 0.1750 (0.1738) acc@1 0.9453 (0.9390) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:10:30] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:10:30] __main__ INFO: [0mVal 61
[32m[2022-06-11 10:10:31] __main__ INFO: [0mEpoch 61 loss 0.4547 acc@1 0.8651 acc@5 0.9948
[32m[2022-06-11 10:10:31] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:10:31] __main__ INFO: [0mTrain 62 23790
[32m[2022-06-11 10:10:35] __main__ INFO: [0mEpoch 62 Step 100/390 lr 0.100000 loss 0.2101 (0.1668) acc@1 0.9375 (0.9403) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:39] __main__ INFO: [0mEpoch 62 Step 200/390 lr 0.100000 loss 0.1727 (0.1672) acc@1 0.9375 (0.9405) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:10:43] __main__ INFO: [0mEpoch 62 Step 300/390 lr 0.100000 loss 0.2856 (0.1712) acc@1 0.9141 (0.9394) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:10:47] __main__ INFO: [0mEpoch 62 Step 390/390 lr 0.100000 loss 0.1850 (0.1751) acc@1 0.9609 (0.9378) acc@5 0.9922 (0.9991)
[32m[2022-06-11 10:10:47] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:10:47] __main__ INFO: [0mVal 62
[32m[2022-06-11 10:10:48] __main__ INFO: [0mEpoch 62 loss 0.4471 acc@1 0.8674 acc@5 0.9929
[32m[2022-06-11 10:10:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:10:48] __main__ INFO: [0mTrain 63 24180
[32m[2022-06-11 10:10:52] __main__ INFO: [0mEpoch 63 Step 100/390 lr 0.100000 loss 0.0745 (0.1544) acc@1 0.9766 (0.9455) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:10:56] __main__ INFO: [0mEpoch 63 Step 200/390 lr 0.100000 loss 0.1782 (0.1555) acc@1 0.9531 (0.9446) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:11:00] __main__ INFO: [0mEpoch 63 Step 300/390 lr 0.100000 loss 0.1254 (0.1653) acc@1 0.9531 (0.9412) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:04] __main__ INFO: [0mEpoch 63 Step 390/390 lr 0.100000 loss 0.2158 (0.1700) acc@1 0.9375 (0.9392) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:04] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:11:04] __main__ INFO: [0mVal 63
[32m[2022-06-11 10:11:05] __main__ INFO: [0mEpoch 63 loss 0.4124 acc@1 0.8758 acc@5 0.9947
[32m[2022-06-11 10:11:05] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:11:05] __main__ INFO: [0mTrain 64 24570
[32m[2022-06-11 10:11:09] __main__ INFO: [0mEpoch 64 Step 100/390 lr 0.100000 loss 0.1533 (0.1548) acc@1 0.9531 (0.9468) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:13] __main__ INFO: [0mEpoch 64 Step 200/390 lr 0.100000 loss 0.1931 (0.1623) acc@1 0.9297 (0.9439) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:17] __main__ INFO: [0mEpoch 64 Step 300/390 lr 0.100000 loss 0.1510 (0.1670) acc@1 0.9219 (0.9424) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:20] __main__ INFO: [0mEpoch 64 Step 390/390 lr 0.100000 loss 0.1181 (0.1692) acc@1 0.9688 (0.9418) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:20] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 10:11:20] __main__ INFO: [0mVal 64
[32m[2022-06-11 10:11:21] __main__ INFO: [0mEpoch 64 loss 0.4547 acc@1 0.8683 acc@5 0.9954
[32m[2022-06-11 10:11:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:11:21] __main__ INFO: [0mTrain 65 24960
[32m[2022-06-11 10:11:25] __main__ INFO: [0mEpoch 65 Step 100/390 lr 0.100000 loss 0.1940 (0.1515) acc@1 0.9062 (0.9464) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:11:29] __main__ INFO: [0mEpoch 65 Step 200/390 lr 0.100000 loss 0.2388 (0.1572) acc@1 0.9141 (0.9452) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:11:33] __main__ INFO: [0mEpoch 65 Step 300/390 lr 0.100000 loss 0.2012 (0.1633) acc@1 0.9297 (0.9430) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:37] __main__ INFO: [0mEpoch 65 Step 390/390 lr 0.100000 loss 0.1326 (0.1696) acc@1 0.9688 (0.9408) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:11:37] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:11:37] __main__ INFO: [0mVal 65
[32m[2022-06-11 10:11:38] __main__ INFO: [0mEpoch 65 loss 0.4387 acc@1 0.8740 acc@5 0.9938
[32m[2022-06-11 10:11:38] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:11:38] __main__ INFO: [0mTrain 66 25350
[32m[2022-06-11 10:11:42] __main__ INFO: [0mEpoch 66 Step 100/390 lr 0.100000 loss 0.1973 (0.1620) acc@1 0.9453 (0.9423) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:11:46] __main__ INFO: [0mEpoch 66 Step 200/390 lr 0.100000 loss 0.1866 (0.1668) acc@1 0.9531 (0.9405) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:50] __main__ INFO: [0mEpoch 66 Step 300/390 lr 0.100000 loss 0.1529 (0.1724) acc@1 0.9375 (0.9388) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:54] __main__ INFO: [0mEpoch 66 Step 390/390 lr 0.100000 loss 0.2226 (0.1738) acc@1 0.9297 (0.9384) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:11:54] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:11:54] __main__ INFO: [0mVal 66
[32m[2022-06-11 10:11:55] __main__ INFO: [0mEpoch 66 loss 0.4242 acc@1 0.8764 acc@5 0.9960
[32m[2022-06-11 10:11:55] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:11:55] __main__ INFO: [0mTrain 67 25740
[32m[2022-06-11 10:11:59] __main__ INFO: [0mEpoch 67 Step 100/390 lr 0.100000 loss 0.1892 (0.1595) acc@1 0.9375 (0.9452) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:12:03] __main__ INFO: [0mEpoch 67 Step 200/390 lr 0.100000 loss 0.1947 (0.1700) acc@1 0.8984 (0.9416) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:07] __main__ INFO: [0mEpoch 67 Step 300/390 lr 0.100000 loss 0.0885 (0.1698) acc@1 0.9844 (0.9410) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:12:10] __main__ INFO: [0mEpoch 67 Step 390/390 lr 0.100000 loss 0.1674 (0.1705) acc@1 0.9297 (0.9407) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:12:10] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:12:10] __main__ INFO: [0mVal 67
[32m[2022-06-11 10:12:11] __main__ INFO: [0mEpoch 67 loss 0.4086 acc@1 0.8769 acc@5 0.9950
[32m[2022-06-11 10:12:11] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:12:11] __main__ INFO: [0mTrain 68 26130
[32m[2022-06-11 10:12:16] __main__ INFO: [0mEpoch 68 Step 100/390 lr 0.100000 loss 0.1197 (0.1533) acc@1 0.9688 (0.9489) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:19] __main__ INFO: [0mEpoch 68 Step 200/390 lr 0.100000 loss 0.2528 (0.1621) acc@1 0.9219 (0.9450) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:23] __main__ INFO: [0mEpoch 68 Step 300/390 lr 0.100000 loss 0.1191 (0.1685) acc@1 0.9688 (0.9421) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:27] __main__ INFO: [0mEpoch 68 Step 390/390 lr 0.100000 loss 0.2163 (0.1743) acc@1 0.9375 (0.9398) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:27] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:12:27] __main__ INFO: [0mVal 68
[32m[2022-06-11 10:12:28] __main__ INFO: [0mEpoch 68 loss 0.4890 acc@1 0.8668 acc@5 0.9950
[32m[2022-06-11 10:12:28] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 10:12:28] __main__ INFO: [0mTrain 69 26520
[32m[2022-06-11 10:12:32] __main__ INFO: [0mEpoch 69 Step 100/390 lr 0.100000 loss 0.1154 (0.1541) acc@1 0.9844 (0.9462) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:36] __main__ INFO: [0mEpoch 69 Step 200/390 lr 0.100000 loss 0.1364 (0.1577) acc@1 0.9453 (0.9451) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:12:40] __main__ INFO: [0mEpoch 69 Step 300/390 lr 0.100000 loss 0.2041 (0.1620) acc@1 0.9375 (0.9426) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:44] __main__ INFO: [0mEpoch 69 Step 390/390 lr 0.100000 loss 0.2820 (0.1644) acc@1 0.8984 (0.9417) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:44] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 10:12:44] __main__ INFO: [0mVal 69
[32m[2022-06-11 10:12:45] __main__ INFO: [0mEpoch 69 loss 0.4136 acc@1 0.8826 acc@5 0.9956
[32m[2022-06-11 10:12:45] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:12:45] __main__ INFO: [0mTrain 70 26910
[32m[2022-06-11 10:12:49] __main__ INFO: [0mEpoch 70 Step 100/390 lr 0.100000 loss 0.1851 (0.1507) acc@1 0.9531 (0.9485) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:12:53] __main__ INFO: [0mEpoch 70 Step 200/390 lr 0.100000 loss 0.2008 (0.1591) acc@1 0.9219 (0.9446) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:12:57] __main__ INFO: [0mEpoch 70 Step 300/390 lr 0.100000 loss 0.1953 (0.1631) acc@1 0.9453 (0.9429) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:00] __main__ INFO: [0mEpoch 70 Step 390/390 lr 0.100000 loss 0.1586 (0.1653) acc@1 0.9297 (0.9423) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:00] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:13:00] __main__ INFO: [0mVal 70
[32m[2022-06-11 10:13:01] __main__ INFO: [0mEpoch 70 loss 0.4163 acc@1 0.8764 acc@5 0.9947
[32m[2022-06-11 10:13:01] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:13:01] __main__ INFO: [0mTrain 71 27300
[32m[2022-06-11 10:13:05] __main__ INFO: [0mEpoch 71 Step 100/390 lr 0.100000 loss 0.2445 (0.1573) acc@1 0.8984 (0.9456) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:13:09] __main__ INFO: [0mEpoch 71 Step 200/390 lr 0.100000 loss 0.1584 (0.1580) acc@1 0.9219 (0.9444) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:13] __main__ INFO: [0mEpoch 71 Step 300/390 lr 0.100000 loss 0.1556 (0.1608) acc@1 0.9375 (0.9434) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:17] __main__ INFO: [0mEpoch 71 Step 390/390 lr 0.100000 loss 0.1637 (0.1653) acc@1 0.9531 (0.9420) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:17] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:13:17] __main__ INFO: [0mVal 71
[32m[2022-06-11 10:13:18] __main__ INFO: [0mEpoch 71 loss 0.4424 acc@1 0.8694 acc@5 0.9961
[32m[2022-06-11 10:13:18] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:13:18] __main__ INFO: [0mTrain 72 27690
[32m[2022-06-11 10:13:22] __main__ INFO: [0mEpoch 72 Step 100/390 lr 0.100000 loss 0.1730 (0.1564) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9989)
[32m[2022-06-11 10:13:26] __main__ INFO: [0mEpoch 72 Step 200/390 lr 0.100000 loss 0.1855 (0.1637) acc@1 0.9297 (0.9428) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:30] __main__ INFO: [0mEpoch 72 Step 300/390 lr 0.100000 loss 0.1909 (0.1673) acc@1 0.9219 (0.9412) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:13:34] __main__ INFO: [0mEpoch 72 Step 390/390 lr 0.100000 loss 0.1195 (0.1737) acc@1 0.9688 (0.9388) acc@5 1.0000 (0.9991)
[32m[2022-06-11 10:13:34] __main__ INFO: [0mElapsed 16.00
[32m[2022-06-11 10:13:34] __main__ INFO: [0mVal 72
[32m[2022-06-11 10:13:35] __main__ INFO: [0mEpoch 72 loss 0.4116 acc@1 0.8795 acc@5 0.9945
[32m[2022-06-11 10:13:35] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:13:35] __main__ INFO: [0mTrain 73 28080
[32m[2022-06-11 10:13:39] __main__ INFO: [0mEpoch 73 Step 100/390 lr 0.100000 loss 0.1155 (0.1535) acc@1 0.9609 (0.9478) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:43] __main__ INFO: [0mEpoch 73 Step 200/390 lr 0.100000 loss 0.2923 (0.1658) acc@1 0.8828 (0.9431) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:47] __main__ INFO: [0mEpoch 73 Step 300/390 lr 0.100000 loss 0.0928 (0.1658) acc@1 0.9688 (0.9423) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:13:51] __main__ INFO: [0mEpoch 73 Step 390/390 lr 0.100000 loss 0.1483 (0.1660) acc@1 0.9453 (0.9417) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:13:51] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:13:51] __main__ INFO: [0mVal 73
[32m[2022-06-11 10:13:52] __main__ INFO: [0mEpoch 73 loss 0.3855 acc@1 0.8893 acc@5 0.9964
[32m[2022-06-11 10:13:52] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:13:52] __main__ INFO: [0mTrain 74 28470
[32m[2022-06-11 10:13:56] __main__ INFO: [0mEpoch 74 Step 100/390 lr 0.100000 loss 0.1283 (0.1567) acc@1 0.9688 (0.9450) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:00] __main__ INFO: [0mEpoch 74 Step 200/390 lr 0.100000 loss 0.2075 (0.1606) acc@1 0.9062 (0.9433) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:04] __main__ INFO: [0mEpoch 74 Step 300/390 lr 0.100000 loss 0.1245 (0.1633) acc@1 0.9453 (0.9422) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:07] __main__ INFO: [0mEpoch 74 Step 390/390 lr 0.100000 loss 0.1689 (0.1659) acc@1 0.9375 (0.9411) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:08] __main__ INFO: [0mElapsed 15.88
[32m[2022-06-11 10:14:08] __main__ INFO: [0mVal 74
[32m[2022-06-11 10:14:08] __main__ INFO: [0mEpoch 74 loss 0.4028 acc@1 0.8822 acc@5 0.9947
[32m[2022-06-11 10:14:08] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 10:14:08] __main__ INFO: [0mTrain 75 28860
[32m[2022-06-11 10:14:12] __main__ INFO: [0mEpoch 75 Step 100/390 lr 0.100000 loss 0.2284 (0.1518) acc@1 0.9375 (0.9463) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:14:16] __main__ INFO: [0mEpoch 75 Step 200/390 lr 0.100000 loss 0.1127 (0.1638) acc@1 0.9609 (0.9417) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:20] __main__ INFO: [0mEpoch 75 Step 300/390 lr 0.100000 loss 0.2286 (0.1649) acc@1 0.9297 (0.9409) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:14:24] __main__ INFO: [0mEpoch 75 Step 390/390 lr 0.100000 loss 0.1444 (0.1672) acc@1 0.9453 (0.9400) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:14:24] __main__ INFO: [0mElapsed 15.41
[32m[2022-06-11 10:14:24] __main__ INFO: [0mVal 75
[32m[2022-06-11 10:14:25] __main__ INFO: [0mEpoch 75 loss 0.5518 acc@1 0.8532 acc@5 0.9930
[32m[2022-06-11 10:14:25] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:14:25] __main__ INFO: [0mTrain 76 29250
[32m[2022-06-11 10:14:29] __main__ INFO: [0mEpoch 76 Step 100/390 lr 0.100000 loss 0.1722 (0.1435) acc@1 0.8984 (0.9504) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:14:33] __main__ INFO: [0mEpoch 76 Step 200/390 lr 0.100000 loss 0.0423 (0.1577) acc@1 0.9922 (0.9446) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:14:37] __main__ INFO: [0mEpoch 76 Step 300/390 lr 0.100000 loss 0.1654 (0.1618) acc@1 0.9375 (0.9435) acc@5 1.0000 (0.9990)
[32m[2022-06-11 10:14:40] __main__ INFO: [0mEpoch 76 Step 390/390 lr 0.100000 loss 0.2284 (0.1651) acc@1 0.9297 (0.9420) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:14:40] __main__ INFO: [0mElapsed 15.62
[32m[2022-06-11 10:14:40] __main__ INFO: [0mVal 76
[32m[2022-06-11 10:14:41] __main__ INFO: [0mEpoch 76 loss 0.5314 acc@1 0.8520 acc@5 0.9902
[32m[2022-06-11 10:14:41] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:14:41] __main__ INFO: [0mTrain 77 29640
[32m[2022-06-11 10:14:46] __main__ INFO: [0mEpoch 77 Step 100/390 lr 0.100000 loss 0.1711 (0.1479) acc@1 0.9453 (0.9481) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:14:49] __main__ INFO: [0mEpoch 77 Step 200/390 lr 0.100000 loss 0.1918 (0.1561) acc@1 0.9453 (0.9457) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:14:53] __main__ INFO: [0mEpoch 77 Step 300/390 lr 0.100000 loss 0.1137 (0.1575) acc@1 0.9609 (0.9452) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:14:57] __main__ INFO: [0mEpoch 77 Step 390/390 lr 0.100000 loss 0.2483 (0.1644) acc@1 0.9141 (0.9423) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:14:57] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:14:57] __main__ INFO: [0mVal 77
[32m[2022-06-11 10:14:58] __main__ INFO: [0mEpoch 77 loss 0.4007 acc@1 0.8793 acc@5 0.9942
[32m[2022-06-11 10:14:58] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:14:58] __main__ INFO: [0mTrain 78 30030
[32m[2022-06-11 10:15:02] __main__ INFO: [0mEpoch 78 Step 100/390 lr 0.100000 loss 0.1286 (0.1560) acc@1 0.9688 (0.9437) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:15:06] __main__ INFO: [0mEpoch 78 Step 200/390 lr 0.100000 loss 0.1946 (0.1659) acc@1 0.9453 (0.9419) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:15:10] __main__ INFO: [0mEpoch 78 Step 300/390 lr 0.100000 loss 0.1194 (0.1641) acc@1 0.9453 (0.9424) acc@5 1.0000 (0.9993)
[32m[2022-06-11 10:15:13] __main__ INFO: [0mEpoch 78 Step 390/390 lr 0.100000 loss 0.1781 (0.1691) acc@1 0.9297 (0.9410) acc@5 0.9922 (0.9993)
[32m[2022-06-11 10:15:13] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:15:13] __main__ INFO: [0mVal 78
[32m[2022-06-11 10:15:14] __main__ INFO: [0mEpoch 78 loss 0.4610 acc@1 0.8641 acc@5 0.9939
[32m[2022-06-11 10:15:14] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:15:14] __main__ INFO: [0mTrain 79 30420
[32m[2022-06-11 10:15:19] __main__ INFO: [0mEpoch 79 Step 100/390 lr 0.100000 loss 0.1092 (0.1518) acc@1 0.9453 (0.9446) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:15:23] __main__ INFO: [0mEpoch 79 Step 200/390 lr 0.100000 loss 0.2298 (0.1540) acc@1 0.9531 (0.9442) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:27] __main__ INFO: [0mEpoch 79 Step 300/390 lr 0.100000 loss 0.1178 (0.1587) acc@1 0.9844 (0.9434) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:30] __main__ INFO: [0mEpoch 79 Step 390/390 lr 0.100000 loss 0.1030 (0.1629) acc@1 0.9844 (0.9419) acc@5 1.0000 (0.9995)
[32m[2022-06-11 10:15:30] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:15:30] __main__ INFO: [0mVal 79
[32m[2022-06-11 10:15:31] __main__ INFO: [0mEpoch 79 loss 0.4525 acc@1 0.8770 acc@5 0.9948
[32m[2022-06-11 10:15:31] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 10:15:31] __main__ INFO: [0mTrain 80 30810
[32m[2022-06-11 10:15:35] __main__ INFO: [0mEpoch 80 Step 100/390 lr 0.100000 loss 0.0857 (0.1653) acc@1 0.9688 (0.9413) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:39] __main__ INFO: [0mEpoch 80 Step 200/390 lr 0.100000 loss 0.1711 (0.1677) acc@1 0.9531 (0.9416) acc@5 1.0000 (0.9992)
[32m[2022-06-11 10:15:43] __main__ INFO: [0mEpoch 80 Step 300/390 lr 0.100000 loss 0.1633 (0.1639) acc@1 0.9219 (0.9422) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:47] __main__ INFO: [0mEpoch 80 Step 390/390 lr 0.100000 loss 0.2726 (0.1679) acc@1 0.9141 (0.9412) acc@5 1.0000 (0.9994)
[32m[2022-06-11 10:15:47] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 10:15:47] __main__ INFO: [0mVal 80
[32m[2022-06-11 10:15:48] __main__ INFO: [0mEpoch 80 loss 0.4470 acc@1 0.8739 acc@5 0.9944
[32m[2022-06-11 10:15:48] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:15:48] __main__ INFO: [0mTrain 81 31200
[32m[2022-06-11 10:15:52] __main__ INFO: [0mEpoch 81 Step 100/390 lr 0.010000 loss 0.1312 (0.1110) acc@1 0.9453 (0.9637) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:15:56] __main__ INFO: [0mEpoch 81 Step 200/390 lr 0.010000 loss 0.1008 (0.1033) acc@1 0.9688 (0.9656) acc@5 1.0000 (0.9996)
[32m[2022-06-11 10:16:00] __main__ INFO: [0mEpoch 81 Step 300/390 lr 0.010000 loss 0.0895 (0.0951) acc@1 0.9766 (0.9686) acc@5 1.0000 (0.9997)
[32m[2022-06-11 10:16:03] __main__ INFO: [0mEpoch 81 Step 390/390 lr 0.010000 loss 0.1290 (0.0900) acc@1 0.9609 (0.9703) acc@5 0.9922 (0.9997)
[32m[2022-06-11 10:16:03] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:16:03] __main__ INFO: [0mVal 81
[32m[2022-06-11 10:16:04] __main__ INFO: [0mEpoch 81 loss 0.2692 acc@1 0.9189 acc@5 0.9980
[32m[2022-06-11 10:16:04] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:16:04] __main__ INFO: [0mTrain 82 31590
[32m[2022-06-11 10:16:08] __main__ INFO: [0mEpoch 82 Step 100/390 lr 0.010000 loss 0.0511 (0.0664) acc@1 0.9688 (0.9798) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:12] __main__ INFO: [0mEpoch 82 Step 200/390 lr 0.010000 loss 0.0407 (0.0640) acc@1 0.9922 (0.9802) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:16] __main__ INFO: [0mEpoch 82 Step 300/390 lr 0.010000 loss 0.0616 (0.0620) acc@1 0.9844 (0.9805) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:20] __main__ INFO: [0mEpoch 82 Step 390/390 lr 0.010000 loss 0.0667 (0.0604) acc@1 0.9844 (0.9809) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:20] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:16:20] __main__ INFO: [0mVal 82
[32m[2022-06-11 10:16:21] __main__ INFO: [0mEpoch 82 loss 0.2662 acc@1 0.9216 acc@5 0.9978
[32m[2022-06-11 10:16:21] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:16:21] __main__ INFO: [0mTrain 83 31980
[32m[2022-06-11 10:16:25] __main__ INFO: [0mEpoch 83 Step 100/390 lr 0.010000 loss 0.0720 (0.0500) acc@1 0.9766 (0.9849) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:16:29] __main__ INFO: [0mEpoch 83 Step 200/390 lr 0.010000 loss 0.0488 (0.0496) acc@1 0.9844 (0.9852) acc@5 1.0000 (0.9998)
[32m[2022-06-11 10:16:33] __main__ INFO: [0mEpoch 83 Step 300/390 lr 0.010000 loss 0.0369 (0.0505) acc@1 0.9922 (0.9848) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:37] __main__ INFO: [0mEpoch 83 Step 390/390 lr 0.010000 loss 0.0652 (0.0510) acc@1 0.9609 (0.9843) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:16:37] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 10:16:37] __main__ INFO: [0mVal 83
[32m[2022-06-11 10:16:38] __main__ INFO: [0mEpoch 83 loss 0.2687 acc@1 0.9226 acc@5 0.9982
[32m[2022-06-11 10:16:38] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:16:38] __main__ INFO: [0mTrain 84 32370
[32m[2022-06-11 10:16:42] __main__ INFO: [0mEpoch 84 Step 100/390 lr 0.010000 loss 0.0351 (0.0445) acc@1 0.9922 (0.9857) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:46] __main__ INFO: [0mEpoch 84 Step 200/390 lr 0.010000 loss 0.0446 (0.0439) acc@1 0.9844 (0.9863) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:50] __main__ INFO: [0mEpoch 84 Step 300/390 lr 0.010000 loss 0.0233 (0.0445) acc@1 1.0000 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:53] __main__ INFO: [0mEpoch 84 Step 390/390 lr 0.010000 loss 0.0310 (0.0439) acc@1 0.9922 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:16:53] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:16:53] __main__ INFO: [0mVal 84
[32m[2022-06-11 10:16:54] __main__ INFO: [0mEpoch 84 loss 0.2741 acc@1 0.9240 acc@5 0.9983
[32m[2022-06-11 10:16:54] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:16:54] __main__ INFO: [0mTrain 85 32760
[32m[2022-06-11 10:16:58] __main__ INFO: [0mEpoch 85 Step 100/390 lr 0.010000 loss 0.0217 (0.0396) acc@1 1.0000 (0.9883) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:02] __main__ INFO: [0mEpoch 85 Step 200/390 lr 0.010000 loss 0.0505 (0.0387) acc@1 0.9844 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:06] __main__ INFO: [0mEpoch 85 Step 300/390 lr 0.010000 loss 0.0119 (0.0391) acc@1 1.0000 (0.9885) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:10] __main__ INFO: [0mEpoch 85 Step 390/390 lr 0.010000 loss 0.0405 (0.0396) acc@1 0.9922 (0.9883) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:10] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:17:10] __main__ INFO: [0mVal 85
[32m[2022-06-11 10:17:11] __main__ INFO: [0mEpoch 85 loss 0.2732 acc@1 0.9250 acc@5 0.9980
[32m[2022-06-11 10:17:11] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:17:11] __main__ INFO: [0mTrain 86 33150
[32m[2022-06-11 10:17:15] __main__ INFO: [0mEpoch 86 Step 100/390 lr 0.010000 loss 0.0420 (0.0334) acc@1 1.0000 (0.9904) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:17:19] __main__ INFO: [0mEpoch 86 Step 200/390 lr 0.010000 loss 0.0225 (0.0351) acc@1 0.9922 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:23] __main__ INFO: [0mEpoch 86 Step 300/390 lr 0.010000 loss 0.0333 (0.0352) acc@1 0.9922 (0.9897) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:26] __main__ INFO: [0mEpoch 86 Step 390/390 lr 0.010000 loss 0.0376 (0.0345) acc@1 0.9922 (0.9897) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:27] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:17:27] __main__ INFO: [0mVal 86
[32m[2022-06-11 10:17:28] __main__ INFO: [0mEpoch 86 loss 0.2806 acc@1 0.9228 acc@5 0.9976
[32m[2022-06-11 10:17:28] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:17:28] __main__ INFO: [0mTrain 87 33540
[32m[2022-06-11 10:17:32] __main__ INFO: [0mEpoch 87 Step 100/390 lr 0.010000 loss 0.0558 (0.0305) acc@1 0.9844 (0.9914) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:17:36] __main__ INFO: [0mEpoch 87 Step 200/390 lr 0.010000 loss 0.0516 (0.0320) acc@1 0.9844 (0.9907) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:40] __main__ INFO: [0mEpoch 87 Step 300/390 lr 0.010000 loss 0.0618 (0.0331) acc@1 0.9844 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:43] __main__ INFO: [0mEpoch 87 Step 390/390 lr 0.010000 loss 0.0911 (0.0330) acc@1 0.9609 (0.9901) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:43] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:17:43] __main__ INFO: [0mVal 87
[32m[2022-06-11 10:17:44] __main__ INFO: [0mEpoch 87 loss 0.2785 acc@1 0.9240 acc@5 0.9981
[32m[2022-06-11 10:17:44] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:17:44] __main__ INFO: [0mTrain 88 33930
[32m[2022-06-11 10:17:48] __main__ INFO: [0mEpoch 88 Step 100/390 lr 0.010000 loss 0.0578 (0.0300) acc@1 0.9766 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:52] __main__ INFO: [0mEpoch 88 Step 200/390 lr 0.010000 loss 0.0232 (0.0309) acc@1 0.9922 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:17:56] __main__ INFO: [0mEpoch 88 Step 300/390 lr 0.010000 loss 0.0469 (0.0314) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:00] __main__ INFO: [0mEpoch 88 Step 390/390 lr 0.010000 loss 0.0201 (0.0306) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:00] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:18:00] __main__ INFO: [0mVal 88
[32m[2022-06-11 10:18:01] __main__ INFO: [0mEpoch 88 loss 0.2954 acc@1 0.9225 acc@5 0.9979
[32m[2022-06-11 10:18:01] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:18:01] __main__ INFO: [0mTrain 89 34320
[32m[2022-06-11 10:18:05] __main__ INFO: [0mEpoch 89 Step 100/390 lr 0.010000 loss 0.0360 (0.0287) acc@1 0.9922 (0.9915) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:09] __main__ INFO: [0mEpoch 89 Step 200/390 lr 0.010000 loss 0.0474 (0.0284) acc@1 0.9766 (0.9913) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:13] __main__ INFO: [0mEpoch 89 Step 300/390 lr 0.010000 loss 0.0416 (0.0287) acc@1 0.9844 (0.9913) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:16] __main__ INFO: [0mEpoch 89 Step 390/390 lr 0.010000 loss 0.0227 (0.0287) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:16] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 10:18:16] __main__ INFO: [0mVal 89
[32m[2022-06-11 10:18:17] __main__ INFO: [0mEpoch 89 loss 0.2878 acc@1 0.9241 acc@5 0.9981
[32m[2022-06-11 10:18:17] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:18:17] __main__ INFO: [0mTrain 90 34710
[32m[2022-06-11 10:18:22] __main__ INFO: [0mEpoch 90 Step 100/390 lr 0.010000 loss 0.0301 (0.0265) acc@1 0.9922 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:26] __main__ INFO: [0mEpoch 90 Step 200/390 lr 0.010000 loss 0.0109 (0.0266) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:30] __main__ INFO: [0mEpoch 90 Step 300/390 lr 0.010000 loss 0.0110 (0.0269) acc@1 1.0000 (0.9915) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:33] __main__ INFO: [0mEpoch 90 Step 390/390 lr 0.010000 loss 0.0377 (0.0269) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:33] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:18:33] __main__ INFO: [0mVal 90
[32m[2022-06-11 10:18:34] __main__ INFO: [0mEpoch 90 loss 0.2952 acc@1 0.9240 acc@5 0.9980
[32m[2022-06-11 10:18:34] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:18:34] __main__ INFO: [0mTrain 91 35100
[32m[2022-06-11 10:18:38] __main__ INFO: [0mEpoch 91 Step 100/390 lr 0.010000 loss 0.0487 (0.0245) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:42] __main__ INFO: [0mEpoch 91 Step 200/390 lr 0.010000 loss 0.0078 (0.0249) acc@1 1.0000 (0.9931) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:46] __main__ INFO: [0mEpoch 91 Step 300/390 lr 0.010000 loss 0.0336 (0.0258) acc@1 0.9844 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:50] __main__ INFO: [0mEpoch 91 Step 390/390 lr 0.010000 loss 0.0142 (0.0262) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:50] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:18:50] __main__ INFO: [0mVal 91
[32m[2022-06-11 10:18:51] __main__ INFO: [0mEpoch 91 loss 0.2955 acc@1 0.9237 acc@5 0.9986
[32m[2022-06-11 10:18:51] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:18:51] __main__ INFO: [0mTrain 92 35490
[32m[2022-06-11 10:18:55] __main__ INFO: [0mEpoch 92 Step 100/390 lr 0.010000 loss 0.0458 (0.0249) acc@1 0.9844 (0.9927) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:18:59] __main__ INFO: [0mEpoch 92 Step 200/390 lr 0.010000 loss 0.0081 (0.0241) acc@1 1.0000 (0.9929) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:03] __main__ INFO: [0mEpoch 92 Step 300/390 lr 0.010000 loss 0.0335 (0.0243) acc@1 0.9922 (0.9929) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:07] __main__ INFO: [0mEpoch 92 Step 390/390 lr 0.010000 loss 0.0214 (0.0239) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:07] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:19:07] __main__ INFO: [0mVal 92
[32m[2022-06-11 10:19:08] __main__ INFO: [0mEpoch 92 loss 0.2951 acc@1 0.9247 acc@5 0.9982
[32m[2022-06-11 10:19:08] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 10:19:08] __main__ INFO: [0mTrain 93 35880
[32m[2022-06-11 10:19:12] __main__ INFO: [0mEpoch 93 Step 100/390 lr 0.010000 loss 0.0193 (0.0218) acc@1 1.0000 (0.9941) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:16] __main__ INFO: [0mEpoch 93 Step 200/390 lr 0.010000 loss 0.0160 (0.0222) acc@1 1.0000 (0.9937) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:20] __main__ INFO: [0mEpoch 93 Step 300/390 lr 0.010000 loss 0.0109 (0.0227) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:23] __main__ INFO: [0mEpoch 93 Step 390/390 lr 0.010000 loss 0.0062 (0.0234) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:24] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:19:24] __main__ INFO: [0mVal 93
[32m[2022-06-11 10:19:24] __main__ INFO: [0mEpoch 93 loss 0.2997 acc@1 0.9233 acc@5 0.9983
[32m[2022-06-11 10:19:24] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:19:24] __main__ INFO: [0mTrain 94 36270
[32m[2022-06-11 10:19:29] __main__ INFO: [0mEpoch 94 Step 100/390 lr 0.010000 loss 0.0110 (0.0196) acc@1 0.9922 (0.9949) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:32] __main__ INFO: [0mEpoch 94 Step 200/390 lr 0.010000 loss 0.0251 (0.0199) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:36] __main__ INFO: [0mEpoch 94 Step 300/390 lr 0.010000 loss 0.0230 (0.0196) acc@1 0.9922 (0.9948) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:40] __main__ INFO: [0mEpoch 94 Step 390/390 lr 0.010000 loss 0.0177 (0.0202) acc@1 1.0000 (0.9943) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:40] __main__ INFO: [0mElapsed 15.55
[32m[2022-06-11 10:19:40] __main__ INFO: [0mVal 94
[32m[2022-06-11 10:19:41] __main__ INFO: [0mEpoch 94 loss 0.3075 acc@1 0.9243 acc@5 0.9983
[32m[2022-06-11 10:19:41] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:19:41] __main__ INFO: [0mTrain 95 36660
[32m[2022-06-11 10:19:45] __main__ INFO: [0mEpoch 95 Step 100/390 lr 0.010000 loss 0.0206 (0.0197) acc@1 0.9922 (0.9945) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:49] __main__ INFO: [0mEpoch 95 Step 200/390 lr 0.010000 loss 0.0169 (0.0195) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:53] __main__ INFO: [0mEpoch 95 Step 300/390 lr 0.010000 loss 0.0225 (0.0188) acc@1 0.9922 (0.9951) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:57] __main__ INFO: [0mEpoch 95 Step 390/390 lr 0.010000 loss 0.0112 (0.0191) acc@1 1.0000 (0.9947) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:19:57] __main__ INFO: [0mElapsed 16.08
[32m[2022-06-11 10:19:57] __main__ INFO: [0mVal 95
[32m[2022-06-11 10:19:58] __main__ INFO: [0mEpoch 95 loss 0.3033 acc@1 0.9251 acc@5 0.9986
[32m[2022-06-11 10:19:58] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:19:58] __main__ INFO: [0mTrain 96 37050
[32m[2022-06-11 10:20:02] __main__ INFO: [0mEpoch 96 Step 100/390 lr 0.010000 loss 0.0192 (0.0196) acc@1 0.9922 (0.9951) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:06] __main__ INFO: [0mEpoch 96 Step 200/390 lr 0.010000 loss 0.0066 (0.0188) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:10] __main__ INFO: [0mEpoch 96 Step 300/390 lr 0.010000 loss 0.0357 (0.0186) acc@1 0.9844 (0.9954) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:14] __main__ INFO: [0mEpoch 96 Step 390/390 lr 0.010000 loss 0.0109 (0.0186) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:14] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:20:14] __main__ INFO: [0mVal 96
[32m[2022-06-11 10:20:15] __main__ INFO: [0mEpoch 96 loss 0.3079 acc@1 0.9249 acc@5 0.9982
[32m[2022-06-11 10:20:15] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:20:15] __main__ INFO: [0mTrain 97 37440
[32m[2022-06-11 10:20:19] __main__ INFO: [0mEpoch 97 Step 100/390 lr 0.010000 loss 0.0209 (0.0174) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:23] __main__ INFO: [0mEpoch 97 Step 200/390 lr 0.010000 loss 0.0208 (0.0171) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:27] __main__ INFO: [0mEpoch 97 Step 300/390 lr 0.010000 loss 0.0121 (0.0173) acc@1 1.0000 (0.9956) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:30] __main__ INFO: [0mEpoch 97 Step 390/390 lr 0.010000 loss 0.0156 (0.0177) acc@1 1.0000 (0.9953) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:31] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:20:31] __main__ INFO: [0mVal 97
[32m[2022-06-11 10:20:32] __main__ INFO: [0mEpoch 97 loss 0.3126 acc@1 0.9248 acc@5 0.9985
[32m[2022-06-11 10:20:32] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:20:32] __main__ INFO: [0mTrain 98 37830
[32m[2022-06-11 10:20:36] __main__ INFO: [0mEpoch 98 Step 100/390 lr 0.010000 loss 0.0034 (0.0186) acc@1 1.0000 (0.9955) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:40] __main__ INFO: [0mEpoch 98 Step 200/390 lr 0.010000 loss 0.0068 (0.0171) acc@1 1.0000 (0.9960) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:43] __main__ INFO: [0mEpoch 98 Step 300/390 lr 0.010000 loss 0.0238 (0.0168) acc@1 0.9922 (0.9957) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:47] __main__ INFO: [0mEpoch 98 Step 390/390 lr 0.010000 loss 0.0182 (0.0168) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:47] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:20:47] __main__ INFO: [0mVal 98
[32m[2022-06-11 10:20:48] __main__ INFO: [0mEpoch 98 loss 0.3147 acc@1 0.9257 acc@5 0.9984
[32m[2022-06-11 10:20:48] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:20:48] __main__ INFO: [0mTrain 99 38220
[32m[2022-06-11 10:20:52] __main__ INFO: [0mEpoch 99 Step 100/390 lr 0.010000 loss 0.0130 (0.0157) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:20:56] __main__ INFO: [0mEpoch 99 Step 200/390 lr 0.010000 loss 0.0091 (0.0160) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:00] __main__ INFO: [0mEpoch 99 Step 300/390 lr 0.010000 loss 0.0119 (0.0158) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:04] __main__ INFO: [0mEpoch 99 Step 390/390 lr 0.010000 loss 0.0271 (0.0159) acc@1 0.9922 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:04] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:21:04] __main__ INFO: [0mVal 99
[32m[2022-06-11 10:21:05] __main__ INFO: [0mEpoch 99 loss 0.3089 acc@1 0.9257 acc@5 0.9984
[32m[2022-06-11 10:21:05] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:21:05] __main__ INFO: [0mTrain 100 38610
[32m[2022-06-11 10:21:09] __main__ INFO: [0mEpoch 100 Step 100/390 lr 0.010000 loss 0.0340 (0.0130) acc@1 0.9844 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:13] __main__ INFO: [0mEpoch 100 Step 200/390 lr 0.010000 loss 0.0062 (0.0142) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:17] __main__ INFO: [0mEpoch 100 Step 300/390 lr 0.010000 loss 0.0227 (0.0144) acc@1 1.0000 (0.9963) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:20] __main__ INFO: [0mEpoch 100 Step 390/390 lr 0.010000 loss 0.0256 (0.0148) acc@1 0.9844 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:21] __main__ INFO: [0mElapsed 15.78
[32m[2022-06-11 10:21:21] __main__ INFO: [0mVal 100
[32m[2022-06-11 10:21:22] __main__ INFO: [0mEpoch 100 loss 0.3121 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:21:22] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:21:22] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00100.pth
[32m[2022-06-11 10:21:22] __main__ INFO: [0mTrain 101 39000
[32m[2022-06-11 10:21:26] __main__ INFO: [0mEpoch 101 Step 100/390 lr 0.010000 loss 0.0396 (0.0149) acc@1 0.9922 (0.9961) acc@5 1.0000 (0.9999)
[32m[2022-06-11 10:21:30] __main__ INFO: [0mEpoch 101 Step 200/390 lr 0.010000 loss 0.0291 (0.0150) acc@1 0.9922 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:34] __main__ INFO: [0mEpoch 101 Step 300/390 lr 0.010000 loss 0.0304 (0.0155) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:37] __main__ INFO: [0mEpoch 101 Step 390/390 lr 0.010000 loss 0.0062 (0.0157) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:37] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:21:37] __main__ INFO: [0mVal 101
[32m[2022-06-11 10:21:38] __main__ INFO: [0mEpoch 101 loss 0.3245 acc@1 0.9236 acc@5 0.9982
[32m[2022-06-11 10:21:38] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:21:38] __main__ INFO: [0mTrain 102 39390
[32m[2022-06-11 10:21:43] __main__ INFO: [0mEpoch 102 Step 100/390 lr 0.010000 loss 0.0160 (0.0143) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:47] __main__ INFO: [0mEpoch 102 Step 200/390 lr 0.010000 loss 0.0140 (0.0152) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:51] __main__ INFO: [0mEpoch 102 Step 300/390 lr 0.010000 loss 0.0241 (0.0152) acc@1 0.9922 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:54] __main__ INFO: [0mEpoch 102 Step 390/390 lr 0.010000 loss 0.0056 (0.0152) acc@1 1.0000 (0.9961) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:21:54] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:21:54] __main__ INFO: [0mVal 102
[32m[2022-06-11 10:21:55] __main__ INFO: [0mEpoch 102 loss 0.3157 acc@1 0.9243 acc@5 0.9984
[32m[2022-06-11 10:21:55] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:21:55] __main__ INFO: [0mTrain 103 39780
[32m[2022-06-11 10:21:59] __main__ INFO: [0mEpoch 103 Step 100/390 lr 0.010000 loss 0.0052 (0.0144) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:03] __main__ INFO: [0mEpoch 103 Step 200/390 lr 0.010000 loss 0.0146 (0.0152) acc@1 0.9922 (0.9956) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:07] __main__ INFO: [0mEpoch 103 Step 300/390 lr 0.010000 loss 0.0121 (0.0153) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:11] __main__ INFO: [0mEpoch 103 Step 390/390 lr 0.010000 loss 0.0110 (0.0150) acc@1 1.0000 (0.9959) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:11] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:22:11] __main__ INFO: [0mVal 103
[32m[2022-06-11 10:22:12] __main__ INFO: [0mEpoch 103 loss 0.3255 acc@1 0.9215 acc@5 0.9984
[32m[2022-06-11 10:22:12] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:22:12] __main__ INFO: [0mTrain 104 40170
[32m[2022-06-11 10:22:16] __main__ INFO: [0mEpoch 104 Step 100/390 lr 0.010000 loss 0.0080 (0.0146) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:20] __main__ INFO: [0mEpoch 104 Step 200/390 lr 0.010000 loss 0.0050 (0.0135) acc@1 1.0000 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:24] __main__ INFO: [0mEpoch 104 Step 300/390 lr 0.010000 loss 0.0224 (0.0131) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:27] __main__ INFO: [0mEpoch 104 Step 390/390 lr 0.010000 loss 0.0241 (0.0132) acc@1 0.9844 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:27] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:22:27] __main__ INFO: [0mVal 104
[32m[2022-06-11 10:22:28] __main__ INFO: [0mEpoch 104 loss 0.3291 acc@1 0.9229 acc@5 0.9981
[32m[2022-06-11 10:22:28] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:22:28] __main__ INFO: [0mTrain 105 40560
[32m[2022-06-11 10:22:32] __main__ INFO: [0mEpoch 105 Step 100/390 lr 0.010000 loss 0.0369 (0.0129) acc@1 0.9844 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:36] __main__ INFO: [0mEpoch 105 Step 200/390 lr 0.010000 loss 0.0176 (0.0128) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:40] __main__ INFO: [0mEpoch 105 Step 300/390 lr 0.010000 loss 0.0210 (0.0131) acc@1 0.9844 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:44] __main__ INFO: [0mEpoch 105 Step 390/390 lr 0.010000 loss 0.0223 (0.0136) acc@1 0.9922 (0.9966) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:44] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:22:44] __main__ INFO: [0mVal 105
[32m[2022-06-11 10:22:45] __main__ INFO: [0mEpoch 105 loss 0.3259 acc@1 0.9234 acc@5 0.9980
[32m[2022-06-11 10:22:45] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:22:45] __main__ INFO: [0mTrain 106 40950
[32m[2022-06-11 10:22:49] __main__ INFO: [0mEpoch 106 Step 100/390 lr 0.010000 loss 0.0076 (0.0118) acc@1 1.0000 (0.9971) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:53] __main__ INFO: [0mEpoch 106 Step 200/390 lr 0.010000 loss 0.0049 (0.0114) acc@1 1.0000 (0.9972) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:22:57] __main__ INFO: [0mEpoch 106 Step 300/390 lr 0.010000 loss 0.0101 (0.0121) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:00] __main__ INFO: [0mEpoch 106 Step 390/390 lr 0.010000 loss 0.0011 (0.0125) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:01] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:23:01] __main__ INFO: [0mVal 106
[32m[2022-06-11 10:23:02] __main__ INFO: [0mEpoch 106 loss 0.3271 acc@1 0.9249 acc@5 0.9978
[32m[2022-06-11 10:23:02] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:23:02] __main__ INFO: [0mTrain 107 41340
[32m[2022-06-11 10:23:06] __main__ INFO: [0mEpoch 107 Step 100/390 lr 0.010000 loss 0.0056 (0.0108) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:10] __main__ INFO: [0mEpoch 107 Step 200/390 lr 0.010000 loss 0.0076 (0.0114) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:14] __main__ INFO: [0mEpoch 107 Step 300/390 lr 0.010000 loss 0.0186 (0.0114) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:17] __main__ INFO: [0mEpoch 107 Step 390/390 lr 0.010000 loss 0.0027 (0.0117) acc@1 1.0000 (0.9969) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:17] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 10:23:17] __main__ INFO: [0mVal 107
[32m[2022-06-11 10:23:18] __main__ INFO: [0mEpoch 107 loss 0.3328 acc@1 0.9237 acc@5 0.9977
[32m[2022-06-11 10:23:18] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:23:18] __main__ INFO: [0mTrain 108 41730
[32m[2022-06-11 10:23:23] __main__ INFO: [0mEpoch 108 Step 100/390 lr 0.010000 loss 0.0044 (0.0143) acc@1 1.0000 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:26] __main__ INFO: [0mEpoch 108 Step 200/390 lr 0.010000 loss 0.0060 (0.0134) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:30] __main__ INFO: [0mEpoch 108 Step 300/390 lr 0.010000 loss 0.0194 (0.0128) acc@1 0.9922 (0.9965) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:34] __main__ INFO: [0mEpoch 108 Step 390/390 lr 0.010000 loss 0.0053 (0.0125) acc@1 1.0000 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:34] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:23:34] __main__ INFO: [0mVal 108
[32m[2022-06-11 10:23:35] __main__ INFO: [0mEpoch 108 loss 0.3304 acc@1 0.9239 acc@5 0.9977
[32m[2022-06-11 10:23:35] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:23:35] __main__ INFO: [0mTrain 109 42120
[32m[2022-06-11 10:23:39] __main__ INFO: [0mEpoch 109 Step 100/390 lr 0.010000 loss 0.0232 (0.0108) acc@1 0.9844 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:43] __main__ INFO: [0mEpoch 109 Step 200/390 lr 0.010000 loss 0.0030 (0.0118) acc@1 1.0000 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:47] __main__ INFO: [0mEpoch 109 Step 300/390 lr 0.010000 loss 0.0125 (0.0118) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:50] __main__ INFO: [0mEpoch 109 Step 390/390 lr 0.010000 loss 0.0112 (0.0122) acc@1 1.0000 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:23:51] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 10:23:51] __main__ INFO: [0mVal 109
[32m[2022-06-11 10:23:52] __main__ INFO: [0mEpoch 109 loss 0.3293 acc@1 0.9226 acc@5 0.9973
[32m[2022-06-11 10:23:52] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:23:52] __main__ INFO: [0mTrain 110 42510
[32m[2022-06-11 10:23:56] __main__ INFO: [0mEpoch 110 Step 100/390 lr 0.010000 loss 0.0127 (0.0104) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:00] __main__ INFO: [0mEpoch 110 Step 200/390 lr 0.010000 loss 0.0354 (0.0106) acc@1 0.9922 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:04] __main__ INFO: [0mEpoch 110 Step 300/390 lr 0.010000 loss 0.0714 (0.0113) acc@1 0.9766 (0.9972) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:07] __main__ INFO: [0mEpoch 110 Step 390/390 lr 0.010000 loss 0.0118 (0.0112) acc@1 0.9922 (0.9973) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:07] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:24:07] __main__ INFO: [0mVal 110
[32m[2022-06-11 10:24:08] __main__ INFO: [0mEpoch 110 loss 0.3347 acc@1 0.9238 acc@5 0.9981
[32m[2022-06-11 10:24:08] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:24:08] __main__ INFO: [0mTrain 111 42900
[32m[2022-06-11 10:24:12] __main__ INFO: [0mEpoch 111 Step 100/390 lr 0.010000 loss 0.0154 (0.0119) acc@1 0.9922 (0.9967) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:16] __main__ INFO: [0mEpoch 111 Step 200/390 lr 0.010000 loss 0.0149 (0.0116) acc@1 0.9922 (0.9968) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:20] __main__ INFO: [0mEpoch 111 Step 300/390 lr 0.010000 loss 0.0379 (0.0112) acc@1 0.9922 (0.9971) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:24] __main__ INFO: [0mEpoch 111 Step 390/390 lr 0.010000 loss 0.0229 (0.0114) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:24] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:24:24] __main__ INFO: [0mVal 111
[32m[2022-06-11 10:24:25] __main__ INFO: [0mEpoch 111 loss 0.3314 acc@1 0.9236 acc@5 0.9980
[32m[2022-06-11 10:24:25] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:24:25] __main__ INFO: [0mTrain 112 43290
[32m[2022-06-11 10:24:29] __main__ INFO: [0mEpoch 112 Step 100/390 lr 0.010000 loss 0.0054 (0.0097) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:33] __main__ INFO: [0mEpoch 112 Step 200/390 lr 0.010000 loss 0.0113 (0.0101) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:37] __main__ INFO: [0mEpoch 112 Step 300/390 lr 0.010000 loss 0.0124 (0.0100) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:40] __main__ INFO: [0mEpoch 112 Step 390/390 lr 0.010000 loss 0.0067 (0.0104) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:41] __main__ INFO: [0mElapsed 15.96
[32m[2022-06-11 10:24:41] __main__ INFO: [0mVal 112
[32m[2022-06-11 10:24:42] __main__ INFO: [0mEpoch 112 loss 0.3295 acc@1 0.9269 acc@5 0.9978
[32m[2022-06-11 10:24:42] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:24:42] __main__ INFO: [0mTrain 113 43680
[32m[2022-06-11 10:24:46] __main__ INFO: [0mEpoch 113 Step 100/390 lr 0.010000 loss 0.0218 (0.0108) acc@1 0.9922 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:50] __main__ INFO: [0mEpoch 113 Step 200/390 lr 0.010000 loss 0.0106 (0.0103) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:54] __main__ INFO: [0mEpoch 113 Step 300/390 lr 0.010000 loss 0.0092 (0.0103) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:58] __main__ INFO: [0mEpoch 113 Step 390/390 lr 0.010000 loss 0.0017 (0.0104) acc@1 1.0000 (0.9976) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:24:58] __main__ INFO: [0mElapsed 16.11
[32m[2022-06-11 10:24:58] __main__ INFO: [0mVal 113
[32m[2022-06-11 10:24:59] __main__ INFO: [0mEpoch 113 loss 0.3368 acc@1 0.9232 acc@5 0.9979
[32m[2022-06-11 10:24:59] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:24:59] __main__ INFO: [0mTrain 114 44070
[32m[2022-06-11 10:25:03] __main__ INFO: [0mEpoch 114 Step 100/390 lr 0.010000 loss 0.0130 (0.0112) acc@1 0.9922 (0.9970) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:07] __main__ INFO: [0mEpoch 114 Step 200/390 lr 0.010000 loss 0.0103 (0.0106) acc@1 0.9922 (0.9973) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:11] __main__ INFO: [0mEpoch 114 Step 300/390 lr 0.010000 loss 0.0056 (0.0104) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:14] __main__ INFO: [0mEpoch 114 Step 390/390 lr 0.010000 loss 0.0054 (0.0105) acc@1 1.0000 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:14] __main__ INFO: [0mElapsed 15.86
[32m[2022-06-11 10:25:14] __main__ INFO: [0mVal 114
[32m[2022-06-11 10:25:15] __main__ INFO: [0mEpoch 114 loss 0.3349 acc@1 0.9241 acc@5 0.9982
[32m[2022-06-11 10:25:15] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:25:15] __main__ INFO: [0mTrain 115 44460
[32m[2022-06-11 10:25:20] __main__ INFO: [0mEpoch 115 Step 100/390 lr 0.010000 loss 0.0038 (0.0092) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:23] __main__ INFO: [0mEpoch 115 Step 200/390 lr 0.010000 loss 0.0056 (0.0091) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:27] __main__ INFO: [0mEpoch 115 Step 300/390 lr 0.010000 loss 0.0078 (0.0093) acc@1 1.0000 (0.9980) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:31] __main__ INFO: [0mEpoch 115 Step 390/390 lr 0.010000 loss 0.0032 (0.0099) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:31] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:25:31] __main__ INFO: [0mVal 115
[32m[2022-06-11 10:25:32] __main__ INFO: [0mEpoch 115 loss 0.3382 acc@1 0.9232 acc@5 0.9980
[32m[2022-06-11 10:25:32] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:25:32] __main__ INFO: [0mTrain 116 44850
[32m[2022-06-11 10:25:36] __main__ INFO: [0mEpoch 116 Step 100/390 lr 0.010000 loss 0.0104 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:40] __main__ INFO: [0mEpoch 116 Step 200/390 lr 0.010000 loss 0.0052 (0.0097) acc@1 1.0000 (0.9974) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:44] __main__ INFO: [0mEpoch 116 Step 300/390 lr 0.010000 loss 0.0034 (0.0091) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:48] __main__ INFO: [0mEpoch 116 Step 390/390 lr 0.010000 loss 0.0038 (0.0094) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:48] __main__ INFO: [0mElapsed 16.21
[32m[2022-06-11 10:25:48] __main__ INFO: [0mVal 116
[32m[2022-06-11 10:25:49] __main__ INFO: [0mEpoch 116 loss 0.3378 acc@1 0.9256 acc@5 0.9981
[32m[2022-06-11 10:25:49] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:25:49] __main__ INFO: [0mTrain 117 45240
[32m[2022-06-11 10:25:53] __main__ INFO: [0mEpoch 117 Step 100/390 lr 0.010000 loss 0.0078 (0.0095) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:25:57] __main__ INFO: [0mEpoch 117 Step 200/390 lr 0.010000 loss 0.0057 (0.0097) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:02] __main__ INFO: [0mEpoch 117 Step 300/390 lr 0.010000 loss 0.0104 (0.0095) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:05] __main__ INFO: [0mEpoch 117 Step 390/390 lr 0.010000 loss 0.0465 (0.0098) acc@1 0.9766 (0.9975) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:05] __main__ INFO: [0mElapsed 16.14
[32m[2022-06-11 10:26:05] __main__ INFO: [0mVal 117
[32m[2022-06-11 10:26:06] __main__ INFO: [0mEpoch 117 loss 0.3420 acc@1 0.9234 acc@5 0.9975
[32m[2022-06-11 10:26:06] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 10:26:06] __main__ INFO: [0mTrain 118 45630
[32m[2022-06-11 10:26:10] __main__ INFO: [0mEpoch 118 Step 100/390 lr 0.010000 loss 0.0028 (0.0096) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:14] __main__ INFO: [0mEpoch 118 Step 200/390 lr 0.010000 loss 0.0137 (0.0091) acc@1 0.9922 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:18] __main__ INFO: [0mEpoch 118 Step 300/390 lr 0.010000 loss 0.0096 (0.0090) acc@1 0.9922 (0.9980) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:22] __main__ INFO: [0mEpoch 118 Step 390/390 lr 0.010000 loss 0.0078 (0.0092) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:22] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 10:26:22] __main__ INFO: [0mVal 118
[32m[2022-06-11 10:26:23] __main__ INFO: [0mEpoch 118 loss 0.3374 acc@1 0.9246 acc@5 0.9981
[32m[2022-06-11 10:26:23] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:26:23] __main__ INFO: [0mTrain 119 46020
[32m[2022-06-11 10:26:27] __main__ INFO: [0mEpoch 119 Step 100/390 lr 0.010000 loss 0.0241 (0.0096) acc@1 0.9922 (0.9981) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:31] __main__ INFO: [0mEpoch 119 Step 200/390 lr 0.010000 loss 0.0026 (0.0095) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:35] __main__ INFO: [0mEpoch 119 Step 300/390 lr 0.010000 loss 0.0066 (0.0094) acc@1 1.0000 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:38] __main__ INFO: [0mEpoch 119 Step 390/390 lr 0.010000 loss 0.0066 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:39] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 10:26:39] __main__ INFO: [0mVal 119
[32m[2022-06-11 10:26:40] __main__ INFO: [0mEpoch 119 loss 0.3417 acc@1 0.9243 acc@5 0.9982
[32m[2022-06-11 10:26:40] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:26:40] __main__ INFO: [0mTrain 120 46410
[32m[2022-06-11 10:26:44] __main__ INFO: [0mEpoch 120 Step 100/390 lr 0.010000 loss 0.0080 (0.0086) acc@1 0.9922 (0.9981) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:48] __main__ INFO: [0mEpoch 120 Step 200/390 lr 0.010000 loss 0.0103 (0.0091) acc@1 1.0000 (0.9979) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:52] __main__ INFO: [0mEpoch 120 Step 300/390 lr 0.010000 loss 0.0150 (0.0089) acc@1 0.9922 (0.9978) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:55] __main__ INFO: [0mEpoch 120 Step 390/390 lr 0.010000 loss 0.0097 (0.0091) acc@1 1.0000 (0.9977) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:26:55] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 10:26:55] __main__ INFO: [0mVal 120
[32m[2022-06-11 10:26:56] __main__ INFO: [0mEpoch 120 loss 0.3371 acc@1 0.9245 acc@5 0.9983
[32m[2022-06-11 10:26:56] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:26:56] __main__ INFO: [0mTrain 121 46800
[32m[2022-06-11 10:27:01] __main__ INFO: [0mEpoch 121 Step 100/390 lr 0.001000 loss 0.0052 (0.0080) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:04] __main__ INFO: [0mEpoch 121 Step 200/390 lr 0.001000 loss 0.0036 (0.0078) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:08] __main__ INFO: [0mEpoch 121 Step 300/390 lr 0.001000 loss 0.0076 (0.0074) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:12] __main__ INFO: [0mEpoch 121 Step 390/390 lr 0.001000 loss 0.0044 (0.0077) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:12] __main__ INFO: [0mElapsed 15.51
[32m[2022-06-11 10:27:12] __main__ INFO: [0mVal 121
[32m[2022-06-11 10:27:13] __main__ INFO: [0mEpoch 121 loss 0.3372 acc@1 0.9249 acc@5 0.9982
[32m[2022-06-11 10:27:13] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:27:13] __main__ INFO: [0mTrain 122 47190
[32m[2022-06-11 10:27:17] __main__ INFO: [0mEpoch 122 Step 100/390 lr 0.001000 loss 0.0092 (0.0073) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:21] __main__ INFO: [0mEpoch 122 Step 200/390 lr 0.001000 loss 0.0058 (0.0075) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:25] __main__ INFO: [0mEpoch 122 Step 300/390 lr 0.001000 loss 0.0053 (0.0074) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:29] __main__ INFO: [0mEpoch 122 Step 390/390 lr 0.001000 loss 0.0069 (0.0075) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:29] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:27:29] __main__ INFO: [0mVal 122
[32m[2022-06-11 10:27:30] __main__ INFO: [0mEpoch 122 loss 0.3346 acc@1 0.9258 acc@5 0.9979
[32m[2022-06-11 10:27:30] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:27:30] __main__ INFO: [0mTrain 123 47580
[32m[2022-06-11 10:27:34] __main__ INFO: [0mEpoch 123 Step 100/390 lr 0.001000 loss 0.0082 (0.0062) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:38] __main__ INFO: [0mEpoch 123 Step 200/390 lr 0.001000 loss 0.0059 (0.0065) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:42] __main__ INFO: [0mEpoch 123 Step 300/390 lr 0.001000 loss 0.0020 (0.0070) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:45] __main__ INFO: [0mEpoch 123 Step 390/390 lr 0.001000 loss 0.0136 (0.0071) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:45] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:27:45] __main__ INFO: [0mVal 123
[32m[2022-06-11 10:27:46] __main__ INFO: [0mEpoch 123 loss 0.3341 acc@1 0.9247 acc@5 0.9980
[32m[2022-06-11 10:27:46] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:27:46] __main__ INFO: [0mTrain 124 47970
[32m[2022-06-11 10:27:50] __main__ INFO: [0mEpoch 124 Step 100/390 lr 0.001000 loss 0.0045 (0.0086) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:54] __main__ INFO: [0mEpoch 124 Step 200/390 lr 0.001000 loss 0.0027 (0.0076) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:27:58] __main__ INFO: [0mEpoch 124 Step 300/390 lr 0.001000 loss 0.0223 (0.0074) acc@1 0.9922 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:02] __main__ INFO: [0mEpoch 124 Step 390/390 lr 0.001000 loss 0.0039 (0.0073) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:02] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:28:02] __main__ INFO: [0mVal 124
[32m[2022-06-11 10:28:03] __main__ INFO: [0mEpoch 124 loss 0.3348 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:28:03] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:28:03] __main__ INFO: [0mTrain 125 48360
[32m[2022-06-11 10:28:07] __main__ INFO: [0mEpoch 125 Step 100/390 lr 0.001000 loss 0.0354 (0.0077) acc@1 0.9922 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:11] __main__ INFO: [0mEpoch 125 Step 200/390 lr 0.001000 loss 0.0044 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:15] __main__ INFO: [0mEpoch 125 Step 300/390 lr 0.001000 loss 0.0058 (0.0069) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:19] __main__ INFO: [0mEpoch 125 Step 390/390 lr 0.001000 loss 0.0120 (0.0071) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:19] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:28:19] __main__ INFO: [0mVal 125
[32m[2022-06-11 10:28:20] __main__ INFO: [0mEpoch 125 loss 0.3356 acc@1 0.9260 acc@5 0.9982
[32m[2022-06-11 10:28:20] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:28:20] __main__ INFO: [0mTrain 126 48750
[32m[2022-06-11 10:28:24] __main__ INFO: [0mEpoch 126 Step 100/390 lr 0.001000 loss 0.0039 (0.0072) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:28] __main__ INFO: [0mEpoch 126 Step 200/390 lr 0.001000 loss 0.0036 (0.0076) acc@1 1.0000 (0.9982) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:32] __main__ INFO: [0mEpoch 126 Step 300/390 lr 0.001000 loss 0.0049 (0.0076) acc@1 1.0000 (0.9983) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:36] __main__ INFO: [0mEpoch 126 Step 390/390 lr 0.001000 loss 0.0028 (0.0076) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:36] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:28:36] __main__ INFO: [0mVal 126
[32m[2022-06-11 10:28:37] __main__ INFO: [0mEpoch 126 loss 0.3332 acc@1 0.9261 acc@5 0.9980
[32m[2022-06-11 10:28:37] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:28:37] __main__ INFO: [0mTrain 127 49140
[32m[2022-06-11 10:28:41] __main__ INFO: [0mEpoch 127 Step 100/390 lr 0.001000 loss 0.0024 (0.0068) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:45] __main__ INFO: [0mEpoch 127 Step 200/390 lr 0.001000 loss 0.0094 (0.0069) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:49] __main__ INFO: [0mEpoch 127 Step 300/390 lr 0.001000 loss 0.0051 (0.0072) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:52] __main__ INFO: [0mEpoch 127 Step 390/390 lr 0.001000 loss 0.0033 (0.0071) acc@1 1.0000 (0.9985) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:28:52] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:28:52] __main__ INFO: [0mVal 127
[32m[2022-06-11 10:28:53] __main__ INFO: [0mEpoch 127 loss 0.3333 acc@1 0.9273 acc@5 0.9983
[32m[2022-06-11 10:28:53] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:28:53] __main__ INFO: [0mTrain 128 49530
[32m[2022-06-11 10:28:57] __main__ INFO: [0mEpoch 128 Step 100/390 lr 0.001000 loss 0.0028 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:02] __main__ INFO: [0mEpoch 128 Step 200/390 lr 0.001000 loss 0.0021 (0.0067) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:06] __main__ INFO: [0mEpoch 128 Step 300/390 lr 0.001000 loss 0.0020 (0.0066) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:09] __main__ INFO: [0mEpoch 128 Step 390/390 lr 0.001000 loss 0.0038 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:10] __main__ INFO: [0mElapsed 16.38
[32m[2022-06-11 10:29:10] __main__ INFO: [0mVal 128
[32m[2022-06-11 10:29:11] __main__ INFO: [0mEpoch 128 loss 0.3336 acc@1 0.9268 acc@5 0.9982
[32m[2022-06-11 10:29:11] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:29:11] __main__ INFO: [0mTrain 129 49920
[32m[2022-06-11 10:29:15] __main__ INFO: [0mEpoch 129 Step 100/390 lr 0.001000 loss 0.0073 (0.0072) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:19] __main__ INFO: [0mEpoch 129 Step 200/390 lr 0.001000 loss 0.0060 (0.0071) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:23] __main__ INFO: [0mEpoch 129 Step 300/390 lr 0.001000 loss 0.0015 (0.0067) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:26] __main__ INFO: [0mEpoch 129 Step 390/390 lr 0.001000 loss 0.0021 (0.0065) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:26] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:29:26] __main__ INFO: [0mVal 129
[32m[2022-06-11 10:29:27] __main__ INFO: [0mEpoch 129 loss 0.3328 acc@1 0.9267 acc@5 0.9982
[32m[2022-06-11 10:29:27] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:29:27] __main__ INFO: [0mTrain 130 50310
[32m[2022-06-11 10:29:31] __main__ INFO: [0mEpoch 130 Step 100/390 lr 0.001000 loss 0.0047 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:35] __main__ INFO: [0mEpoch 130 Step 200/390 lr 0.001000 loss 0.0048 (0.0056) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:40] __main__ INFO: [0mEpoch 130 Step 300/390 lr 0.001000 loss 0.0022 (0.0061) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:43] __main__ INFO: [0mEpoch 130 Step 390/390 lr 0.001000 loss 0.0029 (0.0061) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:43] __main__ INFO: [0mElapsed 16.03
[32m[2022-06-11 10:29:43] __main__ INFO: [0mVal 130
[32m[2022-06-11 10:29:44] __main__ INFO: [0mEpoch 130 loss 0.3332 acc@1 0.9258 acc@5 0.9982
[32m[2022-06-11 10:29:44] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:29:44] __main__ INFO: [0mTrain 131 50700
[32m[2022-06-11 10:29:48] __main__ INFO: [0mEpoch 131 Step 100/390 lr 0.001000 loss 0.0112 (0.0061) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:52] __main__ INFO: [0mEpoch 131 Step 200/390 lr 0.001000 loss 0.0026 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:29:56] __main__ INFO: [0mEpoch 131 Step 300/390 lr 0.001000 loss 0.0196 (0.0068) acc@1 0.9922 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:00] __main__ INFO: [0mEpoch 131 Step 390/390 lr 0.001000 loss 0.0069 (0.0068) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:00] __main__ INFO: [0mElapsed 15.98
[32m[2022-06-11 10:30:00] __main__ INFO: [0mVal 131
[32m[2022-06-11 10:30:01] __main__ INFO: [0mEpoch 131 loss 0.3339 acc@1 0.9273 acc@5 0.9983
[32m[2022-06-11 10:30:01] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:30:01] __main__ INFO: [0mTrain 132 51090
[32m[2022-06-11 10:30:05] __main__ INFO: [0mEpoch 132 Step 100/390 lr 0.001000 loss 0.0064 (0.0062) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:09] __main__ INFO: [0mEpoch 132 Step 200/390 lr 0.001000 loss 0.0073 (0.0064) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:13] __main__ INFO: [0mEpoch 132 Step 300/390 lr 0.001000 loss 0.0027 (0.0063) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:17] __main__ INFO: [0mEpoch 132 Step 390/390 lr 0.001000 loss 0.0036 (0.0065) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:17] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:30:17] __main__ INFO: [0mVal 132
[32m[2022-06-11 10:30:18] __main__ INFO: [0mEpoch 132 loss 0.3362 acc@1 0.9260 acc@5 0.9981
[32m[2022-06-11 10:30:18] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:30:18] __main__ INFO: [0mTrain 133 51480
[32m[2022-06-11 10:30:22] __main__ INFO: [0mEpoch 133 Step 100/390 lr 0.001000 loss 0.0055 (0.0067) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:26] __main__ INFO: [0mEpoch 133 Step 200/390 lr 0.001000 loss 0.0054 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:30] __main__ INFO: [0mEpoch 133 Step 300/390 lr 0.001000 loss 0.0036 (0.0062) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:33] __main__ INFO: [0mEpoch 133 Step 390/390 lr 0.001000 loss 0.0072 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:33] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:30:33] __main__ INFO: [0mVal 133
[32m[2022-06-11 10:30:34] __main__ INFO: [0mEpoch 133 loss 0.3328 acc@1 0.9266 acc@5 0.9982
[32m[2022-06-11 10:30:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:30:34] __main__ INFO: [0mTrain 134 51870
[32m[2022-06-11 10:30:38] __main__ INFO: [0mEpoch 134 Step 100/390 lr 0.001000 loss 0.0065 (0.0062) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:42] __main__ INFO: [0mEpoch 134 Step 200/390 lr 0.001000 loss 0.0072 (0.0060) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:46] __main__ INFO: [0mEpoch 134 Step 300/390 lr 0.001000 loss 0.0050 (0.0063) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:50] __main__ INFO: [0mEpoch 134 Step 390/390 lr 0.001000 loss 0.0045 (0.0062) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:50] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:30:50] __main__ INFO: [0mVal 134
[32m[2022-06-11 10:30:51] __main__ INFO: [0mEpoch 134 loss 0.3339 acc@1 0.9271 acc@5 0.9981
[32m[2022-06-11 10:30:51] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:30:51] __main__ INFO: [0mTrain 135 52260
[32m[2022-06-11 10:30:55] __main__ INFO: [0mEpoch 135 Step 100/390 lr 0.001000 loss 0.0108 (0.0056) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:30:59] __main__ INFO: [0mEpoch 135 Step 200/390 lr 0.001000 loss 0.0101 (0.0058) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:03] __main__ INFO: [0mEpoch 135 Step 300/390 lr 0.001000 loss 0.0070 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:07] __main__ INFO: [0mEpoch 135 Step 390/390 lr 0.001000 loss 0.0052 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:07] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:31:07] __main__ INFO: [0mVal 135
[32m[2022-06-11 10:31:08] __main__ INFO: [0mEpoch 135 loss 0.3347 acc@1 0.9272 acc@5 0.9982
[32m[2022-06-11 10:31:08] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:31:08] __main__ INFO: [0mTrain 136 52650
[32m[2022-06-11 10:31:12] __main__ INFO: [0mEpoch 136 Step 100/390 lr 0.001000 loss 0.0041 (0.0059) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:16] __main__ INFO: [0mEpoch 136 Step 200/390 lr 0.001000 loss 0.0026 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:20] __main__ INFO: [0mEpoch 136 Step 300/390 lr 0.001000 loss 0.0223 (0.0063) acc@1 0.9922 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:23] __main__ INFO: [0mEpoch 136 Step 390/390 lr 0.001000 loss 0.0054 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:23] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:31:23] __main__ INFO: [0mVal 136
[32m[2022-06-11 10:31:24] __main__ INFO: [0mEpoch 136 loss 0.3359 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:31:24] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:31:24] __main__ INFO: [0mTrain 137 53040
[32m[2022-06-11 10:31:28] __main__ INFO: [0mEpoch 137 Step 100/390 lr 0.001000 loss 0.0048 (0.0056) acc@1 1.0000 (0.9994) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:32] __main__ INFO: [0mEpoch 137 Step 200/390 lr 0.001000 loss 0.0014 (0.0056) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:36] __main__ INFO: [0mEpoch 137 Step 300/390 lr 0.001000 loss 0.0034 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:40] __main__ INFO: [0mEpoch 137 Step 390/390 lr 0.001000 loss 0.0210 (0.0057) acc@1 0.9844 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:40] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:31:40] __main__ INFO: [0mVal 137
[32m[2022-06-11 10:31:41] __main__ INFO: [0mEpoch 137 loss 0.3332 acc@1 0.9271 acc@5 0.9982
[32m[2022-06-11 10:31:41] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:31:41] __main__ INFO: [0mTrain 138 53430
[32m[2022-06-11 10:31:45] __main__ INFO: [0mEpoch 138 Step 100/390 lr 0.001000 loss 0.0024 (0.0071) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:49] __main__ INFO: [0mEpoch 138 Step 200/390 lr 0.001000 loss 0.0046 (0.0068) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:53] __main__ INFO: [0mEpoch 138 Step 300/390 lr 0.001000 loss 0.0037 (0.0070) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:57] __main__ INFO: [0mEpoch 138 Step 390/390 lr 0.001000 loss 0.0058 (0.0067) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:31:57] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 10:31:57] __main__ INFO: [0mVal 138
[32m[2022-06-11 10:31:58] __main__ INFO: [0mEpoch 138 loss 0.3346 acc@1 0.9269 acc@5 0.9982
[32m[2022-06-11 10:31:58] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:31:58] __main__ INFO: [0mTrain 139 53820
[32m[2022-06-11 10:32:02] __main__ INFO: [0mEpoch 139 Step 100/390 lr 0.001000 loss 0.0025 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:06] __main__ INFO: [0mEpoch 139 Step 200/390 lr 0.001000 loss 0.0043 (0.0058) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:10] __main__ INFO: [0mEpoch 139 Step 300/390 lr 0.001000 loss 0.0031 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:13] __main__ INFO: [0mEpoch 139 Step 390/390 lr 0.001000 loss 0.0043 (0.0060) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:13] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 10:32:13] __main__ INFO: [0mVal 139
[32m[2022-06-11 10:32:14] __main__ INFO: [0mEpoch 139 loss 0.3363 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:32:14] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:32:14] __main__ INFO: [0mTrain 140 54210
[32m[2022-06-11 10:32:19] __main__ INFO: [0mEpoch 140 Step 100/390 lr 0.001000 loss 0.0022 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:22] __main__ INFO: [0mEpoch 140 Step 200/390 lr 0.001000 loss 0.0044 (0.0063) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:26] __main__ INFO: [0mEpoch 140 Step 300/390 lr 0.001000 loss 0.0017 (0.0064) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:30] __main__ INFO: [0mEpoch 140 Step 390/390 lr 0.001000 loss 0.0125 (0.0062) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:30] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:32:30] __main__ INFO: [0mVal 140
[32m[2022-06-11 10:32:31] __main__ INFO: [0mEpoch 140 loss 0.3373 acc@1 0.9267 acc@5 0.9981
[32m[2022-06-11 10:32:31] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:32:31] __main__ INFO: [0mTrain 141 54600
[32m[2022-06-11 10:32:35] __main__ INFO: [0mEpoch 141 Step 100/390 lr 0.001000 loss 0.0035 (0.0053) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:39] __main__ INFO: [0mEpoch 141 Step 200/390 lr 0.001000 loss 0.0054 (0.0061) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:43] __main__ INFO: [0mEpoch 141 Step 300/390 lr 0.001000 loss 0.0061 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:47] __main__ INFO: [0mEpoch 141 Step 390/390 lr 0.001000 loss 0.0043 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:47] __main__ INFO: [0mElapsed 16.02
[32m[2022-06-11 10:32:47] __main__ INFO: [0mVal 141
[32m[2022-06-11 10:32:48] __main__ INFO: [0mEpoch 141 loss 0.3360 acc@1 0.9276 acc@5 0.9981
[32m[2022-06-11 10:32:48] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:32:48] __main__ INFO: [0mTrain 142 54990
[32m[2022-06-11 10:32:52] __main__ INFO: [0mEpoch 142 Step 100/390 lr 0.001000 loss 0.0058 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:32:56] __main__ INFO: [0mEpoch 142 Step 200/390 lr 0.001000 loss 0.0057 (0.0064) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:00] __main__ INFO: [0mEpoch 142 Step 300/390 lr 0.001000 loss 0.0074 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:04] __main__ INFO: [0mEpoch 142 Step 390/390 lr 0.001000 loss 0.0032 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:04] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:33:04] __main__ INFO: [0mVal 142
[32m[2022-06-11 10:33:05] __main__ INFO: [0mEpoch 142 loss 0.3345 acc@1 0.9268 acc@5 0.9981
[32m[2022-06-11 10:33:05] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:05] __main__ INFO: [0mTrain 143 55380
[32m[2022-06-11 10:33:09] __main__ INFO: [0mEpoch 143 Step 100/390 lr 0.001000 loss 0.0029 (0.0059) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:13] __main__ INFO: [0mEpoch 143 Step 200/390 lr 0.001000 loss 0.0023 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:17] __main__ INFO: [0mEpoch 143 Step 300/390 lr 0.001000 loss 0.0222 (0.0058) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:20] __main__ INFO: [0mEpoch 143 Step 390/390 lr 0.001000 loss 0.0018 (0.0058) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:21] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-11 10:33:21] __main__ INFO: [0mVal 143
[32m[2022-06-11 10:33:22] __main__ INFO: [0mEpoch 143 loss 0.3364 acc@1 0.9265 acc@5 0.9980
[32m[2022-06-11 10:33:22] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:22] __main__ INFO: [0mTrain 144 55770
[32m[2022-06-11 10:33:26] __main__ INFO: [0mEpoch 144 Step 100/390 lr 0.001000 loss 0.0027 (0.0057) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:30] __main__ INFO: [0mEpoch 144 Step 200/390 lr 0.001000 loss 0.0042 (0.0064) acc@1 1.0000 (0.9984) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:34] __main__ INFO: [0mEpoch 144 Step 300/390 lr 0.001000 loss 0.0040 (0.0061) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:37] __main__ INFO: [0mEpoch 144 Step 390/390 lr 0.001000 loss 0.0034 (0.0059) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:37] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:33:37] __main__ INFO: [0mVal 144
[32m[2022-06-11 10:33:38] __main__ INFO: [0mEpoch 144 loss 0.3348 acc@1 0.9269 acc@5 0.9981
[32m[2022-06-11 10:33:38] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:33:38] __main__ INFO: [0mTrain 145 56160
[32m[2022-06-11 10:33:42] __main__ INFO: [0mEpoch 145 Step 100/390 lr 0.001000 loss 0.0053 (0.0065) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:46] __main__ INFO: [0mEpoch 145 Step 200/390 lr 0.001000 loss 0.0062 (0.0066) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:50] __main__ INFO: [0mEpoch 145 Step 300/390 lr 0.001000 loss 0.0048 (0.0063) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:54] __main__ INFO: [0mEpoch 145 Step 390/390 lr 0.001000 loss 0.0046 (0.0064) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:33:54] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 10:33:54] __main__ INFO: [0mVal 145
[32m[2022-06-11 10:33:55] __main__ INFO: [0mEpoch 145 loss 0.3356 acc@1 0.9269 acc@5 0.9979
[32m[2022-06-11 10:33:55] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:33:55] __main__ INFO: [0mTrain 146 56550
[32m[2022-06-11 10:33:59] __main__ INFO: [0mEpoch 146 Step 100/390 lr 0.001000 loss 0.0037 (0.0056) acc@1 1.0000 (0.9986) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:03] __main__ INFO: [0mEpoch 146 Step 200/390 lr 0.001000 loss 0.0009 (0.0059) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:07] __main__ INFO: [0mEpoch 146 Step 300/390 lr 0.001000 loss 0.0023 (0.0059) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:10] __main__ INFO: [0mEpoch 146 Step 390/390 lr 0.001000 loss 0.0045 (0.0058) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:11] __main__ INFO: [0mElapsed 15.74
[32m[2022-06-11 10:34:11] __main__ INFO: [0mVal 146
[32m[2022-06-11 10:34:12] __main__ INFO: [0mEpoch 146 loss 0.3340 acc@1 0.9270 acc@5 0.9979
[32m[2022-06-11 10:34:12] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 10:34:12] __main__ INFO: [0mTrain 147 56940
[32m[2022-06-11 10:34:16] __main__ INFO: [0mEpoch 147 Step 100/390 lr 0.001000 loss 0.0075 (0.0062) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:20] __main__ INFO: [0mEpoch 147 Step 200/390 lr 0.001000 loss 0.0040 (0.0056) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:24] __main__ INFO: [0mEpoch 147 Step 300/390 lr 0.001000 loss 0.0028 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:27] __main__ INFO: [0mEpoch 147 Step 390/390 lr 0.001000 loss 0.0010 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:27] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 10:34:27] __main__ INFO: [0mVal 147
[32m[2022-06-11 10:34:28] __main__ INFO: [0mEpoch 147 loss 0.3350 acc@1 0.9273 acc@5 0.9981
[32m[2022-06-11 10:34:28] __main__ INFO: [0mElapsed 0.88
[32m[2022-06-11 10:34:28] __main__ INFO: [0mTrain 148 57330
[32m[2022-06-11 10:34:32] __main__ INFO: [0mEpoch 148 Step 100/390 lr 0.001000 loss 0.0044 (0.0063) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:36] __main__ INFO: [0mEpoch 148 Step 200/390 lr 0.001000 loss 0.0027 (0.0059) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:40] __main__ INFO: [0mEpoch 148 Step 300/390 lr 0.001000 loss 0.0059 (0.0057) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:44] __main__ INFO: [0mEpoch 148 Step 390/390 lr 0.001000 loss 0.0237 (0.0059) acc@1 0.9922 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:44] __main__ INFO: [0mElapsed 16.07
[32m[2022-06-11 10:34:44] __main__ INFO: [0mVal 148
[32m[2022-06-11 10:34:45] __main__ INFO: [0mEpoch 148 loss 0.3374 acc@1 0.9266 acc@5 0.9981
[32m[2022-06-11 10:34:45] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:34:45] __main__ INFO: [0mTrain 149 57720
[32m[2022-06-11 10:34:49] __main__ INFO: [0mEpoch 149 Step 100/390 lr 0.001000 loss 0.0026 (0.0054) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:53] __main__ INFO: [0mEpoch 149 Step 200/390 lr 0.001000 loss 0.0056 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:34:57] __main__ INFO: [0mEpoch 149 Step 300/390 lr 0.001000 loss 0.0048 (0.0057) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:01] __main__ INFO: [0mEpoch 149 Step 390/390 lr 0.001000 loss 0.0046 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:01] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:35:01] __main__ INFO: [0mVal 149
[32m[2022-06-11 10:35:02] __main__ INFO: [0mEpoch 149 loss 0.3367 acc@1 0.9266 acc@5 0.9983
[32m[2022-06-11 10:35:02] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:35:02] __main__ INFO: [0mTrain 150 58110
[32m[2022-06-11 10:35:06] __main__ INFO: [0mEpoch 150 Step 100/390 lr 0.001000 loss 0.0055 (0.0053) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:10] __main__ INFO: [0mEpoch 150 Step 200/390 lr 0.001000 loss 0.0041 (0.0051) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:14] __main__ INFO: [0mEpoch 150 Step 300/390 lr 0.001000 loss 0.0046 (0.0053) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:17] __main__ INFO: [0mEpoch 150 Step 390/390 lr 0.001000 loss 0.0030 (0.0055) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:18] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 10:35:18] __main__ INFO: [0mVal 150
[32m[2022-06-11 10:35:19] __main__ INFO: [0mEpoch 150 loss 0.3352 acc@1 0.9272 acc@5 0.9981
[32m[2022-06-11 10:35:19] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:35:19] __main__ INFO: [0mTrain 151 58500
[32m[2022-06-11 10:35:23] __main__ INFO: [0mEpoch 151 Step 100/390 lr 0.001000 loss 0.0057 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:27] __main__ INFO: [0mEpoch 151 Step 200/390 lr 0.001000 loss 0.0042 (0.0056) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:31] __main__ INFO: [0mEpoch 151 Step 300/390 lr 0.001000 loss 0.0042 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:34] __main__ INFO: [0mEpoch 151 Step 390/390 lr 0.001000 loss 0.0060 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:34] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 10:35:34] __main__ INFO: [0mVal 151
[32m[2022-06-11 10:35:36] __main__ INFO: [0mEpoch 151 loss 0.3377 acc@1 0.9272 acc@5 0.9981
[32m[2022-06-11 10:35:36] __main__ INFO: [0mElapsed 1.04
[32m[2022-06-11 10:35:36] __main__ INFO: [0mTrain 152 58890
[32m[2022-06-11 10:35:40] __main__ INFO: [0mEpoch 152 Step 100/390 lr 0.001000 loss 0.0056 (0.0056) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:44] __main__ INFO: [0mEpoch 152 Step 200/390 lr 0.001000 loss 0.0035 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:48] __main__ INFO: [0mEpoch 152 Step 300/390 lr 0.001000 loss 0.0013 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:51] __main__ INFO: [0mEpoch 152 Step 390/390 lr 0.001000 loss 0.0038 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:35:51] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:35:51] __main__ INFO: [0mVal 152
[32m[2022-06-11 10:35:52] __main__ INFO: [0mEpoch 152 loss 0.3377 acc@1 0.9270 acc@5 0.9982
[32m[2022-06-11 10:35:52] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:35:52] __main__ INFO: [0mTrain 153 59280
[32m[2022-06-11 10:35:56] __main__ INFO: [0mEpoch 153 Step 100/390 lr 0.001000 loss 0.0153 (0.0063) acc@1 0.9922 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:00] __main__ INFO: [0mEpoch 153 Step 200/390 lr 0.001000 loss 0.0035 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:04] __main__ INFO: [0mEpoch 153 Step 300/390 lr 0.001000 loss 0.0062 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:08] __main__ INFO: [0mEpoch 153 Step 390/390 lr 0.001000 loss 0.0128 (0.0057) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:08] __main__ INFO: [0mElapsed 15.73
[32m[2022-06-11 10:36:08] __main__ INFO: [0mVal 153
[32m[2022-06-11 10:36:09] __main__ INFO: [0mEpoch 153 loss 0.3357 acc@1 0.9265 acc@5 0.9983
[32m[2022-06-11 10:36:09] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:36:09] __main__ INFO: [0mTrain 154 59670
[32m[2022-06-11 10:36:13] __main__ INFO: [0mEpoch 154 Step 100/390 lr 0.001000 loss 0.0048 (0.0051) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:17] __main__ INFO: [0mEpoch 154 Step 200/390 lr 0.001000 loss 0.0085 (0.0051) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:21] __main__ INFO: [0mEpoch 154 Step 300/390 lr 0.001000 loss 0.0046 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:25] __main__ INFO: [0mEpoch 154 Step 390/390 lr 0.001000 loss 0.0077 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:25] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:36:25] __main__ INFO: [0mVal 154
[32m[2022-06-11 10:36:26] __main__ INFO: [0mEpoch 154 loss 0.3375 acc@1 0.9269 acc@5 0.9982
[32m[2022-06-11 10:36:26] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 10:36:26] __main__ INFO: [0mTrain 155 60060
[32m[2022-06-11 10:36:30] __main__ INFO: [0mEpoch 155 Step 100/390 lr 0.001000 loss 0.0028 (0.0061) acc@1 1.0000 (0.9987) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:34] __main__ INFO: [0mEpoch 155 Step 200/390 lr 0.001000 loss 0.0175 (0.0060) acc@1 0.9922 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:38] __main__ INFO: [0mEpoch 155 Step 300/390 lr 0.001000 loss 0.0041 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:41] __main__ INFO: [0mEpoch 155 Step 390/390 lr 0.001000 loss 0.0038 (0.0059) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:42] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 10:36:42] __main__ INFO: [0mVal 155
[32m[2022-06-11 10:36:42] __main__ INFO: [0mEpoch 155 loss 0.3379 acc@1 0.9256 acc@5 0.9981
[32m[2022-06-11 10:36:42] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:36:42] __main__ INFO: [0mTrain 156 60450
[32m[2022-06-11 10:36:47] __main__ INFO: [0mEpoch 156 Step 100/390 lr 0.001000 loss 0.0027 (0.0050) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:50] __main__ INFO: [0mEpoch 156 Step 200/390 lr 0.001000 loss 0.0033 (0.0057) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:54] __main__ INFO: [0mEpoch 156 Step 300/390 lr 0.001000 loss 0.0081 (0.0059) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:58] __main__ INFO: [0mEpoch 156 Step 390/390 lr 0.001000 loss 0.0036 (0.0057) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:36:58] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 10:36:58] __main__ INFO: [0mVal 156
[32m[2022-06-11 10:36:59] __main__ INFO: [0mEpoch 156 loss 0.3391 acc@1 0.9267 acc@5 0.9980
[32m[2022-06-11 10:36:59] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:36:59] __main__ INFO: [0mTrain 157 60840
[32m[2022-06-11 10:37:03] __main__ INFO: [0mEpoch 157 Step 100/390 lr 0.001000 loss 0.0097 (0.0055) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:07] __main__ INFO: [0mEpoch 157 Step 200/390 lr 0.001000 loss 0.0103 (0.0053) acc@1 0.9922 (0.9994) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:11] __main__ INFO: [0mEpoch 157 Step 300/390 lr 0.001000 loss 0.0024 (0.0054) acc@1 1.0000 (0.9993) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:15] __main__ INFO: [0mEpoch 157 Step 390/390 lr 0.001000 loss 0.0007 (0.0054) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:15] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:37:15] __main__ INFO: [0mVal 157
[32m[2022-06-11 10:37:16] __main__ INFO: [0mEpoch 157 loss 0.3397 acc@1 0.9260 acc@5 0.9981
[32m[2022-06-11 10:37:16] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:37:16] __main__ INFO: [0mTrain 158 61230
[32m[2022-06-11 10:37:20] __main__ INFO: [0mEpoch 158 Step 100/390 lr 0.001000 loss 0.0058 (0.0058) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:24] __main__ INFO: [0mEpoch 158 Step 200/390 lr 0.001000 loss 0.0295 (0.0059) acc@1 0.9922 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:28] __main__ INFO: [0mEpoch 158 Step 300/390 lr 0.001000 loss 0.0022 (0.0059) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:31] __main__ INFO: [0mEpoch 158 Step 390/390 lr 0.001000 loss 0.0085 (0.0061) acc@1 1.0000 (0.9988) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:31] __main__ INFO: [0mElapsed 15.76
[32m[2022-06-11 10:37:31] __main__ INFO: [0mVal 158
[32m[2022-06-11 10:37:32] __main__ INFO: [0mEpoch 158 loss 0.3394 acc@1 0.9261 acc@5 0.9982
[32m[2022-06-11 10:37:32] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:37:32] __main__ INFO: [0mTrain 159 61620
[32m[2022-06-11 10:37:37] __main__ INFO: [0mEpoch 159 Step 100/390 lr 0.001000 loss 0.0038 (0.0056) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:41] __main__ INFO: [0mEpoch 159 Step 200/390 lr 0.001000 loss 0.0041 (0.0055) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:45] __main__ INFO: [0mEpoch 159 Step 300/390 lr 0.001000 loss 0.0081 (0.0055) acc@1 0.9922 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:48] __main__ INFO: [0mEpoch 159 Step 390/390 lr 0.001000 loss 0.0014 (0.0055) acc@1 1.0000 (0.9989) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:48] __main__ INFO: [0mElapsed 15.96
[32m[2022-06-11 10:37:48] __main__ INFO: [0mVal 159
[32m[2022-06-11 10:37:49] __main__ INFO: [0mEpoch 159 loss 0.3392 acc@1 0.9253 acc@5 0.9982
[32m[2022-06-11 10:37:49] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:37:49] __main__ INFO: [0mTrain 160 62010
[32m[2022-06-11 10:37:54] __main__ INFO: [0mEpoch 160 Step 100/390 lr 0.001000 loss 0.0034 (0.0054) acc@1 1.0000 (0.9991) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:37:58] __main__ INFO: [0mEpoch 160 Step 200/390 lr 0.001000 loss 0.0026 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:02] __main__ INFO: [0mEpoch 160 Step 300/390 lr 0.001000 loss 0.0014 (0.0051) acc@1 1.0000 (0.9992) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:05] __main__ INFO: [0mEpoch 160 Step 390/390 lr 0.001000 loss 0.0021 (0.0053) acc@1 1.0000 (0.9990) acc@5 1.0000 (1.0000)
[32m[2022-06-11 10:38:05] __main__ INFO: [0mElapsed 16.19
[32m[2022-06-11 10:38:05] __main__ INFO: [0mVal 160
[32m[2022-06-11 10:38:07] __main__ INFO: [0mEpoch 160 loss 0.3397 acc@1 0.9269 acc@5 0.9983
[32m[2022-06-11 10:38:07] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:38:07] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00160.pth
[32m[2022-06-11 10:40:57] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:40:57] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:41:01] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:41:01] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:41:01] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:41:02] __main__ INFO: [0mEpoch 0 loss 16761.8818 acc@1 0.1000 acc@5 0.5000
[32m[2022-06-11 10:41:02] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:41:02] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:41:06] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 2.0921 (3.0445) acc@1 0.2266 (0.1339) acc@5 0.7344 (0.5749)
[32m[2022-06-11 10:41:10] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 1.9818 (2.5336) acc@1 0.2109 (0.1777) acc@5 0.7891 (0.6750)
[32m[2022-06-11 10:41:14] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 1.8391 (2.3184) acc@1 0.3594 (0.2121) acc@5 0.8359 (0.7251)
[32m[2022-06-11 10:41:18] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 1.7720 (2.2011) acc@1 0.3672 (0.2393) acc@5 0.8984 (0.7548)
[32m[2022-06-11 10:41:18] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:41:18] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:41:19] __main__ INFO: [0mEpoch 1 loss 1.7234 acc@1 0.3559 acc@5 0.8697
[32m[2022-06-11 10:41:19] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:41:19] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:41:39] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:41:39] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:41:43] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:41:43] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:41:56] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:41:56] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:42:00] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:42:00] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:42:00] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:42:01] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 10:42:01] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 10:42:01] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:42:05] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6691 (1.1213) acc@1 0.8047 (0.6034) acc@5 0.9844 (0.9481)
[32m[2022-06-11 10:42:09] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7345 (0.9261) acc@1 0.7266 (0.6763) acc@5 0.9766 (0.9654)
[32m[2022-06-11 10:42:13] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6907 (0.8324) acc@1 0.7344 (0.7102) acc@5 1.0000 (0.9728)
[32m[2022-06-11 10:42:17] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5141 (0.7787) acc@1 0.8203 (0.7294) acc@5 0.9922 (0.9766)
[32m[2022-06-11 10:42:17] __main__ INFO: [0mElapsed 15.89
[32m[2022-06-11 10:42:17] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:42:18] __main__ INFO: [0mEpoch 1 loss 0.9312 acc@1 0.7042 acc@5 0.9808
[32m[2022-06-11 10:42:18] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:42:18] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:42:22] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.5724 (0.5403) acc@1 0.7891 (0.8145) acc@5 0.9844 (0.9914)
[32m[2022-06-11 10:42:26] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4236 (0.5283) acc@1 0.8359 (0.8182) acc@5 0.9922 (0.9916)
[32m[2022-06-11 10:42:30] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3453 (0.5233) acc@1 0.9062 (0.8201) acc@5 1.0000 (0.9918)
[32m[2022-06-11 10:42:33] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4180 (0.5189) acc@1 0.8438 (0.8216) acc@5 1.0000 (0.9917)
[32m[2022-06-11 10:42:33] __main__ INFO: [0mElapsed 15.38
[32m[2022-06-11 10:42:33] __main__ INFO: [0mVal 2
[32m[2022-06-11 10:42:34] __main__ INFO: [0mEpoch 2 loss 0.6407 acc@1 0.7932 acc@5 0.9863
[32m[2022-06-11 10:42:34] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:42:34] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 10:42:38] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4105 (0.4575) acc@1 0.8438 (0.8416) acc@5 0.9922 (0.9945)
[32m[2022-06-11 10:42:43] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4895 (0.4595) acc@1 0.8438 (0.8409) acc@5 1.0000 (0.9937)
[32m[2022-06-11 10:42:46] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6639 (0.4528) acc@1 0.7578 (0.8445) acc@5 0.9844 (0.9935)
[32m[2022-06-11 10:42:50] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5132 (0.4524) acc@1 0.8047 (0.8439) acc@5 0.9922 (0.9934)
[32m[2022-06-11 10:42:50] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 10:42:50] __main__ INFO: [0mVal 3
[32m[2022-06-11 10:42:51] __main__ INFO: [0mEpoch 3 loss 0.6262 acc@1 0.7988 acc@5 0.9880
[32m[2022-06-11 10:42:51] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:42:51] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 10:42:55] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4061 (0.4096) acc@1 0.8516 (0.8577) acc@5 1.0000 (0.9963)
[32m[2022-06-11 10:42:59] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4589 (0.4128) acc@1 0.8750 (0.8575) acc@5 0.9922 (0.9953)
[32m[2022-06-11 10:43:03] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.5466 (0.4142) acc@1 0.8359 (0.8571) acc@5 0.9922 (0.9949)
[32m[2022-06-11 10:43:07] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3279 (0.4123) acc@1 0.8906 (0.8575) acc@5 0.9922 (0.9947)
[32m[2022-06-11 10:43:07] __main__ INFO: [0mElapsed 15.88
[32m[2022-06-11 10:43:07] __main__ INFO: [0mVal 4
[32m[2022-06-11 10:43:08] __main__ INFO: [0mEpoch 4 loss 0.6014 acc@1 0.8002 acc@5 0.9893
[32m[2022-06-11 10:43:08] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:43:08] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 10:43:12] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4272 (0.3719) acc@1 0.8750 (0.8752) acc@5 0.9922 (0.9950)
[32m[2022-06-11 10:43:16] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3475 (0.3740) acc@1 0.8750 (0.8723) acc@5 0.9922 (0.9954)
[32m[2022-06-11 10:43:20] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2680 (0.3766) acc@1 0.9141 (0.8716) acc@5 0.9922 (0.9949)
[32m[2022-06-11 10:43:24] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3758 (0.3763) acc@1 0.8906 (0.8713) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:43:24] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:43:24] __main__ INFO: [0mVal 5
[32m[2022-06-11 10:43:25] __main__ INFO: [0mEpoch 5 loss 0.5451 acc@1 0.8250 acc@5 0.9886
[32m[2022-06-11 10:43:25] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:43:25] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 10:43:29] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4855 (0.3594) acc@1 0.8516 (0.8762) acc@5 1.0000 (0.9962)
[32m[2022-06-11 10:43:33] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2561 (0.3590) acc@1 0.9062 (0.8753) acc@5 1.0000 (0.9959)
[32m[2022-06-11 10:43:37] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3281 (0.3557) acc@1 0.8750 (0.8768) acc@5 0.9922 (0.9957)
[32m[2022-06-11 10:43:40] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3798 (0.3583) acc@1 0.8828 (0.8751) acc@5 1.0000 (0.9957)
[32m[2022-06-11 10:43:40] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 10:43:40] __main__ INFO: [0mVal 6
[32m[2022-06-11 10:43:41] __main__ INFO: [0mEpoch 6 loss 0.4687 acc@1 0.8438 acc@5 0.9932
[32m[2022-06-11 10:43:41] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:43:41] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 10:43:45] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4040 (0.3372) acc@1 0.8516 (0.8834) acc@5 1.0000 (0.9959)
[32m[2022-06-11 10:43:49] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2708 (0.3400) acc@1 0.9141 (0.8826) acc@5 0.9922 (0.9959)
[32m[2022-06-11 10:56:27] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 10:56:27] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 10:56:31] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 10:56:31] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 10:56:31] __main__ INFO: [0mVal 0
[32m[2022-06-11 10:56:32] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 10:56:32] __main__ INFO: [0mElapsed 1.01
[32m[2022-06-11 10:56:32] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 10:56:36] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6951 (1.1207) acc@1 0.7891 (0.6041) acc@5 0.9922 (0.9481)
[32m[2022-06-11 10:56:40] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6980 (0.9291) acc@1 0.7578 (0.6738) acc@5 0.9922 (0.9647)
[32m[2022-06-11 10:56:44] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6337 (0.8341) acc@1 0.7734 (0.7078) acc@5 1.0000 (0.9726)
[32m[2022-06-11 10:56:47] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5439 (0.7788) acc@1 0.8359 (0.7276) acc@5 1.0000 (0.9764)
[32m[2022-06-11 10:56:47] __main__ INFO: [0mElapsed 15.91
[32m[2022-06-11 10:56:47] __main__ INFO: [0mVal 1
[32m[2022-06-11 10:56:48] __main__ INFO: [0mEpoch 1 loss 0.8453 acc@1 0.7230 acc@5 0.9805
[32m[2022-06-11 10:56:48] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 10:56:48] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 10:56:53] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6121 (0.5395) acc@1 0.7969 (0.8155) acc@5 0.9844 (0.9912)
[32m[2022-06-11 10:56:57] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4845 (0.5274) acc@1 0.8438 (0.8182) acc@5 0.9922 (0.9912)
[32m[2022-06-11 10:57:01] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3920 (0.5210) acc@1 0.8828 (0.8208) acc@5 0.9922 (0.9913)
[32m[2022-06-11 10:57:04] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.3620 (0.5155) acc@1 0.8672 (0.8228) acc@5 1.0000 (0.9915)
[32m[2022-06-11 10:57:04] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 10:57:04] __main__ INFO: [0mVal 2
[32m[2022-06-11 10:57:05] __main__ INFO: [0mEpoch 2 loss 0.6125 acc@1 0.8026 acc@5 0.9878
[32m[2022-06-11 10:57:05] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 10:57:05] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 10:57:09] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4144 (0.4560) acc@1 0.8594 (0.8421) acc@5 0.9844 (0.9934)
[32m[2022-06-11 10:57:13] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5340 (0.4564) acc@1 0.8438 (0.8409) acc@5 0.9922 (0.9931)
[32m[2022-06-11 10:57:17] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5588 (0.4509) acc@1 0.7812 (0.8440) acc@5 0.9766 (0.9932)
[32m[2022-06-11 10:57:21] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.5174 (0.4521) acc@1 0.7812 (0.8432) acc@5 0.9922 (0.9932)
[32m[2022-06-11 10:57:21] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 10:57:21] __main__ INFO: [0mVal 3
[32m[2022-06-11 10:57:22] __main__ INFO: [0mEpoch 3 loss 0.6062 acc@1 0.8054 acc@5 0.9853
[32m[2022-06-11 10:57:22] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:57:22] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 10:57:26] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4386 (0.4043) acc@1 0.8672 (0.8594) acc@5 0.9844 (0.9952)
[32m[2022-06-11 10:57:30] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4525 (0.4087) acc@1 0.8359 (0.8574) acc@5 1.0000 (0.9950)
[32m[2022-06-11 10:57:34] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4729 (0.4107) acc@1 0.8516 (0.8561) acc@5 0.9922 (0.9946)
[32m[2022-06-11 10:57:37] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.2988 (0.4105) acc@1 0.8984 (0.8572) acc@5 1.0000 (0.9946)
[32m[2022-06-11 10:57:37] __main__ INFO: [0mElapsed 15.48
[32m[2022-06-11 10:57:37] __main__ INFO: [0mVal 4
[32m[2022-06-11 10:57:38] __main__ INFO: [0mEpoch 4 loss 0.5357 acc@1 0.8176 acc@5 0.9896
[32m[2022-06-11 10:57:38] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:57:38] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 10:57:42] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3871 (0.3745) acc@1 0.8906 (0.8741) acc@5 0.9922 (0.9955)
[32m[2022-06-11 10:57:46] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2828 (0.3717) acc@1 0.9297 (0.8736) acc@5 0.9922 (0.9952)
[32m[2022-06-11 10:57:50] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2867 (0.3730) acc@1 0.9062 (0.8727) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:57:54] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3977 (0.3736) acc@1 0.8750 (0.8719) acc@5 0.9922 (0.9951)
[32m[2022-06-11 10:57:54] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 10:57:54] __main__ INFO: [0mVal 5
[32m[2022-06-11 10:57:55] __main__ INFO: [0mEpoch 5 loss 0.6330 acc@1 0.7968 acc@5 0.9832
[32m[2022-06-11 10:57:55] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 10:57:55] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 10:57:59] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4442 (0.3665) acc@1 0.8359 (0.8715) acc@5 1.0000 (0.9958)
[32m[2022-06-11 10:58:03] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2820 (0.3629) acc@1 0.8828 (0.8736) acc@5 1.0000 (0.9957)
[32m[2022-06-11 10:58:07] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2700 (0.3601) acc@1 0.8906 (0.8750) acc@5 0.9922 (0.9953)
[32m[2022-06-11 10:58:10] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3269 (0.3596) acc@1 0.8984 (0.8749) acc@5 0.9922 (0.9954)
[32m[2022-06-11 10:58:11] __main__ INFO: [0mElapsed 15.64
[32m[2022-06-11 10:58:11] __main__ INFO: [0mVal 6
[32m[2022-06-11 10:58:12] __main__ INFO: [0mEpoch 6 loss 0.5733 acc@1 0.8152 acc@5 0.9924
[32m[2022-06-11 10:58:12] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 10:58:12] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 10:58:16] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4802 (0.3335) acc@1 0.8281 (0.8825) acc@5 0.9922 (0.9968)
[32m[2022-06-11 10:58:19] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2045 (0.3386) acc@1 0.9531 (0.8829) acc@5 0.9922 (0.9961)
[32m[2022-06-11 10:58:23] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4583 (0.3393) acc@1 0.8438 (0.8824) acc@5 1.0000 (0.9961)
[32m[2022-06-11 10:58:27] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2662 (0.3389) acc@1 0.9219 (0.8823) acc@5 0.9922 (0.9962)
[32m[2022-06-11 10:58:27] __main__ INFO: [0mElapsed 15.52
[32m[2022-06-11 10:58:27] __main__ INFO: [0mVal 7
[32m[2022-06-11 10:58:28] __main__ INFO: [0mEpoch 7 loss 0.5119 acc@1 0.8397 acc@5 0.9914
[32m[2022-06-11 10:58:28] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 10:58:28] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 10:58:32] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4452 (0.3094) acc@1 0.8281 (0.8938) acc@5 0.9922 (0.9968)
[32m[2022-06-11 10:58:36] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.2973 (0.3230) acc@1 0.8984 (0.8889) acc@5 1.0000 (0.9962)
[32m[2022-06-11 10:58:40] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3904 (0.3244) acc@1 0.8750 (0.8890) acc@5 0.9922 (0.9961)
[32m[2022-06-11 10:58:43] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3229 (0.3242) acc@1 0.9062 (0.8897) acc@5 0.9844 (0.9964)
[32m[2022-06-11 10:58:44] __main__ INFO: [0mElapsed 15.54
[32m[2022-06-11 10:58:44] __main__ INFO: [0mVal 8
[32m[2022-06-11 10:58:45] __main__ INFO: [0mEpoch 8 loss 0.4766 acc@1 0.8468 acc@5 0.9921
[32m[2022-06-11 10:58:45] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 10:58:45] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 10:58:49] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4175 (0.3099) acc@1 0.8828 (0.8935) acc@5 0.9844 (0.9970)
[32m[2022-06-11 10:58:53] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2971 (0.3112) acc@1 0.9141 (0.8927) acc@5 1.0000 (0.9972)
[32m[2022-06-11 10:58:57] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3992 (0.3152) acc@1 0.8672 (0.8915) acc@5 1.0000 (0.9968)
[32m[2022-06-11 10:59:00] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2723 (0.3143) acc@1 0.9141 (0.8917) acc@5 1.0000 (0.9968)
[32m[2022-06-11 10:59:00] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 10:59:00] __main__ INFO: [0mVal 9
[32m[2022-06-11 10:59:01] __main__ INFO: [0mEpoch 9 loss 0.4917 acc@1 0.8401 acc@5 0.9942
[32m[2022-06-11 10:59:01] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 10:59:01] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 10:59:05] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3100 (0.2918) acc@1 0.8750 (0.8984) acc@5 1.0000 (0.9975)
[32m[2022-06-11 10:59:09] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3057 (0.2993) acc@1 0.8984 (0.8969) acc@5 1.0000 (0.9969)
[32m[2022-06-11 10:59:13] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2057 (0.2991) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9973)
[32m[2022-06-11 10:59:17] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2768 (0.3041) acc@1 0.9062 (0.8941) acc@5 1.0000 (0.9972)
[32m[2022-06-11 10:59:17] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 10:59:17] __main__ INFO: [0mVal 10
[32m[2022-06-11 10:59:18] __main__ INFO: [0mEpoch 10 loss 0.6311 acc@1 0.8086 acc@5 0.9872
[32m[2022-06-11 10:59:18] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 10:59:18] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:07:48] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:07:48] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:07:52] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:07:52] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:07:52] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:07:53] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:07:53] __main__ INFO: [0mElapsed 1.05
[32m[2022-06-11 11:07:53] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:07:57] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6641 (1.1200) acc@1 0.7969 (0.6042) acc@5 0.9922 (0.9484)
[32m[2022-06-11 11:08:01] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7145 (0.9269) acc@1 0.7656 (0.6759) acc@5 0.9922 (0.9649)
[32m[2022-06-11 11:08:05] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6042 (0.8352) acc@1 0.7266 (0.7097) acc@5 1.0000 (0.9723)
[32m[2022-06-11 11:08:09] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5422 (0.7822) acc@1 0.8125 (0.7281) acc@5 1.0000 (0.9762)
[32m[2022-06-11 11:08:09] __main__ INFO: [0mElapsed 16.07
[32m[2022-06-11 11:08:09] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:08:10] __main__ INFO: [0mEpoch 1 loss 0.7418 acc@1 0.7514 acc@5 0.9830
[32m[2022-06-11 11:08:10] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:08:10] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:08:14] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.7173 (0.5433) acc@1 0.7422 (0.8114) acc@5 0.9922 (0.9912)
[32m[2022-06-11 11:08:18] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4550 (0.5308) acc@1 0.8594 (0.8161) acc@5 0.9922 (0.9907)
[32m[2022-06-11 11:08:22] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3489 (0.5249) acc@1 0.9062 (0.8193) acc@5 0.9922 (0.9913)
[32m[2022-06-11 11:08:25] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4092 (0.5187) acc@1 0.8203 (0.8216) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:08:26] __main__ INFO: [0mElapsed 15.71
[32m[2022-06-11 11:08:26] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:08:27] __main__ INFO: [0mEpoch 2 loss 0.7899 acc@1 0.7582 acc@5 0.9773
[32m[2022-06-11 11:08:27] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:08:27] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:08:31] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.3938 (0.4555) acc@1 0.8594 (0.8454) acc@5 0.9922 (0.9943)
[32m[2022-06-11 11:08:35] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4942 (0.4565) acc@1 0.8281 (0.8434) acc@5 0.9922 (0.9936)
[32m[2022-06-11 11:08:39] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6109 (0.4499) acc@1 0.7578 (0.8452) acc@5 0.9844 (0.9939)
[32m[2022-06-11 11:08:42] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4959 (0.4518) acc@1 0.8281 (0.8447) acc@5 1.0000 (0.9939)
[32m[2022-06-11 11:08:42] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 11:08:42] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:08:43] __main__ INFO: [0mEpoch 3 loss 0.6889 acc@1 0.7752 acc@5 0.9861
[32m[2022-06-11 11:08:43] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:08:43] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:08:48] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4060 (0.4074) acc@1 0.8750 (0.8597) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:08:52] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4291 (0.4097) acc@1 0.8516 (0.8597) acc@5 1.0000 (0.9946)
[32m[2022-06-11 11:08:55] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4992 (0.4119) acc@1 0.8438 (0.8579) acc@5 0.9922 (0.9945)
[32m[2022-06-11 11:08:59] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3074 (0.4104) acc@1 0.8984 (0.8586) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:08:59] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 11:08:59] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:09:00] __main__ INFO: [0mEpoch 4 loss 0.5217 acc@1 0.8262 acc@5 0.9915
[32m[2022-06-11 11:09:00] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:09:00] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:09:04] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4267 (0.3737) acc@1 0.8828 (0.8723) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:09:08] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2756 (0.3737) acc@1 0.9375 (0.8712) acc@5 0.9922 (0.9953)
[32m[2022-06-11 11:09:12] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2928 (0.3770) acc@1 0.8828 (0.8699) acc@5 0.9922 (0.9952)
[32m[2022-06-11 11:09:16] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4317 (0.3776) acc@1 0.8516 (0.8698) acc@5 0.9922 (0.9949)
[32m[2022-06-11 11:09:16] __main__ INFO: [0mElapsed 15.63
[32m[2022-06-11 11:09:16] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:09:17] __main__ INFO: [0mEpoch 5 loss 0.5635 acc@1 0.8131 acc@5 0.9898
[32m[2022-06-11 11:09:17] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:09:17] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:09:21] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4078 (0.3572) acc@1 0.8281 (0.8753) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:09:25] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2983 (0.3572) acc@1 0.8516 (0.8752) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:09:29] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3187 (0.3543) acc@1 0.8672 (0.8772) acc@5 1.0000 (0.9963)
[32m[2022-06-11 11:09:32] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3353 (0.3550) acc@1 0.8828 (0.8765) acc@5 0.9922 (0.9961)
[32m[2022-06-11 11:09:32] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:09:32] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:09:33] __main__ INFO: [0mEpoch 6 loss 0.5299 acc@1 0.8240 acc@5 0.9914
[32m[2022-06-11 11:09:33] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:09:33] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:09:38] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4683 (0.3395) acc@1 0.8125 (0.8820) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:09:42] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2793 (0.3389) acc@1 0.9141 (0.8820) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:09:46] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4390 (0.3415) acc@1 0.8672 (0.8807) acc@5 0.9922 (0.9961)
[32m[2022-06-11 11:09:49] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2575 (0.3419) acc@1 0.9062 (0.8807) acc@5 1.0000 (0.9961)
[32m[2022-06-11 11:09:49] __main__ INFO: [0mElapsed 15.94
[32m[2022-06-11 11:09:49] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:09:50] __main__ INFO: [0mEpoch 7 loss 0.5152 acc@1 0.8341 acc@5 0.9914
[32m[2022-06-11 11:09:50] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:09:50] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:09:54] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4600 (0.3088) acc@1 0.8203 (0.8924) acc@5 0.9844 (0.9974)
[32m[2022-06-11 11:09:58] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3304 (0.3197) acc@1 0.8672 (0.8892) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:10:02] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3306 (0.3223) acc@1 0.8672 (0.8882) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:10:06] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3190 (0.3219) acc@1 0.8984 (0.8885) acc@5 0.9844 (0.9968)
[32m[2022-06-11 11:10:06] __main__ INFO: [0mElapsed 15.66
[32m[2022-06-11 11:10:06] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:10:07] __main__ INFO: [0mEpoch 8 loss 0.4809 acc@1 0.8474 acc@5 0.9927
[32m[2022-06-11 11:10:07] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:10:07] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:10:11] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3982 (0.3073) acc@1 0.8672 (0.8923) acc@5 0.9922 (0.9978)
[32m[2022-06-11 11:10:15] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2549 (0.3071) acc@1 0.9375 (0.8917) acc@5 1.0000 (0.9977)
[32m[2022-06-11 11:10:19] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3600 (0.3092) acc@1 0.8828 (0.8909) acc@5 0.9844 (0.9973)
[32m[2022-06-11 11:10:22] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2504 (0.3076) acc@1 0.9453 (0.8920) acc@5 0.9922 (0.9971)
[32m[2022-06-11 11:10:22] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 11:10:22] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:10:23] __main__ INFO: [0mEpoch 9 loss 0.4815 acc@1 0.8467 acc@5 0.9951
[32m[2022-06-11 11:10:23] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:10:23] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:10:28] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3211 (0.2920) acc@1 0.8750 (0.8979) acc@5 1.0000 (0.9975)
[32m[2022-06-11 11:10:31] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3215 (0.2973) acc@1 0.8906 (0.8980) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:10:35] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1521 (0.2968) acc@1 0.9609 (0.8976) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:10:39] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2432 (0.3031) acc@1 0.9062 (0.8956) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:10:39] __main__ INFO: [0mElapsed 15.83
[32m[2022-06-11 11:10:39] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:10:40] __main__ INFO: [0mEpoch 10 loss 0.4984 acc@1 0.8449 acc@5 0.9928
[32m[2022-06-11 11:10:40] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:10:40] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:11:08] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:11:08] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:11:12] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:11:12] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:11:12] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:11:13] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:11:13] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:11:13] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:11:17] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6881 (1.1215) acc@1 0.7891 (0.6053) acc@5 1.0000 (0.9480)
[32m[2022-06-11 11:11:21] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6868 (0.9272) acc@1 0.7422 (0.6771) acc@5 0.9922 (0.9648)
[32m[2022-06-11 11:11:25] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6476 (0.8340) acc@1 0.7344 (0.7090) acc@5 1.0000 (0.9721)
[32m[2022-06-11 11:11:29] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5383 (0.7801) acc@1 0.8203 (0.7280) acc@5 0.9922 (0.9762)
[32m[2022-06-11 11:11:29] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 11:11:29] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:11:30] __main__ INFO: [0mEpoch 1 loss 0.8620 acc@1 0.7167 acc@5 0.9823
[32m[2022-06-11 11:11:30] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:11:30] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:11:34] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6999 (0.5464) acc@1 0.7656 (0.8143) acc@5 0.9844 (0.9912)
[32m[2022-06-11 11:11:38] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.5270 (0.5310) acc@1 0.8281 (0.8179) acc@5 0.9922 (0.9910)
[32m[2022-06-11 11:11:42] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3923 (0.5229) acc@1 0.8906 (0.8205) acc@5 1.0000 (0.9913)
[32m[2022-06-11 11:11:45] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4069 (0.5205) acc@1 0.8359 (0.8212) acc@5 1.0000 (0.9913)
[32m[2022-06-11 11:11:46] __main__ INFO: [0mElapsed 15.89
[32m[2022-06-11 11:11:46] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:11:46] __main__ INFO: [0mEpoch 2 loss 0.7687 acc@1 0.7622 acc@5 0.9843
[32m[2022-06-11 11:11:46] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:11:46] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:11:51] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4542 (0.4567) acc@1 0.8438 (0.8429) acc@5 0.9844 (0.9937)
[32m[2022-06-11 11:11:55] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5747 (0.4598) acc@1 0.7891 (0.8427) acc@5 0.9922 (0.9930)
[32m[2022-06-11 11:11:58] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5849 (0.4531) acc@1 0.7734 (0.8438) acc@5 0.9922 (0.9933)
[32m[2022-06-11 11:12:02] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4755 (0.4548) acc@1 0.8203 (0.8441) acc@5 1.0000 (0.9930)
[32m[2022-06-11 11:12:02] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:12:02] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:12:03] __main__ INFO: [0mEpoch 3 loss 0.5518 acc@1 0.8180 acc@5 0.9890
[32m[2022-06-11 11:12:03] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:12:03] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:12:07] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3491 (0.4053) acc@1 0.9141 (0.8606) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:12:11] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4388 (0.4076) acc@1 0.8672 (0.8606) acc@5 1.0000 (0.9954)
[32m[2022-06-11 11:12:15] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4700 (0.4125) acc@1 0.8672 (0.8586) acc@5 0.9922 (0.9949)
[32m[2022-06-11 11:12:19] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3007 (0.4121) acc@1 0.8984 (0.8575) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:12:19] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 11:12:19] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:12:20] __main__ INFO: [0mEpoch 4 loss 0.6579 acc@1 0.7870 acc@5 0.9881
[32m[2022-06-11 11:12:20] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:12:20] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:12:24] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3672 (0.3731) acc@1 0.8828 (0.8707) acc@5 1.0000 (0.9949)
[32m[2022-06-11 11:12:28] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3230 (0.3762) acc@1 0.8984 (0.8693) acc@5 0.9922 (0.9952)
[32m[2022-06-11 11:12:32] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2219 (0.3773) acc@1 0.9453 (0.8705) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:12:35] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3911 (0.3806) acc@1 0.8984 (0.8685) acc@5 0.9844 (0.9951)
[32m[2022-06-11 11:12:36] __main__ INFO: [0mElapsed 15.59
[32m[2022-06-11 11:12:36] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:12:36] __main__ INFO: [0mEpoch 5 loss 0.6748 acc@1 0.7864 acc@5 0.9885
[32m[2022-06-11 11:12:36] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:12:36] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:12:41] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4149 (0.3637) acc@1 0.8750 (0.8734) acc@5 1.0000 (0.9965)
[32m[2022-06-11 11:12:45] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2633 (0.3619) acc@1 0.9297 (0.8749) acc@5 1.0000 (0.9963)
[32m[2022-06-11 11:12:49] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3190 (0.3587) acc@1 0.8750 (0.8758) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:12:52] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.2982 (0.3598) acc@1 0.8828 (0.8750) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:12:52] __main__ INFO: [0mElapsed 15.81
[32m[2022-06-11 11:12:52] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:12:53] __main__ INFO: [0mEpoch 6 loss 0.4413 acc@1 0.8534 acc@5 0.9935
[32m[2022-06-11 11:12:53] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:12:53] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:12:58] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4156 (0.3303) acc@1 0.8594 (0.8850) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:13:02] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2663 (0.3403) acc@1 0.9141 (0.8829) acc@5 0.9922 (0.9955)
[32m[2022-06-11 11:13:06] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3548 (0.3376) acc@1 0.8906 (0.8838) acc@5 1.0000 (0.9959)
[32m[2022-06-11 11:13:09] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2980 (0.3371) acc@1 0.8906 (0.8839) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:13:09] __main__ INFO: [0mElapsed 15.85
[32m[2022-06-11 11:13:09] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:13:10] __main__ INFO: [0mEpoch 7 loss 0.5129 acc@1 0.8314 acc@5 0.9914
[32m[2022-06-11 11:13:10] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:13:10] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:13:14] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4732 (0.3177) acc@1 0.8359 (0.8915) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:13:18] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3651 (0.3274) acc@1 0.8359 (0.8882) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:13:22] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3525 (0.3278) acc@1 0.8828 (0.8876) acc@5 0.9922 (0.9965)
[32m[2022-06-11 11:13:26] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3310 (0.3252) acc@1 0.8906 (0.8879) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:13:26] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 11:13:26] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:13:27] __main__ INFO: [0mEpoch 8 loss 0.4486 acc@1 0.8552 acc@5 0.9947
[32m[2022-06-11 11:13:27] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:13:27] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:13:31] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3911 (0.3088) acc@1 0.8672 (0.8948) acc@5 0.9844 (0.9970)
[32m[2022-06-11 11:13:35] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2668 (0.3079) acc@1 0.9062 (0.8941) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:13:39] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3345 (0.3118) acc@1 0.8984 (0.8935) acc@5 0.9922 (0.9967)
[32m[2022-06-11 11:13:43] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2954 (0.3126) acc@1 0.9297 (0.8929) acc@5 1.0000 (0.9965)
[32m[2022-06-11 11:13:43] __main__ INFO: [0mElapsed 16.03
[32m[2022-06-11 11:13:43] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:13:44] __main__ INFO: [0mEpoch 9 loss 0.4958 acc@1 0.8402 acc@5 0.9917
[32m[2022-06-11 11:13:44] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 11:13:44] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:13:48] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.2592 (0.2875) acc@1 0.9297 (0.9017) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:13:52] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3328 (0.2966) acc@1 0.8906 (0.8982) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:13:56] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1916 (0.2963) acc@1 0.9375 (0.8990) acc@5 1.0000 (0.9973)
[32m[2022-06-11 11:13:59] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2386 (0.3004) acc@1 0.8984 (0.8967) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:13:59] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:13:59] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:14:00] __main__ INFO: [0mEpoch 10 loss 0.4900 acc@1 0.8455 acc@5 0.9924
[32m[2022-06-11 11:14:00] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:14:00] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:27:26] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:27:26] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:27:30] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:27:30] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:27:30] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:27:31] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:27:31] __main__ INFO: [0mElapsed 1.05
[32m[2022-06-11 11:27:31] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:27:35] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6703 (1.1210) acc@1 0.8047 (0.6047) acc@5 0.9844 (0.9472)
[32m[2022-06-11 11:27:39] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7222 (0.9280) acc@1 0.7422 (0.6745) acc@5 0.9922 (0.9645)
[32m[2022-06-11 11:27:43] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6236 (0.8361) acc@1 0.7344 (0.7081) acc@5 1.0000 (0.9722)
[32m[2022-06-11 11:27:47] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5172 (0.7813) acc@1 0.8438 (0.7278) acc@5 0.9922 (0.9760)
[32m[2022-06-11 11:27:47] __main__ INFO: [0mElapsed 15.92
[32m[2022-06-11 11:27:47] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:27:48] __main__ INFO: [0mEpoch 1 loss 0.8147 acc@1 0.7362 acc@5 0.9789
[32m[2022-06-11 11:27:48] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:27:48] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:27:52] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6497 (0.5428) acc@1 0.7812 (0.8155) acc@5 0.9766 (0.9916)
[32m[2022-06-11 11:27:56] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4312 (0.5311) acc@1 0.8516 (0.8182) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:28:00] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3347 (0.5251) acc@1 0.8984 (0.8199) acc@5 0.9922 (0.9915)
[32m[2022-06-11 11:28:03] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4081 (0.5213) acc@1 0.8438 (0.8206) acc@5 1.0000 (0.9917)
[32m[2022-06-11 11:28:03] __main__ INFO: [0mElapsed 15.72
[32m[2022-06-11 11:28:03] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:28:04] __main__ INFO: [0mEpoch 2 loss 0.6768 acc@1 0.7845 acc@5 0.9879
[32m[2022-06-11 11:28:04] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:28:04] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:28:08] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4239 (0.4556) acc@1 0.8594 (0.8435) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:12] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4784 (0.4589) acc@1 0.8281 (0.8427) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:16] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.6112 (0.4546) acc@1 0.7891 (0.8441) acc@5 0.9844 (0.9933)
[32m[2022-06-11 11:28:20] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4878 (0.4547) acc@1 0.8359 (0.8434) acc@5 1.0000 (0.9933)
[32m[2022-06-11 11:28:20] __main__ INFO: [0mElapsed 15.48
[32m[2022-06-11 11:28:20] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:28:21] __main__ INFO: [0mEpoch 3 loss 0.6242 acc@1 0.8021 acc@5 0.9880
[32m[2022-06-11 11:28:21] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:28:21] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:28:25] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3409 (0.4014) acc@1 0.9141 (0.8616) acc@5 1.0000 (0.9958)
[32m[2022-06-11 11:28:29] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.3867 (0.4082) acc@1 0.8828 (0.8592) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:28:33] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4383 (0.4112) acc@1 0.8906 (0.8586) acc@5 0.9922 (0.9948)
[32m[2022-06-11 11:28:36] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3536 (0.4104) acc@1 0.8828 (0.8591) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:28:36] __main__ INFO: [0mElapsed 15.52
[32m[2022-06-11 11:28:36] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:28:37] __main__ INFO: [0mEpoch 4 loss 0.5941 acc@1 0.8077 acc@5 0.9905
[32m[2022-06-11 11:28:37] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:28:37] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:28:41] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3732 (0.3712) acc@1 0.8516 (0.8715) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:28:45] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.3087 (0.3722) acc@1 0.9062 (0.8719) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:28:49] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2765 (0.3759) acc@1 0.9219 (0.8697) acc@5 1.0000 (0.9958)
[32m[2022-06-11 11:28:53] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.4014 (0.3771) acc@1 0.8828 (0.8703) acc@5 0.9922 (0.9955)
[32m[2022-06-11 11:28:53] __main__ INFO: [0mElapsed 16.21
[32m[2022-06-11 11:28:53] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:28:54] __main__ INFO: [0mEpoch 5 loss 0.5608 acc@1 0.8170 acc@5 0.9902
[32m[2022-06-11 11:28:54] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:28:54] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:28:59] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4154 (0.3587) acc@1 0.8828 (0.8772) acc@5 0.9844 (0.9955)
[32m[2022-06-11 11:29:02] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2614 (0.3568) acc@1 0.8828 (0.8778) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:29:06] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3376 (0.3562) acc@1 0.8828 (0.8774) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:29:10] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3081 (0.3559) acc@1 0.8906 (0.8776) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:29:10] __main__ INFO: [0mElapsed 15.84
[32m[2022-06-11 11:29:10] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:29:11] __main__ INFO: [0mEpoch 6 loss 0.5310 acc@1 0.8204 acc@5 0.9908
[32m[2022-06-11 11:29:11] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:29:11] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:29:15] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4543 (0.3390) acc@1 0.8203 (0.8825) acc@5 1.0000 (0.9962)
[32m[2022-06-11 11:29:19] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2390 (0.3413) acc@1 0.9219 (0.8832) acc@5 0.9922 (0.9962)
[32m[2022-06-11 11:29:23] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3725 (0.3419) acc@1 0.8750 (0.8827) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:27] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2497 (0.3394) acc@1 0.9219 (0.8829) acc@5 0.9922 (0.9963)
[32m[2022-06-11 11:29:27] __main__ INFO: [0mElapsed 15.82
[32m[2022-06-11 11:29:27] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:29:28] __main__ INFO: [0mEpoch 7 loss 0.5983 acc@1 0.8205 acc@5 0.9866
[32m[2022-06-11 11:29:28] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:29:28] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:29:32] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.5077 (0.3133) acc@1 0.8203 (0.8886) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:29:36] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3406 (0.3232) acc@1 0.8828 (0.8873) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:40] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.2572 (0.3243) acc@1 0.9219 (0.8881) acc@5 0.9922 (0.9964)
[32m[2022-06-11 11:29:44] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.3474 (0.3239) acc@1 0.9062 (0.8881) acc@5 0.9922 (0.9965)
[32m[2022-06-11 11:29:44] __main__ INFO: [0mElapsed 15.80
[32m[2022-06-11 11:29:44] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:29:45] __main__ INFO: [0mEpoch 8 loss 0.4387 acc@1 0.8590 acc@5 0.9939
[32m[2022-06-11 11:29:45] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:29:45] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:29:49] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4169 (0.3055) acc@1 0.8516 (0.8938) acc@5 0.9844 (0.9975)
[32m[2022-06-11 11:29:53] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2892 (0.3029) acc@1 0.9219 (0.8959) acc@5 1.0000 (0.9974)
[32m[2022-06-11 11:29:57] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4639 (0.3071) acc@1 0.8359 (0.8943) acc@5 0.9922 (0.9972)
[32m[2022-06-11 11:30:00] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2928 (0.3071) acc@1 0.9297 (0.8946) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:30:00] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 11:30:00] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:30:01] __main__ INFO: [0mEpoch 9 loss 0.5721 acc@1 0.8158 acc@5 0.9908
[32m[2022-06-11 11:30:01] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:30:01] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:30:05] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3427 (0.2947) acc@1 0.8906 (0.8985) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:30:09] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3172 (0.2975) acc@1 0.8828 (0.8981) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:30:13] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2174 (0.2962) acc@1 0.9375 (0.8975) acc@5 0.9922 (0.9971)
[32m[2022-06-11 11:30:17] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2691 (0.3025) acc@1 0.9062 (0.8953) acc@5 1.0000 (0.9971)
[32m[2022-06-11 11:30:17] __main__ INFO: [0mElapsed 15.39
[32m[2022-06-11 11:30:17] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:30:18] __main__ INFO: [0mEpoch 10 loss 0.5443 acc@1 0.8378 acc@5 0.9919
[32m[2022-06-11 11:30:18] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:30:18] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:32:53] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:32:53] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:14] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:33:14] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:18] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:33:18] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:33:18] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:33:19] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:33:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:33:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:33:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:33:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:33:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:33:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:33:34] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:33:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:33:39] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6751 (1.1220) acc@1 0.7812 (0.6027) acc@5 1.0000 (0.9478)
[32m[2022-06-11 11:33:43] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.7131 (0.9283) acc@1 0.7500 (0.6738) acc@5 0.9844 (0.9642)
[32m[2022-06-11 11:33:46] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.6397 (0.8345) acc@1 0.7422 (0.7076) acc@5 1.0000 (0.9721)
[32m[2022-06-11 11:33:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5589 (0.7804) acc@1 0.8203 (0.7277) acc@5 0.9766 (0.9760)
[32m[2022-06-11 11:33:50] __main__ INFO: [0mElapsed 15.75
[32m[2022-06-11 11:33:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:33:51] __main__ INFO: [0mEpoch 1 loss 0.6942 acc@1 0.7607 acc@5 0.9840
[32m[2022-06-11 11:33:51] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:33:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:33:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6618 (0.5374) acc@1 0.7500 (0.8174) acc@5 0.9922 (0.9913)
[32m[2022-06-11 11:33:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.5240 (0.5284) acc@1 0.8203 (0.8186) acc@5 1.0000 (0.9910)
[32m[2022-06-11 11:34:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.3815 (0.5242) acc@1 0.8750 (0.8194) acc@5 0.9922 (0.9911)
[32m[2022-06-11 11:34:06] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4191 (0.5212) acc@1 0.8359 (0.8203) acc@5 1.0000 (0.9912)
[32m[2022-06-11 11:34:07] __main__ INFO: [0mElapsed 15.60
[32m[2022-06-11 11:34:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:34:07] __main__ INFO: [0mEpoch 2 loss 0.7611 acc@1 0.7603 acc@5 0.9845
[32m[2022-06-11 11:34:07] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:07] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:34:11] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4705 (0.4533) acc@1 0.8281 (0.8444) acc@5 0.9922 (0.9933)
[32m[2022-06-11 11:34:15] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.5197 (0.4571) acc@1 0.7969 (0.8413) acc@5 0.9922 (0.9930)
[32m[2022-06-11 11:34:19] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5835 (0.4506) acc@1 0.7969 (0.8434) acc@5 0.9922 (0.9934)
[32m[2022-06-11 11:34:23] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4464 (0.4526) acc@1 0.8281 (0.8429) acc@5 1.0000 (0.9932)
[32m[2022-06-11 11:34:23] __main__ INFO: [0mElapsed 15.44
[32m[2022-06-11 11:34:23] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:34:24] __main__ INFO: [0mEpoch 3 loss 0.5718 acc@1 0.8130 acc@5 0.9891
[32m[2022-06-11 11:34:24] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:24] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:34:28] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.4051 (0.4032) acc@1 0.8750 (0.8591) acc@5 0.9844 (0.9955)
[32m[2022-06-11 11:34:32] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4391 (0.4073) acc@1 0.8281 (0.8590) acc@5 1.0000 (0.9953)
[32m[2022-06-11 11:34:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4881 (0.4133) acc@1 0.8203 (0.8578) acc@5 0.9922 (0.9946)
[32m[2022-06-11 11:34:39] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3223 (0.4137) acc@1 0.8906 (0.8577) acc@5 1.0000 (0.9946)
[32m[2022-06-11 11:34:39] __main__ INFO: [0mElapsed 15.49
[32m[2022-06-11 11:34:39] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:34:40] __main__ INFO: [0mEpoch 4 loss 0.5389 acc@1 0.8208 acc@5 0.9917
[32m[2022-06-11 11:34:40] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:34:40] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:34:44] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.3861 (0.3711) acc@1 0.8594 (0.8691) acc@5 0.9922 (0.9951)
[32m[2022-06-11 11:34:48] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2983 (0.3729) acc@1 0.9062 (0.8700) acc@5 0.9844 (0.9956)
[32m[2022-06-11 11:34:52] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2727 (0.3737) acc@1 0.9062 (0.8699) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:34:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3270 (0.3734) acc@1 0.8984 (0.8701) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:34:56] __main__ INFO: [0mElapsed 15.50
[32m[2022-06-11 11:34:56] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:34:57] __main__ INFO: [0mEpoch 5 loss 0.5079 acc@1 0.8316 acc@5 0.9918
[32m[2022-06-11 11:34:57] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:34:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:35:01] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.4298 (0.3571) acc@1 0.8594 (0.8766) acc@5 0.9922 (0.9960)
[32m[2022-06-11 11:35:05] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2715 (0.3590) acc@1 0.9141 (0.8746) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:35:09] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.3308 (0.3558) acc@1 0.8594 (0.8752) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:35:12] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.4591 (0.3577) acc@1 0.8281 (0.8746) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:35:12] __main__ INFO: [0mElapsed 15.70
[32m[2022-06-11 11:35:12] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:35:13] __main__ INFO: [0mEpoch 6 loss 0.4822 acc@1 0.8396 acc@5 0.9937
[32m[2022-06-11 11:35:13] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:35:13] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:35:17] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.4135 (0.3379) acc@1 0.8594 (0.8837) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:35:21] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2655 (0.3424) acc@1 0.8984 (0.8819) acc@5 0.9922 (0.9958)
[32m[2022-06-11 11:35:25] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.3765 (0.3425) acc@1 0.8828 (0.8811) acc@5 0.9922 (0.9959)
[32m[2022-06-11 11:35:29] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2733 (0.3410) acc@1 0.8828 (0.8814) acc@5 1.0000 (0.9961)
[32m[2022-06-11 11:35:29] __main__ INFO: [0mElapsed 15.47
[32m[2022-06-11 11:35:29] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:35:30] __main__ INFO: [0mEpoch 7 loss 0.4863 acc@1 0.8432 acc@5 0.9916
[32m[2022-06-11 11:35:30] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:35:30] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:35:34] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.3991 (0.3068) acc@1 0.8125 (0.8939) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:35:38] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3476 (0.3234) acc@1 0.8984 (0.8891) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:35:42] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3212 (0.3239) acc@1 0.8906 (0.8890) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:35:45] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.2679 (0.3236) acc@1 0.9062 (0.8885) acc@5 0.9922 (0.9967)
[32m[2022-06-11 11:35:45] __main__ INFO: [0mElapsed 15.67
[32m[2022-06-11 11:35:45] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:35:46] __main__ INFO: [0mEpoch 8 loss 0.4820 acc@1 0.8479 acc@5 0.9936
[32m[2022-06-11 11:35:46] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:35:46] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:35:50] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.4427 (0.3077) acc@1 0.8828 (0.8927) acc@5 0.9844 (0.9970)
[32m[2022-06-11 11:35:54] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2354 (0.3048) acc@1 0.9609 (0.8939) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:35:58] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.3996 (0.3074) acc@1 0.8438 (0.8931) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:36:02] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.3134 (0.3090) acc@1 0.9062 (0.8928) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:36:02] __main__ INFO: [0mElapsed 15.58
[32m[2022-06-11 11:36:02] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:36:03] __main__ INFO: [0mEpoch 9 loss 0.4614 acc@1 0.8524 acc@5 0.9929
[32m[2022-06-11 11:36:03] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:36:03] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:36:07] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.2864 (0.2892) acc@1 0.8984 (0.8998) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:36:11] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3060 (0.3012) acc@1 0.8750 (0.8959) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:36:15] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.2197 (0.2992) acc@1 0.9062 (0.8962) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:36:19] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2509 (0.3031) acc@1 0.8984 (0.8944) acc@5 1.0000 (0.9968)
[32m[2022-06-11 11:36:19] __main__ INFO: [0mElapsed 15.77
[32m[2022-06-11 11:36:19] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:36:20] __main__ INFO: [0mEpoch 10 loss 0.7019 acc@1 0.8042 acc@5 0.9815
[32m[2022-06-11 11:36:20] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:36:20] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:37:40] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:37:40] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:37:44] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:37:44] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:37:44] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:37:45] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:39:29] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:39:29] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:39:33] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:39:33] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:39:33] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:39:34] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:39:34] __main__ INFO: [0mElapsed 0.96
[32m[2022-06-11 11:39:34] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:39:38] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 0.6560 (1.1208) acc@1 0.7969 (0.6029) acc@5 0.9922 (0.9484)
[32m[2022-06-11 11:39:42] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 0.6912 (0.9272) acc@1 0.7500 (0.6748) acc@5 0.9844 (0.9650)
[32m[2022-06-11 11:39:47] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 0.5721 (0.8329) acc@1 0.7969 (0.7089) acc@5 0.9922 (0.9728)
[32m[2022-06-11 11:39:50] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 0.5301 (0.7798) acc@1 0.8125 (0.7275) acc@5 0.9922 (0.9767)
[32m[2022-06-11 11:39:50] __main__ INFO: [0mElapsed 16.30
[32m[2022-06-11 11:39:50] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:39:51] __main__ INFO: [0mEpoch 1 loss 0.8266 acc@1 0.7217 acc@5 0.9845
[32m[2022-06-11 11:39:51] __main__ INFO: [0mElapsed 0.87
[32m[2022-06-11 11:39:51] __main__ INFO: [0mTrain 2 390
[32m[2022-06-11 11:39:55] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 0.6631 (0.5386) acc@1 0.7891 (0.8181) acc@5 0.9922 (0.9905)
[32m[2022-06-11 11:39:59] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 0.4213 (0.5260) acc@1 0.8516 (0.8202) acc@5 1.0000 (0.9910)
[32m[2022-06-11 11:40:03] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 0.4339 (0.5216) acc@1 0.8359 (0.8199) acc@5 0.9844 (0.9910)
[32m[2022-06-11 11:40:06] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 0.4238 (0.5171) acc@1 0.8594 (0.8215) acc@5 0.9922 (0.9908)
[32m[2022-06-11 11:40:07] __main__ INFO: [0mElapsed 15.49
[32m[2022-06-11 11:40:07] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:40:07] __main__ INFO: [0mEpoch 2 loss 0.7564 acc@1 0.7634 acc@5 0.9817
[32m[2022-06-11 11:40:07] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:40:07] __main__ INFO: [0mTrain 3 780
[32m[2022-06-11 11:40:12] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 0.4271 (0.4522) acc@1 0.8438 (0.8474) acc@5 0.9922 (0.9947)
[32m[2022-06-11 11:40:16] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 0.4912 (0.4587) acc@1 0.8281 (0.8420) acc@5 1.0000 (0.9938)
[32m[2022-06-11 11:40:19] __main__ INFO: [0mEpoch 3 Step 300/390 lr 0.100000 loss 0.5944 (0.4537) acc@1 0.7812 (0.8430) acc@5 0.9922 (0.9939)
[32m[2022-06-11 11:40:23] __main__ INFO: [0mEpoch 3 Step 390/390 lr 0.100000 loss 0.4324 (0.4562) acc@1 0.8516 (0.8425) acc@5 0.9922 (0.9937)
[32m[2022-06-11 11:40:23] __main__ INFO: [0mElapsed 15.68
[32m[2022-06-11 11:40:23] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:40:24] __main__ INFO: [0mEpoch 3 loss 0.5576 acc@1 0.8108 acc@5 0.9906
[32m[2022-06-11 11:40:24] __main__ INFO: [0mElapsed 0.92
[32m[2022-06-11 11:40:24] __main__ INFO: [0mTrain 4 1170
[32m[2022-06-11 11:40:28] __main__ INFO: [0mEpoch 4 Step 100/390 lr 0.100000 loss 0.3417 (0.4003) acc@1 0.8750 (0.8628) acc@5 1.0000 (0.9959)
[32m[2022-06-11 11:40:32] __main__ INFO: [0mEpoch 4 Step 200/390 lr 0.100000 loss 0.4416 (0.4058) acc@1 0.8359 (0.8599) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:40:36] __main__ INFO: [0mEpoch 4 Step 300/390 lr 0.100000 loss 0.4186 (0.4105) acc@1 0.8516 (0.8592) acc@5 1.0000 (0.9947)
[32m[2022-06-11 11:40:40] __main__ INFO: [0mEpoch 4 Step 390/390 lr 0.100000 loss 0.3404 (0.4104) acc@1 0.8672 (0.8595) acc@5 0.9922 (0.9945)
[32m[2022-06-11 11:40:40] __main__ INFO: [0mElapsed 15.61
[32m[2022-06-11 11:40:40] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:40:41] __main__ INFO: [0mEpoch 4 loss 0.6213 acc@1 0.8007 acc@5 0.9880
[32m[2022-06-11 11:40:41] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:40:41] __main__ INFO: [0mTrain 5 1560
[32m[2022-06-11 11:40:45] __main__ INFO: [0mEpoch 5 Step 100/390 lr 0.100000 loss 0.4079 (0.3747) acc@1 0.8359 (0.8704) acc@5 1.0000 (0.9960)
[32m[2022-06-11 11:40:49] __main__ INFO: [0mEpoch 5 Step 200/390 lr 0.100000 loss 0.2575 (0.3763) acc@1 0.9219 (0.8705) acc@5 0.9922 (0.9960)
[32m[2022-06-11 11:40:53] __main__ INFO: [0mEpoch 5 Step 300/390 lr 0.100000 loss 0.2716 (0.3793) acc@1 0.9219 (0.8702) acc@5 0.9922 (0.9957)
[32m[2022-06-11 11:40:56] __main__ INFO: [0mEpoch 5 Step 390/390 lr 0.100000 loss 0.3944 (0.3779) acc@1 0.8984 (0.8708) acc@5 0.9922 (0.9954)
[32m[2022-06-11 11:40:56] __main__ INFO: [0mElapsed 15.65
[32m[2022-06-11 11:40:56] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:40:57] __main__ INFO: [0mEpoch 5 loss 0.6340 acc@1 0.7983 acc@5 0.9882
[32m[2022-06-11 11:40:57] __main__ INFO: [0mElapsed 0.89
[32m[2022-06-11 11:40:57] __main__ INFO: [0mTrain 6 1950
[32m[2022-06-11 11:41:01] __main__ INFO: [0mEpoch 6 Step 100/390 lr 0.100000 loss 0.3681 (0.3611) acc@1 0.8984 (0.8734) acc@5 1.0000 (0.9956)
[32m[2022-06-11 11:41:05] __main__ INFO: [0mEpoch 6 Step 200/390 lr 0.100000 loss 0.2942 (0.3556) acc@1 0.8828 (0.8760) acc@5 1.0000 (0.9954)
[32m[2022-06-11 11:41:09] __main__ INFO: [0mEpoch 6 Step 300/390 lr 0.100000 loss 0.2841 (0.3535) acc@1 0.8828 (0.8767) acc@5 1.0000 (0.9957)
[32m[2022-06-11 11:41:13] __main__ INFO: [0mEpoch 6 Step 390/390 lr 0.100000 loss 0.3543 (0.3569) acc@1 0.8984 (0.8756) acc@5 1.0000 (0.9956)
[32m[2022-06-11 11:41:13] __main__ INFO: [0mElapsed 15.90
[32m[2022-06-11 11:41:13] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:41:14] __main__ INFO: [0mEpoch 6 loss 0.4887 acc@1 0.8397 acc@5 0.9926
[32m[2022-06-11 11:41:14] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:41:14] __main__ INFO: [0mTrain 7 2340
[32m[2022-06-11 11:41:18] __main__ INFO: [0mEpoch 7 Step 100/390 lr 0.100000 loss 0.3626 (0.3323) acc@1 0.8750 (0.8843) acc@5 0.9922 (0.9970)
[32m[2022-06-11 11:41:22] __main__ INFO: [0mEpoch 7 Step 200/390 lr 0.100000 loss 0.2886 (0.3423) acc@1 0.8906 (0.8816) acc@5 0.9922 (0.9966)
[32m[2022-06-11 11:41:26] __main__ INFO: [0mEpoch 7 Step 300/390 lr 0.100000 loss 0.4444 (0.3420) acc@1 0.8516 (0.8821) acc@5 0.9766 (0.9964)
[32m[2022-06-11 11:41:30] __main__ INFO: [0mEpoch 7 Step 390/390 lr 0.100000 loss 0.2477 (0.3417) acc@1 0.9141 (0.8825) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:41:30] __main__ INFO: [0mElapsed 15.95
[32m[2022-06-11 11:41:30] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:41:31] __main__ INFO: [0mEpoch 7 loss 0.5324 acc@1 0.8294 acc@5 0.9917
[32m[2022-06-11 11:41:31] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:41:31] __main__ INFO: [0mTrain 8 2730
[32m[2022-06-11 11:41:35] __main__ INFO: [0mEpoch 8 Step 100/390 lr 0.100000 loss 0.4255 (0.3164) acc@1 0.8672 (0.8939) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:41:39] __main__ INFO: [0mEpoch 8 Step 200/390 lr 0.100000 loss 0.3388 (0.3273) acc@1 0.8984 (0.8889) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:41:43] __main__ INFO: [0mEpoch 8 Step 300/390 lr 0.100000 loss 0.3674 (0.3291) acc@1 0.8516 (0.8886) acc@5 1.0000 (0.9966)
[32m[2022-06-11 11:41:47] __main__ INFO: [0mEpoch 8 Step 390/390 lr 0.100000 loss 0.2771 (0.3262) acc@1 0.9297 (0.8883) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:41:47] __main__ INFO: [0mElapsed 15.87
[32m[2022-06-11 11:41:47] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:41:48] __main__ INFO: [0mEpoch 8 loss 0.4212 acc@1 0.8588 acc@5 0.9951
[32m[2022-06-11 11:41:48] __main__ INFO: [0mElapsed 0.91
[32m[2022-06-11 11:41:48] __main__ INFO: [0mTrain 9 3120
[32m[2022-06-11 11:41:52] __main__ INFO: [0mEpoch 9 Step 100/390 lr 0.100000 loss 0.3391 (0.3046) acc@1 0.8906 (0.8966) acc@5 1.0000 (0.9978)
[32m[2022-06-11 11:41:56] __main__ INFO: [0mEpoch 9 Step 200/390 lr 0.100000 loss 0.2622 (0.3039) acc@1 0.9375 (0.8954) acc@5 1.0000 (0.9977)
[32m[2022-06-11 11:42:00] __main__ INFO: [0mEpoch 9 Step 300/390 lr 0.100000 loss 0.4118 (0.3096) acc@1 0.8750 (0.8928) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:42:03] __main__ INFO: [0mEpoch 9 Step 390/390 lr 0.100000 loss 0.2930 (0.3094) acc@1 0.9219 (0.8930) acc@5 1.0000 (0.9970)
[32m[2022-06-11 11:42:03] __main__ INFO: [0mElapsed 15.57
[32m[2022-06-11 11:42:03] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:42:04] __main__ INFO: [0mEpoch 9 loss 0.5741 acc@1 0.8195 acc@5 0.9928
[32m[2022-06-11 11:42:04] __main__ INFO: [0mElapsed 0.97
[32m[2022-06-11 11:42:04] __main__ INFO: [0mTrain 10 3510
[32m[2022-06-11 11:42:08] __main__ INFO: [0mEpoch 10 Step 100/390 lr 0.100000 loss 0.3077 (0.2956) acc@1 0.8594 (0.8976) acc@5 1.0000 (0.9969)
[32m[2022-06-11 11:42:13] __main__ INFO: [0mEpoch 10 Step 200/390 lr 0.100000 loss 0.3786 (0.3034) acc@1 0.8750 (0.8950) acc@5 1.0000 (0.9964)
[32m[2022-06-11 11:42:16] __main__ INFO: [0mEpoch 10 Step 300/390 lr 0.100000 loss 0.1840 (0.3018) acc@1 0.9375 (0.8956) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:42:20] __main__ INFO: [0mEpoch 10 Step 390/390 lr 0.100000 loss 0.2419 (0.3055) acc@1 0.8906 (0.8938) acc@5 1.0000 (0.9967)
[32m[2022-06-11 11:42:20] __main__ INFO: [0mElapsed 15.69
[32m[2022-06-11 11:42:20] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:42:21] __main__ INFO: [0mEpoch 10 loss 0.6033 acc@1 0.8143 acc@5 0.9891
[32m[2022-06-11 11:42:21] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:42:21] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-11 11:43:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:43:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:45:19] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:45:19] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:45:47] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:45:47] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:46:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:46:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:47:09] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: /home/esoc/jihee/Image_Classification/experiments/cifar10/resnet/exp00/checkpoint_00160.pth
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-11 11:47:09] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-11 11:47:13] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-11 11:47:13] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-11 11:47:13] __main__ INFO: [0mVal 0
[32m[2022-06-11 11:47:14] __main__ INFO: [0mEpoch 0 loss 2.9075 acc@1 0.1334 acc@5 0.5883
[32m[2022-06-11 11:47:14] __main__ INFO: [0mElapsed 1.02
[32m[2022-06-11 11:47:14] __main__ INFO: [0mTrain 1 0
[32m[2022-06-11 11:47:16] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 1.1085 (1.4677) acc@1 0.6094 (0.4816) acc@5 0.9766 (0.9099)
[32m[2022-06-11 11:47:16] __main__ INFO: [0mElapsed 2.00
[32m[2022-06-11 11:47:16] __main__ INFO: [0mVal 1
[32m[2022-06-11 11:47:17] __main__ INFO: [0mEpoch 1 loss 1.9991 acc@1 0.4416 acc@5 0.8211
[32m[2022-06-11 11:47:17] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:47:17] __main__ INFO: [0mTrain 2 39
[32m[2022-06-11 11:47:19] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 0.8281 (0.8931) acc@1 0.6641 (0.6855) acc@5 0.9844 (0.9764)
[32m[2022-06-11 11:47:19] __main__ INFO: [0mElapsed 1.82
[32m[2022-06-11 11:47:19] __main__ INFO: [0mVal 2
[32m[2022-06-11 11:47:20] __main__ INFO: [0mEpoch 2 loss 1.1504 acc@1 0.6234 acc@5 0.9625
[32m[2022-06-11 11:47:20] __main__ INFO: [0mElapsed 0.98
[32m[2022-06-11 11:47:20] __main__ INFO: [0mTrain 3 78
[32m[2022-06-11 11:47:22] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 0.7418 (0.7268) acc@1 0.7188 (0.7442) acc@5 0.9844 (0.9874)
[32m[2022-06-11 11:47:22] __main__ INFO: [0mElapsed 1.88
[32m[2022-06-11 11:47:22] __main__ INFO: [0mVal 3
[32m[2022-06-11 11:47:23] __main__ INFO: [0mEpoch 3 loss 1.0344 acc@1 0.6665 acc@5 0.9723
[32m[2022-06-11 11:47:23] __main__ INFO: [0mElapsed 0.95
[32m[2022-06-11 11:47:23] __main__ INFO: [0mTrain 4 117
[32m[2022-06-11 11:47:25] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 0.7325 (0.6317) acc@1 0.7266 (0.7788) acc@5 0.9922 (0.9878)
[32m[2022-06-11 11:47:25] __main__ INFO: [0mElapsed 1.92
[32m[2022-06-11 11:47:25] __main__ INFO: [0mVal 4
[32m[2022-06-11 11:47:26] __main__ INFO: [0mEpoch 4 loss 1.1381 acc@1 0.6523 acc@5 0.9468
[32m[2022-06-11 11:47:26] __main__ INFO: [0mElapsed 0.93
[32m[2022-06-11 11:47:26] __main__ INFO: [0mTrain 5 156
[32m[2022-06-11 11:47:28] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 0.4686 (0.5484) acc@1 0.8594 (0.8089) acc@5 0.9844 (0.9878)
[32m[2022-06-11 11:47:28] __main__ INFO: [0mElapsed 1.90
[32m[2022-06-11 11:47:28] __main__ INFO: [0mVal 5
[32m[2022-06-11 11:47:29] __main__ INFO: [0mEpoch 5 loss 1.1331 acc@1 0.6604 acc@5 0.9684
[32m[2022-06-11 11:47:29] __main__ INFO: [0mElapsed 1.00
[32m[2022-06-11 11:47:29] __main__ INFO: [0mTrain 6 195
[32m[2022-06-11 11:47:31] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 0.5048 (0.5052) acc@1 0.8281 (0.8247) acc@5 0.9922 (0.9914)
[32m[2022-06-11 11:47:31] __main__ INFO: [0mElapsed 1.89
[32m[2022-06-11 11:47:31] __main__ INFO: [0mVal 6
[32m[2022-06-11 11:47:32] __main__ INFO: [0mEpoch 6 loss 1.1472 acc@1 0.6510 acc@5 0.9723
[32m[2022-06-11 11:47:32] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:32] __main__ INFO: [0mTrain 7 234
[32m[2022-06-11 11:47:33] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 0.5296 (0.4943) acc@1 0.8125 (0.8309) acc@5 0.9922 (0.9924)
[32m[2022-06-11 11:47:33] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:33] __main__ INFO: [0mVal 7
[32m[2022-06-11 11:47:34] __main__ INFO: [0mEpoch 7 loss 1.0596 acc@1 0.6989 acc@5 0.9757
[32m[2022-06-11 11:47:34] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:34] __main__ INFO: [0mTrain 8 273
[32m[2022-06-11 11:47:36] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 0.5585 (0.4186) acc@1 0.7969 (0.8544) acc@5 1.0000 (0.9952)
[32m[2022-06-11 11:47:36] __main__ INFO: [0mElapsed 1.82
[32m[2022-06-11 11:47:36] __main__ INFO: [0mVal 8
[32m[2022-06-11 11:47:37] __main__ INFO: [0mEpoch 8 loss 0.8895 acc@1 0.7261 acc@5 0.9779
[32m[2022-06-11 11:47:37] __main__ INFO: [0mElapsed 0.99
[32m[2022-06-11 11:47:37] __main__ INFO: [0mTrain 9 312
[32m[2022-06-11 11:47:39] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 0.3663 (0.3945) acc@1 0.8594 (0.8620) acc@5 0.9922 (0.9968)
[32m[2022-06-11 11:47:39] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:39] __main__ INFO: [0mVal 9
[32m[2022-06-11 11:47:40] __main__ INFO: [0mEpoch 9 loss 1.0373 acc@1 0.7009 acc@5 0.9689
[32m[2022-06-11 11:47:40] __main__ INFO: [0mElapsed 0.94
[32m[2022-06-11 11:47:40] __main__ INFO: [0mTrain 10 351
[32m[2022-06-11 11:47:42] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 0.4399 (0.3806) acc@1 0.8594 (0.8652) acc@5 1.0000 (0.9972)
[32m[2022-06-11 11:47:42] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-11 11:47:42] __main__ INFO: [0mVal 10
[32m[2022-06-11 11:47:43] __main__ INFO: [0mEpoch 10 loss 1.0641 acc@1 0.7062 acc@5 0.9784
[32m[2022-06-11 11:47:43] __main__ INFO: [0mElapsed 0.90
[32m[2022-06-11 11:47:43] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-16 11:03:12] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:03:12] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:04:04] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:04:04] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:04:50] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:04:50] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:04:53] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:04:53] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:04:55] __main__ INFO: [0mVal 0
[32m[2022-06-16 11:05:19] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:05:19] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 1
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:05:23] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:05:23] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:05:24] __main__ INFO: [0mVal 0
[32m[2022-06-16 11:33:11] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:33:11] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:33:16] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:33:16] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:33:16] __main__ INFO: [0mVal 0
[32m[2022-06-16 11:33:17] __main__ INFO: [0mEpoch 0 loss 27477.4460 acc@1 0.1002 acc@5 0.5020
[32m[2022-06-16 11:33:17] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:33:17] __main__ INFO: [0mTrain 1 0
[32m[2022-06-16 11:33:19] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 2.5557 (4.3958) acc@1 0.0938 (0.1084) acc@5 0.5625 (0.5134)
[32m[2022-06-16 11:33:19] __main__ INFO: [0mElapsed 2.04
[32m[2022-06-16 11:33:19] __main__ INFO: [0mVal 1
[32m[2022-06-16 11:33:20] __main__ INFO: [0mEpoch 1 loss 8.0965 acc@1 0.1058 acc@5 0.5285
[32m[2022-06-16 11:33:20] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:33:20] __main__ INFO: [0mTrain 2 39
[32m[2022-06-16 11:33:21] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 2.2933 (2.3830) acc@1 0.1094 (0.1030) acc@5 0.5469 (0.5154)
[32m[2022-06-16 11:33:21] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:33:21] __main__ INFO: [0mVal 2
[32m[2022-06-16 11:33:22] __main__ INFO: [0mEpoch 2 loss 2.3345 acc@1 0.1069 acc@5 0.5106
[32m[2022-06-16 11:33:22] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:33:22] __main__ INFO: [0mTrain 3 78
[32m[2022-06-16 11:33:24] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 2.3020 (2.3441) acc@1 0.1250 (0.1004) acc@5 0.5469 (0.5116)
[32m[2022-06-16 11:33:24] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:33:24] __main__ INFO: [0mVal 3
[32m[2022-06-16 11:33:24] __main__ INFO: [0mEpoch 3 loss 2.3178 acc@1 0.1056 acc@5 0.5081
[32m[2022-06-16 11:33:24] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:33:24] __main__ INFO: [0mTrain 4 117
[32m[2022-06-16 11:33:26] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 2.3065 (2.3293) acc@1 0.1016 (0.1064) acc@5 0.4766 (0.5260)
[32m[2022-06-16 11:33:26] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:33:26] __main__ INFO: [0mVal 4
[32m[2022-06-16 11:33:27] __main__ INFO: [0mEpoch 4 loss 2.3127 acc@1 0.1077 acc@5 0.5138
[32m[2022-06-16 11:33:27] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:33:27] __main__ INFO: [0mTrain 5 156
[32m[2022-06-16 11:33:29] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 2.3142 (2.3242) acc@1 0.1094 (0.0970) acc@5 0.4688 (0.5150)
[32m[2022-06-16 11:33:29] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:33:29] __main__ INFO: [0mVal 5
[32m[2022-06-16 11:33:29] __main__ INFO: [0mEpoch 5 loss 2.3142 acc@1 0.1059 acc@5 0.5064
[32m[2022-06-16 11:33:29] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:33:29] __main__ INFO: [0mTrain 6 195
[32m[2022-06-16 11:33:31] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 2.3112 (2.3170) acc@1 0.1094 (0.1040) acc@5 0.4922 (0.5054)
[32m[2022-06-16 11:33:31] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:33:31] __main__ INFO: [0mVal 6
[32m[2022-06-16 11:33:32] __main__ INFO: [0mEpoch 6 loss 2.3140 acc@1 0.1057 acc@5 0.5091
[32m[2022-06-16 11:33:32] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:33:32] __main__ INFO: [0mTrain 7 234
[32m[2022-06-16 11:33:33] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 2.2988 (2.3093) acc@1 0.1094 (0.1040) acc@5 0.5781 (0.5166)
[32m[2022-06-16 11:33:33] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:33:33] __main__ INFO: [0mVal 7
[32m[2022-06-16 11:33:34] __main__ INFO: [0mEpoch 7 loss 2.3050 acc@1 0.1051 acc@5 0.5089
[32m[2022-06-16 11:33:34] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:33:34] __main__ INFO: [0mTrain 8 273
[32m[2022-06-16 11:33:36] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 2.3509 (2.3081) acc@1 0.0938 (0.0996) acc@5 0.4766 (0.5152)
[32m[2022-06-16 11:33:36] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:33:36] __main__ INFO: [0mVal 8
[32m[2022-06-16 11:33:37] __main__ INFO: [0mEpoch 8 loss 2.3020 acc@1 0.1057 acc@5 0.5065
[32m[2022-06-16 11:33:37] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:33:37] __main__ INFO: [0mTrain 9 312
[32m[2022-06-16 11:33:38] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 2.3283 (2.3066) acc@1 0.0625 (0.1044) acc@5 0.4844 (0.5108)
[32m[2022-06-16 11:33:38] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:33:38] __main__ INFO: [0mVal 9
[32m[2022-06-16 11:33:39] __main__ INFO: [0mEpoch 9 loss 2.3324 acc@1 0.1026 acc@5 0.5095
[32m[2022-06-16 11:33:39] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:33:39] __main__ INFO: [0mTrain 10 351
[32m[2022-06-16 11:33:41] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 2.3122 (2.3051) acc@1 0.0703 (0.1056) acc@5 0.5547 (0.5056)
[32m[2022-06-16 11:33:41] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:33:41] __main__ INFO: [0mVal 10
[32m[2022-06-16 11:33:41] __main__ INFO: [0mEpoch 10 loss 2.3193 acc@1 0.1071 acc@5 0.5082
[32m[2022-06-16 11:33:41] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:33:41] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-16 11:34:01] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: False
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:34:01] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:34:05] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:34:05] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:34:05] __main__ INFO: [0mVal 0
[32m[2022-06-16 11:34:06] __main__ INFO: [0mEpoch 0 loss 16761.8818 acc@1 0.1000 acc@5 0.5000
[32m[2022-06-16 11:34:06] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:34:06] __main__ INFO: [0mTrain 1 0
[32m[2022-06-16 11:34:10] __main__ INFO: [0mEpoch 1 Step 100/390 lr 0.100000 loss 2.3763 (3.0748) acc@1 0.1484 (0.1088) acc@5 0.5781 (0.5452)
[32m[2022-06-16 11:34:14] __main__ INFO: [0mEpoch 1 Step 200/390 lr 0.100000 loss 2.2905 (2.6777) acc@1 0.1562 (0.1248) acc@5 0.6797 (0.5755)
[32m[2022-06-16 11:34:18] __main__ INFO: [0mEpoch 1 Step 300/390 lr 0.100000 loss 2.1006 (2.5043) acc@1 0.1875 (0.1440) acc@5 0.7812 (0.6162)
[32m[2022-06-16 11:34:21] __main__ INFO: [0mEpoch 1 Step 390/390 lr 0.100000 loss 1.9764 (2.3939) acc@1 0.2578 (0.1625) acc@5 0.8438 (0.6540)
[32m[2022-06-16 11:34:21] __main__ INFO: [0mElapsed 15.59
[32m[2022-06-16 11:34:21] __main__ INFO: [0mVal 1
[32m[2022-06-16 11:34:22] __main__ INFO: [0mEpoch 1 loss 1.9449 acc@1 0.2482 acc@5 0.8131
[32m[2022-06-16 11:34:22] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:34:22] __main__ INFO: [0mTrain 2 390
[32m[2022-06-16 11:34:26] __main__ INFO: [0mEpoch 2 Step 100/390 lr 0.100000 loss 1.8968 (1.9380) acc@1 0.2109 (0.2491) acc@5 0.8203 (0.8190)
[32m[2022-06-16 11:34:30] __main__ INFO: [0mEpoch 2 Step 200/390 lr 0.100000 loss 1.6616 (1.8778) acc@1 0.3828 (0.2758) acc@5 0.8828 (0.8350)
[32m[2022-06-16 11:34:34] __main__ INFO: [0mEpoch 2 Step 300/390 lr 0.100000 loss 1.6512 (1.8239) acc@1 0.3594 (0.3015) acc@5 0.8906 (0.8492)
[32m[2022-06-16 11:34:38] __main__ INFO: [0mEpoch 2 Step 390/390 lr 0.100000 loss 1.4952 (1.7783) acc@1 0.4531 (0.3233) acc@5 0.8984 (0.8595)
[32m[2022-06-16 11:34:38] __main__ INFO: [0mElapsed 15.79
[32m[2022-06-16 11:34:38] __main__ INFO: [0mVal 2
[32m[2022-06-16 11:34:39] __main__ INFO: [0mEpoch 2 loss 1.5750 acc@1 0.4263 acc@5 0.9087
[32m[2022-06-16 11:34:39] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:34:39] __main__ INFO: [0mTrain 3 780
[32m[2022-06-16 11:34:43] __main__ INFO: [0mEpoch 3 Step 100/390 lr 0.100000 loss 1.4499 (1.5385) acc@1 0.4844 (0.4384) acc@5 0.8672 (0.9067)
[32m[2022-06-16 11:34:47] __main__ INFO: [0mEpoch 3 Step 200/390 lr 0.100000 loss 1.3488 (1.4895) acc@1 0.5312 (0.4552) acc@5 0.9531 (0.9152)
[32m[2022-06-16 11:35:04] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 500
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: False
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-16 11:35:04] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-16 11:35:08] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-16 11:35:08] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-16 11:35:08] __main__ INFO: [0mVal 0
[32m[2022-06-16 11:35:09] __main__ INFO: [0mEpoch 0 loss 27477.4463 acc@1 0.1002 acc@5 0.5020
[32m[2022-06-16 11:35:09] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:35:09] __main__ INFO: [0mTrain 1 0
[32m[2022-06-16 11:35:10] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 2.2672 (4.3523) acc@1 0.1094 (0.1092) acc@5 0.5938 (0.5154)
[32m[2022-06-16 11:35:11] __main__ INFO: [0mElapsed 1.89
[32m[2022-06-16 11:35:11] __main__ INFO: [0mVal 1
[32m[2022-06-16 11:35:11] __main__ INFO: [0mEpoch 1 loss 14.9878 acc@1 0.1087 acc@5 0.5310
[32m[2022-06-16 11:35:11] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:35:11] __main__ INFO: [0mTrain 2 39
[32m[2022-06-16 11:35:13] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 2.2800 (2.4397) acc@1 0.1172 (0.1060) acc@5 0.5391 (0.5126)
[32m[2022-06-16 11:35:13] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:35:13] __main__ INFO: [0mVal 2
[32m[2022-06-16 11:35:14] __main__ INFO: [0mEpoch 2 loss 2.5837 acc@1 0.1131 acc@5 0.5089
[32m[2022-06-16 11:35:14] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:35:14] __main__ INFO: [0mTrain 3 78
[32m[2022-06-16 11:35:15] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 2.2854 (2.3240) acc@1 0.1484 (0.1010) acc@5 0.5547 (0.5172)
[32m[2022-06-16 11:35:15] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:35:15] __main__ INFO: [0mVal 3
[32m[2022-06-16 11:35:16] __main__ INFO: [0mEpoch 3 loss 2.3020 acc@1 0.1105 acc@5 0.5179
[32m[2022-06-16 11:35:16] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:35:16] __main__ INFO: [0mTrain 4 117
[32m[2022-06-16 11:35:17] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 2.3363 (2.3162) acc@1 0.0938 (0.1086) acc@5 0.4609 (0.5323)
[32m[2022-06-16 11:35:18] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:35:18] __main__ INFO: [0mVal 4
[32m[2022-06-16 11:35:18] __main__ INFO: [0mEpoch 4 loss 2.3066 acc@1 0.1100 acc@5 0.5188
[32m[2022-06-16 11:35:18] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:35:18] __main__ INFO: [0mTrain 5 156
[32m[2022-06-16 11:35:20] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 2.3025 (2.3147) acc@1 0.1016 (0.1040) acc@5 0.5234 (0.5236)
[32m[2022-06-16 11:35:20] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:35:20] __main__ INFO: [0mVal 5
[32m[2022-06-16 11:35:21] __main__ INFO: [0mEpoch 5 loss 2.3371 acc@1 0.1089 acc@5 0.5207
[32m[2022-06-16 11:35:21] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:35:21] __main__ INFO: [0mTrain 6 195
[32m[2022-06-16 11:35:22] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 2.2979 (2.3011) acc@1 0.1172 (0.1096) acc@5 0.5234 (0.5284)
[32m[2022-06-16 11:35:22] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:35:22] __main__ INFO: [0mVal 6
[32m[2022-06-16 11:35:23] __main__ INFO: [0mEpoch 6 loss 2.3055 acc@1 0.1121 acc@5 0.5196
[32m[2022-06-16 11:35:23] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:35:23] __main__ INFO: [0mTrain 7 234
[32m[2022-06-16 11:35:25] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 2.2930 (2.3044) acc@1 0.1016 (0.1114) acc@5 0.5859 (0.5268)
[32m[2022-06-16 11:35:25] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:35:25] __main__ INFO: [0mVal 7
[32m[2022-06-16 11:35:26] __main__ INFO: [0mEpoch 7 loss 2.3103 acc@1 0.1109 acc@5 0.5199
[32m[2022-06-16 11:35:26] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:35:26] __main__ INFO: [0mTrain 8 273
[32m[2022-06-16 11:35:27] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 2.2964 (2.3009) acc@1 0.1484 (0.1090) acc@5 0.4922 (0.5359)
[32m[2022-06-16 11:35:27] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:35:27] __main__ INFO: [0mVal 8
[32m[2022-06-16 11:35:28] __main__ INFO: [0mEpoch 8 loss 2.3151 acc@1 0.1241 acc@5 0.5236
[32m[2022-06-16 11:35:28] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:35:28] __main__ INFO: [0mTrain 9 312
[32m[2022-06-16 11:35:30] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 2.3284 (2.2972) acc@1 0.0703 (0.1152) acc@5 0.4922 (0.5481)
[32m[2022-06-16 11:35:30] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:35:30] __main__ INFO: [0mVal 9
[32m[2022-06-16 11:35:30] __main__ INFO: [0mEpoch 9 loss 2.2984 acc@1 0.1164 acc@5 0.5232
[32m[2022-06-16 11:35:30] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:35:30] __main__ INFO: [0mTrain 10 351
[32m[2022-06-16 11:35:32] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 2.3025 (2.2965) acc@1 0.0781 (0.1222) acc@5 0.5625 (0.5489)
[32m[2022-06-16 11:35:32] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:35:32] __main__ INFO: [0mVal 10
[32m[2022-06-16 11:35:33] __main__ INFO: [0mEpoch 10 loss 2.3022 acc@1 0.1119 acc@5 0.5457
[32m[2022-06-16 11:35:33] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:35:33] __main__ INFO: [0mTrain 11 390
[32m[2022-06-16 11:35:34] __main__ INFO: [0mEpoch 11 Step 39/39 lr 0.100000 loss 2.3096 (2.2937) acc@1 0.0781 (0.1204) acc@5 0.4531 (0.5505)
[32m[2022-06-16 11:35:34] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:35:34] __main__ INFO: [0mVal 11
[32m[2022-06-16 11:35:35] __main__ INFO: [0mEpoch 11 loss 2.2991 acc@1 0.1163 acc@5 0.5379
[32m[2022-06-16 11:35:35] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:35:35] __main__ INFO: [0mTrain 12 429
[32m[2022-06-16 11:35:37] __main__ INFO: [0mEpoch 12 Step 39/39 lr 0.100000 loss 2.3136 (2.2933) acc@1 0.0938 (0.1292) acc@5 0.5000 (0.5577)
[32m[2022-06-16 11:35:37] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:35:37] __main__ INFO: [0mVal 12
[32m[2022-06-16 11:35:37] __main__ INFO: [0mEpoch 12 loss 2.3110 acc@1 0.1304 acc@5 0.5488
[32m[2022-06-16 11:35:37] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:35:37] __main__ INFO: [0mTrain 13 468
[32m[2022-06-16 11:35:39] __main__ INFO: [0mEpoch 13 Step 39/39 lr 0.100000 loss 2.3048 (2.2887) acc@1 0.1484 (0.1154) acc@5 0.5312 (0.5627)
[32m[2022-06-16 11:35:39] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:35:39] __main__ INFO: [0mVal 13
[32m[2022-06-16 11:35:40] __main__ INFO: [0mEpoch 13 loss 2.2953 acc@1 0.1327 acc@5 0.5447
[32m[2022-06-16 11:35:40] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:35:40] __main__ INFO: [0mTrain 14 507
[32m[2022-06-16 11:35:41] __main__ INFO: [0mEpoch 14 Step 39/39 lr 0.100000 loss 2.2760 (2.2876) acc@1 0.1484 (0.1244) acc@5 0.6094 (0.5671)
[32m[2022-06-16 11:35:41] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:35:41] __main__ INFO: [0mVal 14
[32m[2022-06-16 11:35:42] __main__ INFO: [0mEpoch 14 loss 2.3034 acc@1 0.1277 acc@5 0.5588
[32m[2022-06-16 11:35:42] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:35:42] __main__ INFO: [0mTrain 15 546
[32m[2022-06-16 11:35:44] __main__ INFO: [0mEpoch 15 Step 39/39 lr 0.100000 loss 2.3169 (2.2852) acc@1 0.1094 (0.1342) acc@5 0.5547 (0.5671)
[32m[2022-06-16 11:35:44] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:35:44] __main__ INFO: [0mVal 15
[32m[2022-06-16 11:35:45] __main__ INFO: [0mEpoch 15 loss 2.2867 acc@1 0.1332 acc@5 0.5534
[32m[2022-06-16 11:35:45] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:35:45] __main__ INFO: [0mTrain 16 585
[32m[2022-06-16 11:35:46] __main__ INFO: [0mEpoch 16 Step 39/39 lr 0.100000 loss 2.1684 (2.2658) acc@1 0.2031 (0.1394) acc@5 0.7031 (0.5921)
[32m[2022-06-16 11:35:46] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:35:46] __main__ INFO: [0mVal 16
[32m[2022-06-16 11:35:47] __main__ INFO: [0mEpoch 16 loss 2.2085 acc@1 0.1664 acc@5 0.6456
[32m[2022-06-16 11:35:47] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:35:47] __main__ INFO: [0mTrain 17 624
[32m[2022-06-16 11:35:49] __main__ INFO: [0mEpoch 17 Step 39/39 lr 0.100000 loss 2.1018 (2.1356) acc@1 0.1797 (0.1809) acc@5 0.7031 (0.7284)
[32m[2022-06-16 11:35:49] __main__ INFO: [0mElapsed 1.81
[32m[2022-06-16 11:35:49] __main__ INFO: [0mVal 17
[32m[2022-06-16 11:35:50] __main__ INFO: [0mEpoch 17 loss 2.0913 acc@1 0.1766 acc@5 0.7510
[32m[2022-06-16 11:35:50] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:35:50] __main__ INFO: [0mTrain 18 663
[32m[2022-06-16 11:35:51] __main__ INFO: [0mEpoch 18 Step 39/39 lr 0.100000 loss 1.9292 (2.0709) acc@1 0.3203 (0.1871) acc@5 0.8359 (0.7668)
[32m[2022-06-16 11:35:51] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:35:51] __main__ INFO: [0mVal 18
[32m[2022-06-16 11:35:52] __main__ INFO: [0mEpoch 18 loss 2.5405 acc@1 0.1659 acc@5 0.6787
[32m[2022-06-16 11:35:52] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:35:52] __main__ INFO: [0mTrain 19 702
[32m[2022-06-16 11:35:54] __main__ INFO: [0mEpoch 19 Step 39/39 lr 0.100000 loss 1.9299 (2.0221) acc@1 0.2812 (0.1931) acc@5 0.8203 (0.7855)
[32m[2022-06-16 11:35:54] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:35:54] __main__ INFO: [0mVal 19
[32m[2022-06-16 11:35:54] __main__ INFO: [0mEpoch 19 loss 2.1422 acc@1 0.1678 acc@5 0.7075
[32m[2022-06-16 11:35:54] __main__ INFO: [0mElapsed 0.66
[32m[2022-06-16 11:35:54] __main__ INFO: [0mTrain 20 741
[32m[2022-06-16 11:35:56] __main__ INFO: [0mEpoch 20 Step 39/39 lr 0.100000 loss 1.9470 (1.9851) acc@1 0.2422 (0.2089) acc@5 0.7734 (0.7903)
[32m[2022-06-16 11:35:56] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:35:56] __main__ INFO: [0mVal 20
[32m[2022-06-16 11:35:57] __main__ INFO: [0mEpoch 20 loss 2.0145 acc@1 0.2216 acc@5 0.7878
[32m[2022-06-16 11:35:57] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:35:57] __main__ INFO: [0mTrain 21 780
[32m[2022-06-16 11:35:58] __main__ INFO: [0mEpoch 21 Step 39/39 lr 0.100000 loss 1.9126 (1.9522) acc@1 0.2188 (0.2334) acc@5 0.7812 (0.8059)
[32m[2022-06-16 11:35:59] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:35:59] __main__ INFO: [0mVal 21
[32m[2022-06-16 11:35:59] __main__ INFO: [0mEpoch 21 loss 1.9732 acc@1 0.2296 acc@5 0.8256
[32m[2022-06-16 11:35:59] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:35:59] __main__ INFO: [0mTrain 22 819
[32m[2022-06-16 11:36:01] __main__ INFO: [0mEpoch 22 Step 39/39 lr 0.100000 loss 1.9435 (1.9354) acc@1 0.2422 (0.2454) acc@5 0.8125 (0.8125)
[32m[2022-06-16 11:36:01] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:36:01] __main__ INFO: [0mVal 22
[32m[2022-06-16 11:36:02] __main__ INFO: [0mEpoch 22 loss 1.9139 acc@1 0.2702 acc@5 0.8347
[32m[2022-06-16 11:36:02] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:36:02] __main__ INFO: [0mTrain 23 858
[32m[2022-06-16 11:36:03] __main__ INFO: [0mEpoch 23 Step 39/39 lr 0.100000 loss 1.9179 (1.8952) acc@1 0.2969 (0.2728) acc@5 0.8281 (0.8245)
[32m[2022-06-16 11:36:03] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:36:03] __main__ INFO: [0mVal 23
[32m[2022-06-16 11:36:04] __main__ INFO: [0mEpoch 23 loss 1.9667 acc@1 0.2756 acc@5 0.8144
[32m[2022-06-16 11:36:04] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:36:04] __main__ INFO: [0mTrain 24 897
[32m[2022-06-16 11:36:06] __main__ INFO: [0mEpoch 24 Step 39/39 lr 0.100000 loss 1.9453 (1.8582) acc@1 0.2656 (0.2827) acc@5 0.7891 (0.8438)
[32m[2022-06-16 11:36:06] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:36:06] __main__ INFO: [0mVal 24
[32m[2022-06-16 11:36:07] __main__ INFO: [0mEpoch 24 loss 1.8079 acc@1 0.3174 acc@5 0.8547
[32m[2022-06-16 11:36:07] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:36:07] __main__ INFO: [0mTrain 25 936
[32m[2022-06-16 11:36:08] __main__ INFO: [0mEpoch 25 Step 39/39 lr 0.100000 loss 1.8371 (1.8299) acc@1 0.3828 (0.3009) acc@5 0.8594 (0.8494)
[32m[2022-06-16 11:36:08] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:36:08] __main__ INFO: [0mVal 25
[32m[2022-06-16 11:36:09] __main__ INFO: [0mEpoch 25 loss 1.8347 acc@1 0.3144 acc@5 0.8423
[32m[2022-06-16 11:36:09] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:36:09] __main__ INFO: [0mTrain 26 975
[32m[2022-06-16 11:36:11] __main__ INFO: [0mEpoch 26 Step 39/39 lr 0.100000 loss 1.8043 (1.8118) acc@1 0.2969 (0.3113) acc@5 0.8828 (0.8530)
[32m[2022-06-16 11:36:11] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:36:11] __main__ INFO: [0mVal 26
[32m[2022-06-16 11:36:11] __main__ INFO: [0mEpoch 26 loss 1.7871 acc@1 0.3333 acc@5 0.8615
[32m[2022-06-16 11:36:11] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:36:11] __main__ INFO: [0mTrain 27 1014
[32m[2022-06-16 11:36:13] __main__ INFO: [0mEpoch 27 Step 39/39 lr 0.100000 loss 1.7804 (1.7769) acc@1 0.3594 (0.3307) acc@5 0.8828 (0.8598)
[32m[2022-06-16 11:36:13] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:36:13] __main__ INFO: [0mVal 27
[32m[2022-06-16 11:36:14] __main__ INFO: [0mEpoch 27 loss 1.7587 acc@1 0.3465 acc@5 0.8633
[32m[2022-06-16 11:36:14] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:36:14] __main__ INFO: [0mTrain 28 1053
[32m[2022-06-16 11:36:16] __main__ INFO: [0mEpoch 28 Step 39/39 lr 0.100000 loss 1.5926 (1.7500) acc@1 0.4141 (0.3405) acc@5 0.8984 (0.8684)
[32m[2022-06-16 11:36:16] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:36:16] __main__ INFO: [0mVal 28
[32m[2022-06-16 11:36:16] __main__ INFO: [0mEpoch 28 loss 1.9361 acc@1 0.3095 acc@5 0.8338
[32m[2022-06-16 11:36:16] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:36:16] __main__ INFO: [0mTrain 29 1092
[32m[2022-06-16 11:36:18] __main__ INFO: [0mEpoch 29 Step 39/39 lr 0.100000 loss 1.6202 (1.7206) acc@1 0.3516 (0.3638) acc@5 0.9297 (0.8722)
[32m[2022-06-16 11:36:18] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-16 11:36:18] __main__ INFO: [0mVal 29
[32m[2022-06-16 11:36:19] __main__ INFO: [0mEpoch 29 loss 1.7134 acc@1 0.3725 acc@5 0.8706
[32m[2022-06-16 11:36:19] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:36:19] __main__ INFO: [0mTrain 30 1131
[32m[2022-06-16 11:36:20] __main__ INFO: [0mEpoch 30 Step 39/39 lr 0.100000 loss 1.6510 (1.6951) acc@1 0.4297 (0.3616) acc@5 0.8984 (0.8838)
[32m[2022-06-16 11:36:21] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:36:21] __main__ INFO: [0mVal 30
[32m[2022-06-16 11:36:21] __main__ INFO: [0mEpoch 30 loss 1.7140 acc@1 0.3731 acc@5 0.8693
[32m[2022-06-16 11:36:21] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:36:21] __main__ INFO: [0mTrain 31 1170
[32m[2022-06-16 11:36:23] __main__ INFO: [0mEpoch 31 Step 39/39 lr 0.100000 loss 1.5881 (1.6772) acc@1 0.4453 (0.3722) acc@5 0.9297 (0.8842)
[32m[2022-06-16 11:36:23] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:36:23] __main__ INFO: [0mVal 31
[32m[2022-06-16 11:36:24] __main__ INFO: [0mEpoch 31 loss 1.9123 acc@1 0.3358 acc@5 0.8453
[32m[2022-06-16 11:36:24] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:36:24] __main__ INFO: [0mTrain 32 1209
[32m[2022-06-16 11:36:25] __main__ INFO: [0mEpoch 32 Step 39/39 lr 0.100000 loss 1.7301 (1.6385) acc@1 0.4062 (0.3824) acc@5 0.8359 (0.8896)
[32m[2022-06-16 11:36:25] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:36:25] __main__ INFO: [0mVal 32
[32m[2022-06-16 11:36:26] __main__ INFO: [0mEpoch 32 loss 1.7300 acc@1 0.3817 acc@5 0.8824
[32m[2022-06-16 11:36:26] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:36:26] __main__ INFO: [0mTrain 33 1248
[32m[2022-06-16 11:36:28] __main__ INFO: [0mEpoch 33 Step 39/39 lr 0.100000 loss 1.5046 (1.6077) acc@1 0.3672 (0.3976) acc@5 0.9062 (0.9020)
[32m[2022-06-16 11:36:28] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:36:28] __main__ INFO: [0mVal 33
[32m[2022-06-16 11:36:28] __main__ INFO: [0mEpoch 33 loss 1.6551 acc@1 0.3860 acc@5 0.8739
[32m[2022-06-16 11:36:28] __main__ INFO: [0mElapsed 0.66
[32m[2022-06-16 11:36:28] __main__ INFO: [0mTrain 34 1287
[32m[2022-06-16 11:36:30] __main__ INFO: [0mEpoch 34 Step 39/39 lr 0.100000 loss 1.5436 (1.5791) acc@1 0.4219 (0.4101) acc@5 0.9453 (0.9071)
[32m[2022-06-16 11:36:30] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:36:30] __main__ INFO: [0mVal 34
[32m[2022-06-16 11:36:31] __main__ INFO: [0mEpoch 34 loss 1.6046 acc@1 0.3998 acc@5 0.8954
[32m[2022-06-16 11:36:31] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:36:31] __main__ INFO: [0mTrain 35 1326
[32m[2022-06-16 11:36:33] __main__ INFO: [0mEpoch 35 Step 39/39 lr 0.100000 loss 1.5049 (1.5486) acc@1 0.4766 (0.4187) acc@5 0.9297 (0.9121)
[32m[2022-06-16 11:36:33] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:36:33] __main__ INFO: [0mVal 35
[32m[2022-06-16 11:36:33] __main__ INFO: [0mEpoch 35 loss 1.5941 acc@1 0.4134 acc@5 0.8997
[32m[2022-06-16 11:36:33] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:36:33] __main__ INFO: [0mTrain 36 1365
[32m[2022-06-16 11:36:35] __main__ INFO: [0mEpoch 36 Step 39/39 lr 0.100000 loss 1.3997 (1.5450) acc@1 0.4844 (0.4199) acc@5 0.9141 (0.9119)
[32m[2022-06-16 11:36:35] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:36:35] __main__ INFO: [0mVal 36
[32m[2022-06-16 11:36:36] __main__ INFO: [0mEpoch 36 loss 1.6755 acc@1 0.3987 acc@5 0.8856
[32m[2022-06-16 11:36:36] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:36:36] __main__ INFO: [0mTrain 37 1404
[32m[2022-06-16 11:36:38] __main__ INFO: [0mEpoch 37 Step 39/39 lr 0.100000 loss 1.5457 (1.4937) acc@1 0.4219 (0.4481) acc@5 0.9453 (0.9201)
[32m[2022-06-16 11:36:38] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:36:38] __main__ INFO: [0mVal 37
[32m[2022-06-16 11:36:38] __main__ INFO: [0mEpoch 37 loss 1.5326 acc@1 0.4393 acc@5 0.9148
[32m[2022-06-16 11:36:38] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:36:38] __main__ INFO: [0mTrain 38 1443
[32m[2022-06-16 11:36:40] __main__ INFO: [0mEpoch 38 Step 39/39 lr 0.100000 loss 1.5741 (1.4991) acc@1 0.3750 (0.4393) acc@5 0.9219 (0.9191)
[32m[2022-06-16 11:36:40] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:36:40] __main__ INFO: [0mVal 38
[32m[2022-06-16 11:36:41] __main__ INFO: [0mEpoch 38 loss 1.5839 acc@1 0.4225 acc@5 0.9040
[32m[2022-06-16 11:36:41] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:36:41] __main__ INFO: [0mTrain 39 1482
[32m[2022-06-16 11:36:42] __main__ INFO: [0mEpoch 39 Step 39/39 lr 0.100000 loss 1.4062 (1.4582) acc@1 0.4375 (0.4531) acc@5 0.9531 (0.9233)
[32m[2022-06-16 11:36:42] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:36:42] __main__ INFO: [0mVal 39
[32m[2022-06-16 11:36:43] __main__ INFO: [0mEpoch 39 loss 1.5653 acc@1 0.4323 acc@5 0.9037
[32m[2022-06-16 11:36:43] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:36:43] __main__ INFO: [0mTrain 40 1521
[32m[2022-06-16 11:36:45] __main__ INFO: [0mEpoch 40 Step 39/39 lr 0.100000 loss 1.5002 (1.4220) acc@1 0.4688 (0.4742) acc@5 0.8984 (0.9311)
[32m[2022-06-16 11:36:45] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:36:45] __main__ INFO: [0mVal 40
[32m[2022-06-16 11:36:46] __main__ INFO: [0mEpoch 40 loss 1.6099 acc@1 0.4397 acc@5 0.9039
[32m[2022-06-16 11:36:46] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:36:46] __main__ INFO: [0mTrain 41 1560
[32m[2022-06-16 11:36:47] __main__ INFO: [0mEpoch 41 Step 39/39 lr 0.100000 loss 1.2619 (1.3877) acc@1 0.5391 (0.4878) acc@5 0.9531 (0.9335)
[32m[2022-06-16 11:36:47] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:36:47] __main__ INFO: [0mVal 41
[32m[2022-06-16 11:36:48] __main__ INFO: [0mEpoch 41 loss 1.5032 acc@1 0.4513 acc@5 0.9168
[32m[2022-06-16 11:36:48] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:36:48] __main__ INFO: [0mTrain 42 1599
[32m[2022-06-16 11:36:50] __main__ INFO: [0mEpoch 42 Step 39/39 lr 0.100000 loss 1.2566 (1.3652) acc@1 0.5312 (0.4952) acc@5 0.9375 (0.9391)
[32m[2022-06-16 11:36:50] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:36:50] __main__ INFO: [0mVal 42
[32m[2022-06-16 11:36:50] __main__ INFO: [0mEpoch 42 loss 1.6255 acc@1 0.4388 acc@5 0.8973
[32m[2022-06-16 11:36:50] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:36:50] __main__ INFO: [0mTrain 43 1638
[32m[2022-06-16 11:36:52] __main__ INFO: [0mEpoch 43 Step 39/39 lr 0.100000 loss 1.2804 (1.3318) acc@1 0.5469 (0.5078) acc@5 0.9375 (0.9457)
[32m[2022-06-16 11:36:52] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:36:52] __main__ INFO: [0mVal 43
[32m[2022-06-16 11:36:53] __main__ INFO: [0mEpoch 43 loss 1.4142 acc@1 0.4945 acc@5 0.9325
[32m[2022-06-16 11:36:53] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:36:53] __main__ INFO: [0mTrain 44 1677
[32m[2022-06-16 11:36:54] __main__ INFO: [0mEpoch 44 Step 39/39 lr 0.100000 loss 1.3935 (1.3156) acc@1 0.5078 (0.5122) acc@5 0.9219 (0.9473)
[32m[2022-06-16 11:36:54] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:36:54] __main__ INFO: [0mVal 44
[32m[2022-06-16 11:36:55] __main__ INFO: [0mEpoch 44 loss 1.4485 acc@1 0.4875 acc@5 0.9302
[32m[2022-06-16 11:36:55] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:36:55] __main__ INFO: [0mTrain 45 1716
[32m[2022-06-16 11:36:57] __main__ INFO: [0mEpoch 45 Step 39/39 lr 0.100000 loss 1.3507 (1.2877) acc@1 0.5156 (0.5238) acc@5 0.9609 (0.9529)
[32m[2022-06-16 11:36:57] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:36:57] __main__ INFO: [0mVal 45
[32m[2022-06-16 11:36:58] __main__ INFO: [0mEpoch 45 loss 1.4495 acc@1 0.4791 acc@5 0.9262
[32m[2022-06-16 11:36:58] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:36:58] __main__ INFO: [0mTrain 46 1755
[32m[2022-06-16 11:36:59] __main__ INFO: [0mEpoch 46 Step 39/39 lr 0.100000 loss 1.2861 (1.2572) acc@1 0.5312 (0.5377) acc@5 0.9531 (0.9501)
[32m[2022-06-16 11:36:59] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:36:59] __main__ INFO: [0mVal 46
[32m[2022-06-16 11:37:00] __main__ INFO: [0mEpoch 46 loss 1.3964 acc@1 0.4998 acc@5 0.9307
[32m[2022-06-16 11:37:00] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:37:00] __main__ INFO: [0mTrain 47 1794
[32m[2022-06-16 11:37:02] __main__ INFO: [0mEpoch 47 Step 39/39 lr 0.100000 loss 1.1345 (1.2460) acc@1 0.5547 (0.5399) acc@5 0.9688 (0.9565)
[32m[2022-06-16 11:37:02] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:37:02] __main__ INFO: [0mVal 47
[32m[2022-06-16 11:37:03] __main__ INFO: [0mEpoch 47 loss 1.8098 acc@1 0.4507 acc@5 0.8780
[32m[2022-06-16 11:37:03] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:37:03] __main__ INFO: [0mTrain 48 1833
[32m[2022-06-16 11:37:04] __main__ INFO: [0mEpoch 48 Step 39/39 lr 0.100000 loss 1.2792 (1.2030) acc@1 0.5469 (0.5593) acc@5 0.9453 (0.9585)
[32m[2022-06-16 11:37:04] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:37:04] __main__ INFO: [0mVal 48
[32m[2022-06-16 11:37:05] __main__ INFO: [0mEpoch 48 loss 1.3419 acc@1 0.5250 acc@5 0.9396
[32m[2022-06-16 11:37:05] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:37:05] __main__ INFO: [0mTrain 49 1872
[32m[2022-06-16 11:37:07] __main__ INFO: [0mEpoch 49 Step 39/39 lr 0.100000 loss 1.3011 (1.1632) acc@1 0.4766 (0.5745) acc@5 0.9609 (0.9631)
[32m[2022-06-16 11:37:07] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:37:07] __main__ INFO: [0mVal 49
[32m[2022-06-16 11:37:08] __main__ INFO: [0mEpoch 49 loss 1.3387 acc@1 0.5234 acc@5 0.9362
[32m[2022-06-16 11:37:08] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:37:08] __main__ INFO: [0mTrain 50 1911
[32m[2022-06-16 11:37:09] __main__ INFO: [0mEpoch 50 Step 39/39 lr 0.100000 loss 1.2499 (1.1469) acc@1 0.5781 (0.5841) acc@5 0.9453 (0.9629)
[32m[2022-06-16 11:37:09] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:37:09] __main__ INFO: [0mVal 50
[32m[2022-06-16 11:37:10] __main__ INFO: [0mEpoch 50 loss 1.4296 acc@1 0.5052 acc@5 0.9313
[32m[2022-06-16 11:37:10] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:37:10] __main__ INFO: [0mTrain 51 1950
[32m[2022-06-16 11:37:11] __main__ INFO: [0mEpoch 51 Step 39/39 lr 0.100000 loss 1.1953 (1.1075) acc@1 0.5781 (0.6002) acc@5 0.9219 (0.9657)
[32m[2022-06-16 11:37:12] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:37:12] __main__ INFO: [0mVal 51
[32m[2022-06-16 11:37:12] __main__ INFO: [0mEpoch 51 loss 1.4752 acc@1 0.5016 acc@5 0.9236
[32m[2022-06-16 11:37:12] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:37:12] __main__ INFO: [0mTrain 52 1989
[32m[2022-06-16 11:37:14] __main__ INFO: [0mEpoch 52 Step 39/39 lr 0.100000 loss 1.0124 (1.0759) acc@1 0.6016 (0.6088) acc@5 0.9844 (0.9690)
[32m[2022-06-16 11:37:14] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:37:14] __main__ INFO: [0mVal 52
[32m[2022-06-16 11:37:15] __main__ INFO: [0mEpoch 52 loss 1.3263 acc@1 0.5437 acc@5 0.9404
[32m[2022-06-16 11:37:15] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:37:15] __main__ INFO: [0mTrain 53 2028
[32m[2022-06-16 11:37:16] __main__ INFO: [0mEpoch 53 Step 39/39 lr 0.100000 loss 1.1334 (1.0465) acc@1 0.5781 (0.6272) acc@5 0.9609 (0.9679)
[32m[2022-06-16 11:37:16] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:37:16] __main__ INFO: [0mVal 53
[32m[2022-06-16 11:37:17] __main__ INFO: [0mEpoch 53 loss 1.4032 acc@1 0.5321 acc@5 0.9410
[32m[2022-06-16 11:37:17] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:37:17] __main__ INFO: [0mTrain 54 2067
[32m[2022-06-16 11:37:19] __main__ INFO: [0mEpoch 54 Step 39/39 lr 0.100000 loss 1.1296 (1.0275) acc@1 0.5391 (0.6288) acc@5 0.9766 (0.9722)
[32m[2022-06-16 11:37:19] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:37:19] __main__ INFO: [0mVal 54
[32m[2022-06-16 11:37:19] __main__ INFO: [0mEpoch 54 loss 1.3635 acc@1 0.5452 acc@5 0.9419
[32m[2022-06-16 11:37:19] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:37:19] __main__ INFO: [0mTrain 55 2106
[32m[2022-06-16 11:37:21] __main__ INFO: [0mEpoch 55 Step 39/39 lr 0.100000 loss 0.9240 (1.0107) acc@1 0.6406 (0.6352) acc@5 0.9766 (0.9708)
[32m[2022-06-16 11:37:21] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:37:21] __main__ INFO: [0mVal 55
[32m[2022-06-16 11:37:22] __main__ INFO: [0mEpoch 55 loss 1.2438 acc@1 0.5806 acc@5 0.9506
[32m[2022-06-16 11:37:22] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:37:22] __main__ INFO: [0mTrain 56 2145
[32m[2022-06-16 11:37:23] __main__ INFO: [0mEpoch 56 Step 39/39 lr 0.100000 loss 1.0028 (0.9836) acc@1 0.6406 (0.6466) acc@5 0.9922 (0.9724)
[32m[2022-06-16 11:37:23] __main__ INFO: [0mElapsed 1.58
[32m[2022-06-16 11:37:23] __main__ INFO: [0mVal 56
[32m[2022-06-16 11:37:24] __main__ INFO: [0mEpoch 56 loss 1.3644 acc@1 0.5500 acc@5 0.9419
[32m[2022-06-16 11:37:24] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:37:24] __main__ INFO: [0mTrain 57 2184
[32m[2022-06-16 11:37:26] __main__ INFO: [0mEpoch 57 Step 39/39 lr 0.100000 loss 1.1710 (0.9598) acc@1 0.5938 (0.6536) acc@5 0.9453 (0.9740)
[32m[2022-06-16 11:37:26] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:37:26] __main__ INFO: [0mVal 57
[32m[2022-06-16 11:37:27] __main__ INFO: [0mEpoch 57 loss 1.3037 acc@1 0.5608 acc@5 0.9466
[32m[2022-06-16 11:37:27] __main__ INFO: [0mElapsed 0.66
[32m[2022-06-16 11:37:27] __main__ INFO: [0mTrain 58 2223
[32m[2022-06-16 11:37:28] __main__ INFO: [0mEpoch 58 Step 39/39 lr 0.100000 loss 0.9098 (0.9462) acc@1 0.6875 (0.6607) acc@5 0.9766 (0.9764)
[32m[2022-06-16 11:37:28] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:37:28] __main__ INFO: [0mVal 58
[32m[2022-06-16 11:37:29] __main__ INFO: [0mEpoch 58 loss 1.5470 acc@1 0.5318 acc@5 0.9360
[32m[2022-06-16 11:37:29] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:37:29] __main__ INFO: [0mTrain 59 2262
[32m[2022-06-16 11:37:31] __main__ INFO: [0mEpoch 59 Step 39/39 lr 0.100000 loss 1.0146 (0.9143) acc@1 0.5859 (0.6665) acc@5 0.9766 (0.9764)
[32m[2022-06-16 11:37:31] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:37:31] __main__ INFO: [0mVal 59
[32m[2022-06-16 11:37:31] __main__ INFO: [0mEpoch 59 loss 1.2876 acc@1 0.5617 acc@5 0.9485
[32m[2022-06-16 11:37:31] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:37:31] __main__ INFO: [0mTrain 60 2301
[32m[2022-06-16 11:37:33] __main__ INFO: [0mEpoch 60 Step 39/39 lr 0.100000 loss 0.9098 (0.8880) acc@1 0.6797 (0.6819) acc@5 0.9922 (0.9776)
[32m[2022-06-16 11:37:33] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:37:33] __main__ INFO: [0mVal 60
[32m[2022-06-16 11:37:34] __main__ INFO: [0mEpoch 60 loss 1.5272 acc@1 0.5417 acc@5 0.9352
[32m[2022-06-16 11:37:34] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:37:34] __main__ INFO: [0mTrain 61 2340
[32m[2022-06-16 11:37:36] __main__ INFO: [0mEpoch 61 Step 39/39 lr 0.100000 loss 0.8847 (0.8735) acc@1 0.6641 (0.6899) acc@5 0.9766 (0.9798)
[32m[2022-06-16 11:37:36] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:37:36] __main__ INFO: [0mVal 61
[32m[2022-06-16 11:37:36] __main__ INFO: [0mEpoch 61 loss 1.3913 acc@1 0.5581 acc@5 0.9447
[32m[2022-06-16 11:37:36] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:37:36] __main__ INFO: [0mTrain 62 2379
[32m[2022-06-16 11:37:38] __main__ INFO: [0mEpoch 62 Step 39/39 lr 0.100000 loss 0.8202 (0.8590) acc@1 0.6953 (0.6951) acc@5 1.0000 (0.9788)
[32m[2022-06-16 11:37:38] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:37:38] __main__ INFO: [0mVal 62
[32m[2022-06-16 11:37:39] __main__ INFO: [0mEpoch 62 loss 1.3083 acc@1 0.5762 acc@5 0.9524
[32m[2022-06-16 11:37:39] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:37:39] __main__ INFO: [0mTrain 63 2418
[32m[2022-06-16 11:37:40] __main__ INFO: [0mEpoch 63 Step 39/39 lr 0.100000 loss 0.7913 (0.8362) acc@1 0.7500 (0.6963) acc@5 0.9844 (0.9814)
[32m[2022-06-16 11:37:40] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:37:40] __main__ INFO: [0mVal 63
[32m[2022-06-16 11:37:41] __main__ INFO: [0mEpoch 63 loss 1.4095 acc@1 0.5470 acc@5 0.9477
[32m[2022-06-16 11:37:41] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:37:41] __main__ INFO: [0mTrain 64 2457
[32m[2022-06-16 11:37:43] __main__ INFO: [0mEpoch 64 Step 39/39 lr 0.100000 loss 0.8182 (0.8076) acc@1 0.6875 (0.7101) acc@5 0.9922 (0.9820)
[32m[2022-06-16 11:37:43] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:37:43] __main__ INFO: [0mVal 64
[32m[2022-06-16 11:37:44] __main__ INFO: [0mEpoch 64 loss 1.3006 acc@1 0.5827 acc@5 0.9536
[32m[2022-06-16 11:37:44] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:37:44] __main__ INFO: [0mTrain 65 2496
[32m[2022-06-16 11:37:45] __main__ INFO: [0mEpoch 65 Step 39/39 lr 0.100000 loss 0.6934 (0.7944) acc@1 0.7891 (0.7194) acc@5 0.9766 (0.9836)
[32m[2022-06-16 11:37:45] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:37:45] __main__ INFO: [0mVal 65
[32m[2022-06-16 11:37:46] __main__ INFO: [0mEpoch 65 loss 1.6110 acc@1 0.5320 acc@5 0.9272
[32m[2022-06-16 11:37:46] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:37:46] __main__ INFO: [0mTrain 66 2535
[32m[2022-06-16 11:37:48] __main__ INFO: [0mEpoch 66 Step 39/39 lr 0.100000 loss 0.5765 (0.7586) acc@1 0.7812 (0.7266) acc@5 0.9922 (0.9848)
[32m[2022-06-16 11:37:48] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:37:48] __main__ INFO: [0mVal 66
[32m[2022-06-16 11:37:48] __main__ INFO: [0mEpoch 66 loss 1.3768 acc@1 0.5880 acc@5 0.9503
[32m[2022-06-16 11:37:48] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:37:48] __main__ INFO: [0mTrain 67 2574
[32m[2022-06-16 11:37:50] __main__ INFO: [0mEpoch 67 Step 39/39 lr 0.100000 loss 0.7164 (0.7501) acc@1 0.7266 (0.7210) acc@5 0.9844 (0.9880)
[32m[2022-06-16 11:37:50] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:37:50] __main__ INFO: [0mVal 67
[32m[2022-06-16 11:37:51] __main__ INFO: [0mEpoch 67 loss 1.2747 acc@1 0.5918 acc@5 0.9593
[32m[2022-06-16 11:37:51] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:37:51] __main__ INFO: [0mTrain 68 2613
[32m[2022-06-16 11:37:53] __main__ INFO: [0mEpoch 68 Step 39/39 lr 0.100000 loss 0.8606 (0.7477) acc@1 0.7422 (0.7330) acc@5 0.9844 (0.9854)
[32m[2022-06-16 11:37:53] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:37:53] __main__ INFO: [0mVal 68
[32m[2022-06-16 11:37:53] __main__ INFO: [0mEpoch 68 loss 1.5259 acc@1 0.5686 acc@5 0.9471
[32m[2022-06-16 11:37:53] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:37:53] __main__ INFO: [0mTrain 69 2652
[32m[2022-06-16 11:37:55] __main__ INFO: [0mEpoch 69 Step 39/39 lr 0.100000 loss 0.7814 (0.7151) acc@1 0.7188 (0.7422) acc@5 0.9844 (0.9862)
[32m[2022-06-16 11:37:55] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:37:55] __main__ INFO: [0mVal 69
[32m[2022-06-16 11:37:56] __main__ INFO: [0mEpoch 69 loss 1.3429 acc@1 0.5856 acc@5 0.9489
[32m[2022-06-16 11:37:56] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:37:56] __main__ INFO: [0mTrain 70 2691
[32m[2022-06-16 11:37:57] __main__ INFO: [0mEpoch 70 Step 39/39 lr 0.100000 loss 0.6295 (0.7125) acc@1 0.7344 (0.7454) acc@5 1.0000 (0.9858)
[32m[2022-06-16 11:37:57] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:37:57] __main__ INFO: [0mVal 70
[32m[2022-06-16 11:37:58] __main__ INFO: [0mEpoch 70 loss 1.2900 acc@1 0.5980 acc@5 0.9558
[32m[2022-06-16 11:37:58] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:37:58] __main__ INFO: [0mTrain 71 2730
[32m[2022-06-16 11:38:00] __main__ INFO: [0mEpoch 71 Step 39/39 lr 0.100000 loss 0.8257 (0.6938) acc@1 0.7266 (0.7508) acc@5 1.0000 (0.9878)
[32m[2022-06-16 11:38:00] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:38:00] __main__ INFO: [0mVal 71
[32m[2022-06-16 11:38:01] __main__ INFO: [0mEpoch 71 loss 1.2331 acc@1 0.6176 acc@5 0.9575
[32m[2022-06-16 11:38:01] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-16 11:38:01] __main__ INFO: [0mTrain 72 2769
[32m[2022-06-16 11:38:02] __main__ INFO: [0mEpoch 72 Step 39/39 lr 0.100000 loss 0.7164 (0.6874) acc@1 0.7422 (0.7530) acc@5 0.9844 (0.9882)
[32m[2022-06-16 11:38:02] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:38:02] __main__ INFO: [0mVal 72
[32m[2022-06-16 11:38:03] __main__ INFO: [0mEpoch 72 loss 1.2880 acc@1 0.6076 acc@5 0.9542
[32m[2022-06-16 11:38:03] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:38:03] __main__ INFO: [0mTrain 73 2808
[32m[2022-06-16 11:38:05] __main__ INFO: [0mEpoch 73 Step 39/39 lr 0.100000 loss 0.8354 (0.6446) acc@1 0.6953 (0.7686) acc@5 0.9766 (0.9876)
[32m[2022-06-16 11:38:05] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:38:05] __main__ INFO: [0mVal 73
[32m[2022-06-16 11:38:06] __main__ INFO: [0mEpoch 73 loss 1.6240 acc@1 0.5496 acc@5 0.9445
[32m[2022-06-16 11:38:06] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:38:06] __main__ INFO: [0mTrain 74 2847
[32m[2022-06-16 11:38:07] __main__ INFO: [0mEpoch 74 Step 39/39 lr 0.100000 loss 0.6354 (0.6461) acc@1 0.7656 (0.7670) acc@5 0.9922 (0.9898)
[32m[2022-06-16 11:38:07] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:38:07] __main__ INFO: [0mVal 74
[32m[2022-06-16 11:38:08] __main__ INFO: [0mEpoch 74 loss 1.3034 acc@1 0.6035 acc@5 0.9581
[32m[2022-06-16 11:38:08] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:38:08] __main__ INFO: [0mTrain 75 2886
[32m[2022-06-16 11:38:10] __main__ INFO: [0mEpoch 75 Step 39/39 lr 0.100000 loss 0.5871 (0.6145) acc@1 0.7422 (0.7732) acc@5 1.0000 (0.9918)
[32m[2022-06-16 11:38:10] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:38:10] __main__ INFO: [0mVal 75
[32m[2022-06-16 11:38:10] __main__ INFO: [0mEpoch 75 loss 1.3189 acc@1 0.6196 acc@5 0.9593
[32m[2022-06-16 11:38:10] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:38:10] __main__ INFO: [0mTrain 76 2925
[32m[2022-06-16 11:38:12] __main__ INFO: [0mEpoch 76 Step 39/39 lr 0.100000 loss 0.7832 (0.6174) acc@1 0.7344 (0.7780) acc@5 0.9922 (0.9930)
[32m[2022-06-16 11:38:12] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:38:12] __main__ INFO: [0mVal 76
[32m[2022-06-16 11:38:13] __main__ INFO: [0mEpoch 76 loss 1.4064 acc@1 0.5961 acc@5 0.9559
[32m[2022-06-16 11:38:13] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:38:13] __main__ INFO: [0mTrain 77 2964
[32m[2022-06-16 11:38:14] __main__ INFO: [0mEpoch 77 Step 39/39 lr 0.100000 loss 0.5921 (0.6143) acc@1 0.7578 (0.7857) acc@5 1.0000 (0.9906)
[32m[2022-06-16 11:38:14] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:38:14] __main__ INFO: [0mVal 77
[32m[2022-06-16 11:38:15] __main__ INFO: [0mEpoch 77 loss 1.3390 acc@1 0.6068 acc@5 0.9611
[32m[2022-06-16 11:38:15] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:38:15] __main__ INFO: [0mTrain 78 3003
[32m[2022-06-16 11:38:17] __main__ INFO: [0mEpoch 78 Step 39/39 lr 0.100000 loss 0.5971 (0.5585) acc@1 0.7656 (0.7999) acc@5 0.9922 (0.9926)
[32m[2022-06-16 11:38:17] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:38:17] __main__ INFO: [0mVal 78
[32m[2022-06-16 11:38:18] __main__ INFO: [0mEpoch 78 loss 1.4221 acc@1 0.6073 acc@5 0.9536
[32m[2022-06-16 11:38:18] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:38:18] __main__ INFO: [0mTrain 79 3042
[32m[2022-06-16 11:38:19] __main__ INFO: [0mEpoch 79 Step 39/39 lr 0.100000 loss 0.6637 (0.5337) acc@1 0.7578 (0.8037) acc@5 0.9844 (0.9930)
[32m[2022-06-16 11:38:19] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:38:19] __main__ INFO: [0mVal 79
[32m[2022-06-16 11:38:20] __main__ INFO: [0mEpoch 79 loss 1.2696 acc@1 0.6323 acc@5 0.9605
[32m[2022-06-16 11:38:20] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-16 11:38:20] __main__ INFO: [0mTrain 80 3081
[32m[2022-06-16 11:38:22] __main__ INFO: [0mEpoch 80 Step 39/39 lr 0.100000 loss 0.5369 (0.5473) acc@1 0.8281 (0.8037) acc@5 0.9922 (0.9938)
[32m[2022-06-16 11:38:22] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:38:22] __main__ INFO: [0mVal 80
[32m[2022-06-16 11:38:22] __main__ INFO: [0mEpoch 80 loss 1.5722 acc@1 0.5771 acc@5 0.9443
[32m[2022-06-16 11:38:22] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:38:22] __main__ INFO: [0mTrain 81 3120
[32m[2022-06-16 11:38:24] __main__ INFO: [0mEpoch 81 Step 39/39 lr 0.010000 loss 0.4722 (0.4518) acc@1 0.8047 (0.8431) acc@5 0.9922 (0.9948)
[32m[2022-06-16 11:38:24] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:38:24] __main__ INFO: [0mVal 81
[32m[2022-06-16 11:38:25] __main__ INFO: [0mEpoch 81 loss 1.1671 acc@1 0.6661 acc@5 0.9686
[32m[2022-06-16 11:38:25] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:38:25] __main__ INFO: [0mTrain 82 3159
[32m[2022-06-16 11:38:26] __main__ INFO: [0mEpoch 82 Step 39/39 lr 0.010000 loss 0.3196 (0.3508) acc@1 0.8750 (0.8814) acc@5 1.0000 (0.9966)
[32m[2022-06-16 11:38:27] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:38:27] __main__ INFO: [0mVal 82
[32m[2022-06-16 11:38:27] __main__ INFO: [0mEpoch 82 loss 1.1749 acc@1 0.6666 acc@5 0.9691
[32m[2022-06-16 11:38:27] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:38:27] __main__ INFO: [0mTrain 83 3198
[32m[2022-06-16 11:38:29] __main__ INFO: [0mEpoch 83 Step 39/39 lr 0.010000 loss 0.2929 (0.3249) acc@1 0.9062 (0.8886) acc@5 1.0000 (0.9988)
[32m[2022-06-16 11:38:29] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:38:29] __main__ INFO: [0mVal 83
[32m[2022-06-16 11:38:30] __main__ INFO: [0mEpoch 83 loss 1.1958 acc@1 0.6649 acc@5 0.9679
[32m[2022-06-16 11:38:30] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:38:30] __main__ INFO: [0mTrain 84 3237
[32m[2022-06-16 11:38:31] __main__ INFO: [0mEpoch 84 Step 39/39 lr 0.010000 loss 0.3361 (0.3074) acc@1 0.8984 (0.8954) acc@5 1.0000 (0.9986)
[32m[2022-06-16 11:38:31] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:38:31] __main__ INFO: [0mVal 84
[32m[2022-06-16 11:38:32] __main__ INFO: [0mEpoch 84 loss 1.2115 acc@1 0.6674 acc@5 0.9676
[32m[2022-06-16 11:38:32] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:38:32] __main__ INFO: [0mTrain 85 3276
[32m[2022-06-16 11:38:34] __main__ INFO: [0mEpoch 85 Step 39/39 lr 0.010000 loss 0.2346 (0.2880) acc@1 0.8984 (0.9026) acc@5 1.0000 (0.9986)
[32m[2022-06-16 11:38:34] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:38:34] __main__ INFO: [0mVal 85
[32m[2022-06-16 11:38:35] __main__ INFO: [0mEpoch 85 loss 1.2412 acc@1 0.6623 acc@5 0.9667
[32m[2022-06-16 11:38:35] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:38:35] __main__ INFO: [0mTrain 86 3315
[32m[2022-06-16 11:38:36] __main__ INFO: [0mEpoch 86 Step 39/39 lr 0.010000 loss 0.2856 (0.2709) acc@1 0.9062 (0.9087) acc@5 0.9922 (0.9986)
[32m[2022-06-16 11:38:36] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:38:36] __main__ INFO: [0mVal 86
[32m[2022-06-16 11:38:37] __main__ INFO: [0mEpoch 86 loss 1.2519 acc@1 0.6617 acc@5 0.9674
[32m[2022-06-16 11:38:37] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:38:37] __main__ INFO: [0mTrain 87 3354
[32m[2022-06-16 11:38:39] __main__ INFO: [0mEpoch 87 Step 39/39 lr 0.010000 loss 0.2271 (0.2592) acc@1 0.9141 (0.9079) acc@5 1.0000 (0.9984)
[32m[2022-06-16 11:38:39] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:38:39] __main__ INFO: [0mVal 87
[32m[2022-06-16 11:38:40] __main__ INFO: [0mEpoch 87 loss 1.2806 acc@1 0.6629 acc@5 0.9688
[32m[2022-06-16 11:38:40] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:38:40] __main__ INFO: [0mTrain 88 3393
[32m[2022-06-16 11:38:41] __main__ INFO: [0mEpoch 88 Step 39/39 lr 0.010000 loss 0.2282 (0.2573) acc@1 0.9297 (0.9111) acc@5 1.0000 (0.9988)
[32m[2022-06-16 11:38:41] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:38:41] __main__ INFO: [0mVal 88
[32m[2022-06-16 11:38:42] __main__ INFO: [0mEpoch 88 loss 1.2834 acc@1 0.6624 acc@5 0.9676
[32m[2022-06-16 11:38:42] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:38:42] __main__ INFO: [0mTrain 89 3432
[32m[2022-06-16 11:38:43] __main__ INFO: [0mEpoch 89 Step 39/39 lr 0.010000 loss 0.2683 (0.2532) acc@1 0.9219 (0.9141) acc@5 0.9922 (0.9984)
[32m[2022-06-16 11:38:44] __main__ INFO: [0mElapsed 1.52
[32m[2022-06-16 11:38:44] __main__ INFO: [0mVal 89
[32m[2022-06-16 11:38:44] __main__ INFO: [0mEpoch 89 loss 1.2930 acc@1 0.6652 acc@5 0.9677
[32m[2022-06-16 11:38:44] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:38:44] __main__ INFO: [0mTrain 90 3471
[32m[2022-06-16 11:38:46] __main__ INFO: [0mEpoch 90 Step 39/39 lr 0.010000 loss 0.2990 (0.2342) acc@1 0.9219 (0.9239) acc@5 0.9922 (0.9990)
[32m[2022-06-16 11:38:46] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:38:46] __main__ INFO: [0mVal 90
[32m[2022-06-16 11:38:47] __main__ INFO: [0mEpoch 90 loss 1.3379 acc@1 0.6637 acc@5 0.9665
[32m[2022-06-16 11:38:47] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:38:47] __main__ INFO: [0mTrain 91 3510
[32m[2022-06-16 11:38:48] __main__ INFO: [0mEpoch 91 Step 39/39 lr 0.010000 loss 0.1627 (0.2291) acc@1 0.9531 (0.9219) acc@5 1.0000 (0.9992)
[32m[2022-06-16 11:38:48] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:38:48] __main__ INFO: [0mVal 91
[32m[2022-06-16 11:38:49] __main__ INFO: [0mEpoch 91 loss 1.3242 acc@1 0.6655 acc@5 0.9651
[32m[2022-06-16 11:38:49] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:38:49] __main__ INFO: [0mTrain 92 3549
[32m[2022-06-16 11:38:51] __main__ INFO: [0mEpoch 92 Step 39/39 lr 0.010000 loss 0.1924 (0.2338) acc@1 0.9375 (0.9217) acc@5 1.0000 (0.9994)
[32m[2022-06-16 11:38:51] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:38:51] __main__ INFO: [0mVal 92
[32m[2022-06-16 11:38:52] __main__ INFO: [0mEpoch 92 loss 1.3628 acc@1 0.6619 acc@5 0.9655
[32m[2022-06-16 11:38:52] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:38:52] __main__ INFO: [0mTrain 93 3588
[32m[2022-06-16 11:38:53] __main__ INFO: [0mEpoch 93 Step 39/39 lr 0.010000 loss 0.2654 (0.2180) acc@1 0.8672 (0.9277) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:38:53] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:38:53] __main__ INFO: [0mVal 93
[32m[2022-06-16 11:38:54] __main__ INFO: [0mEpoch 93 loss 1.3606 acc@1 0.6624 acc@5 0.9674
[32m[2022-06-16 11:38:54] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:38:54] __main__ INFO: [0mTrain 94 3627
[32m[2022-06-16 11:38:56] __main__ INFO: [0mEpoch 94 Step 39/39 lr 0.010000 loss 0.2002 (0.2140) acc@1 0.9453 (0.9285) acc@5 1.0000 (0.9988)
[32m[2022-06-16 11:38:56] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:38:56] __main__ INFO: [0mVal 94
[32m[2022-06-16 11:38:56] __main__ INFO: [0mEpoch 94 loss 1.3732 acc@1 0.6652 acc@5 0.9650
[32m[2022-06-16 11:38:56] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:38:57] __main__ INFO: [0mTrain 95 3666
[32m[2022-06-16 11:38:58] __main__ INFO: [0mEpoch 95 Step 39/39 lr 0.010000 loss 0.2367 (0.2039) acc@1 0.9219 (0.9299) acc@5 1.0000 (0.9994)
[32m[2022-06-16 11:38:58] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:38:58] __main__ INFO: [0mVal 95
[32m[2022-06-16 11:38:59] __main__ INFO: [0mEpoch 95 loss 1.3953 acc@1 0.6607 acc@5 0.9652
[32m[2022-06-16 11:38:59] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:38:59] __main__ INFO: [0mTrain 96 3705
[32m[2022-06-16 11:39:01] __main__ INFO: [0mEpoch 96 Step 39/39 lr 0.010000 loss 0.1537 (0.2030) acc@1 0.9453 (0.9265) acc@5 1.0000 (0.9994)
[32m[2022-06-16 11:39:01] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:39:01] __main__ INFO: [0mVal 96
[32m[2022-06-16 11:39:02] __main__ INFO: [0mEpoch 96 loss 1.4260 acc@1 0.6568 acc@5 0.9658
[32m[2022-06-16 11:39:02] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:39:02] __main__ INFO: [0mTrain 97 3744
[32m[2022-06-16 11:39:03] __main__ INFO: [0mEpoch 97 Step 39/39 lr 0.010000 loss 0.2042 (0.1990) acc@1 0.9375 (0.9331) acc@5 1.0000 (0.9992)
[32m[2022-06-16 11:39:03] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:39:03] __main__ INFO: [0mVal 97
[32m[2022-06-16 11:39:04] __main__ INFO: [0mEpoch 97 loss 1.4113 acc@1 0.6611 acc@5 0.9660
[32m[2022-06-16 11:39:04] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:39:04] __main__ INFO: [0mTrain 98 3783
[32m[2022-06-16 11:39:06] __main__ INFO: [0mEpoch 98 Step 39/39 lr 0.010000 loss 0.1835 (0.1898) acc@1 0.9297 (0.9329) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:39:06] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:39:06] __main__ INFO: [0mVal 98
[32m[2022-06-16 11:39:06] __main__ INFO: [0mEpoch 98 loss 1.4561 acc@1 0.6595 acc@5 0.9656
[32m[2022-06-16 11:39:06] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:39:06] __main__ INFO: [0mTrain 99 3822
[32m[2022-06-16 11:39:08] __main__ INFO: [0mEpoch 99 Step 39/39 lr 0.010000 loss 0.2236 (0.1792) acc@1 0.9219 (0.9401) acc@5 1.0000 (0.9994)
[32m[2022-06-16 11:39:08] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:39:08] __main__ INFO: [0mVal 99
[32m[2022-06-16 11:39:09] __main__ INFO: [0mEpoch 99 loss 1.4901 acc@1 0.6564 acc@5 0.9646
[32m[2022-06-16 11:39:09] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:39:09] __main__ INFO: [0mTrain 100 3861
[32m[2022-06-16 11:39:10] __main__ INFO: [0mEpoch 100 Step 39/39 lr 0.010000 loss 0.1820 (0.1814) acc@1 0.9609 (0.9379) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:10] __main__ INFO: [0mElapsed 1.58
[32m[2022-06-16 11:39:10] __main__ INFO: [0mVal 100
[32m[2022-06-16 11:39:11] __main__ INFO: [0mEpoch 100 loss 1.4952 acc@1 0.6579 acc@5 0.9651
[32m[2022-06-16 11:39:11] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:39:11] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00100.pth
[32m[2022-06-16 11:39:11] __main__ INFO: [0mTrain 101 3900
[32m[2022-06-16 11:39:13] __main__ INFO: [0mEpoch 101 Step 39/39 lr 0.010000 loss 0.2718 (0.1858) acc@1 0.9141 (0.9333) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:13] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:39:13] __main__ INFO: [0mVal 101
[32m[2022-06-16 11:39:14] __main__ INFO: [0mEpoch 101 loss 1.4956 acc@1 0.6582 acc@5 0.9646
[32m[2022-06-16 11:39:14] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-16 11:39:14] __main__ INFO: [0mTrain 102 3939
[32m[2022-06-16 11:39:15] __main__ INFO: [0mEpoch 102 Step 39/39 lr 0.010000 loss 0.2194 (0.1723) acc@1 0.9141 (0.9379) acc@5 1.0000 (0.9994)
[32m[2022-06-16 11:39:15] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:39:15] __main__ INFO: [0mVal 102
[32m[2022-06-16 11:39:16] __main__ INFO: [0mEpoch 102 loss 1.5142 acc@1 0.6570 acc@5 0.9665
[32m[2022-06-16 11:39:16] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:39:16] __main__ INFO: [0mTrain 103 3978
[32m[2022-06-16 11:39:18] __main__ INFO: [0mEpoch 103 Step 39/39 lr 0.010000 loss 0.2575 (0.1648) acc@1 0.8906 (0.9473) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:18] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:39:18] __main__ INFO: [0mVal 103
[32m[2022-06-16 11:39:19] __main__ INFO: [0mEpoch 103 loss 1.5183 acc@1 0.6563 acc@5 0.9657
[32m[2022-06-16 11:39:19] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:39:19] __main__ INFO: [0mTrain 104 4017
[32m[2022-06-16 11:39:20] __main__ INFO: [0mEpoch 104 Step 39/39 lr 0.010000 loss 0.1093 (0.1555) acc@1 0.9844 (0.9505) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:39:20] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:39:20] __main__ INFO: [0mVal 104
[32m[2022-06-16 11:39:21] __main__ INFO: [0mEpoch 104 loss 1.5485 acc@1 0.6524 acc@5 0.9643
[32m[2022-06-16 11:39:21] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:39:21] __main__ INFO: [0mTrain 105 4056
[32m[2022-06-16 11:39:23] __main__ INFO: [0mEpoch 105 Step 39/39 lr 0.010000 loss 0.0965 (0.1536) acc@1 0.9609 (0.9497) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:23] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:39:23] __main__ INFO: [0mVal 105
[32m[2022-06-16 11:39:23] __main__ INFO: [0mEpoch 105 loss 1.5531 acc@1 0.6587 acc@5 0.9657
[32m[2022-06-16 11:39:23] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:39:23] __main__ INFO: [0mTrain 106 4095
[32m[2022-06-16 11:39:25] __main__ INFO: [0mEpoch 106 Step 39/39 lr 0.010000 loss 0.1863 (0.1436) acc@1 0.9219 (0.9517) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:25] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:39:25] __main__ INFO: [0mVal 106
[32m[2022-06-16 11:39:26] __main__ INFO: [0mEpoch 106 loss 1.5713 acc@1 0.6527 acc@5 0.9649
[32m[2022-06-16 11:39:26] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:39:26] __main__ INFO: [0mTrain 107 4134
[32m[2022-06-16 11:39:27] __main__ INFO: [0mEpoch 107 Step 39/39 lr 0.010000 loss 0.1604 (0.1468) acc@1 0.9297 (0.9539) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:39:27] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:39:27] __main__ INFO: [0mVal 107
[32m[2022-06-16 11:39:28] __main__ INFO: [0mEpoch 107 loss 1.5850 acc@1 0.6551 acc@5 0.9656
[32m[2022-06-16 11:39:28] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:39:28] __main__ INFO: [0mTrain 108 4173
[32m[2022-06-16 11:39:30] __main__ INFO: [0mEpoch 108 Step 39/39 lr 0.010000 loss 0.1439 (0.1437) acc@1 0.9609 (0.9549) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:39:30] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:39:30] __main__ INFO: [0mVal 108
[32m[2022-06-16 11:39:31] __main__ INFO: [0mEpoch 108 loss 1.6021 acc@1 0.6577 acc@5 0.9657
[32m[2022-06-16 11:39:31] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:39:31] __main__ INFO: [0mTrain 109 4212
[32m[2022-06-16 11:39:32] __main__ INFO: [0mEpoch 109 Step 39/39 lr 0.010000 loss 0.1607 (0.1394) acc@1 0.9297 (0.9545) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:32] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:39:32] __main__ INFO: [0mVal 109
[32m[2022-06-16 11:39:33] __main__ INFO: [0mEpoch 109 loss 1.6284 acc@1 0.6565 acc@5 0.9634
[32m[2022-06-16 11:39:33] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:39:33] __main__ INFO: [0mTrain 110 4251
[32m[2022-06-16 11:39:34] __main__ INFO: [0mEpoch 110 Step 39/39 lr 0.010000 loss 0.1373 (0.1391) acc@1 0.9453 (0.9489) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:35] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:39:35] __main__ INFO: [0mVal 110
[32m[2022-06-16 11:39:35] __main__ INFO: [0mEpoch 110 loss 1.6310 acc@1 0.6536 acc@5 0.9636
[32m[2022-06-16 11:39:35] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:39:35] __main__ INFO: [0mTrain 111 4290
[32m[2022-06-16 11:39:37] __main__ INFO: [0mEpoch 111 Step 39/39 lr 0.010000 loss 0.0954 (0.1394) acc@1 0.9609 (0.9509) acc@5 1.0000 (0.9996)
[32m[2022-06-16 11:39:37] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:39:37] __main__ INFO: [0mVal 111
[32m[2022-06-16 11:39:38] __main__ INFO: [0mEpoch 111 loss 1.6144 acc@1 0.6526 acc@5 0.9653
[32m[2022-06-16 11:39:38] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:39:38] __main__ INFO: [0mTrain 112 4329
[32m[2022-06-16 11:39:39] __main__ INFO: [0mEpoch 112 Step 39/39 lr 0.010000 loss 0.1707 (0.1193) acc@1 0.9375 (0.9607) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:39] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:39:39] __main__ INFO: [0mVal 112
[32m[2022-06-16 11:39:40] __main__ INFO: [0mEpoch 112 loss 1.6728 acc@1 0.6551 acc@5 0.9659
[32m[2022-06-16 11:39:40] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:39:40] __main__ INFO: [0mTrain 113 4368
[32m[2022-06-16 11:39:42] __main__ INFO: [0mEpoch 113 Step 39/39 lr 0.010000 loss 0.1429 (0.1233) acc@1 0.9297 (0.9595) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:42] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:39:42] __main__ INFO: [0mVal 113
[32m[2022-06-16 11:39:43] __main__ INFO: [0mEpoch 113 loss 1.6784 acc@1 0.6496 acc@5 0.9651
[32m[2022-06-16 11:39:43] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:39:43] __main__ INFO: [0mTrain 114 4407
[32m[2022-06-16 11:39:44] __main__ INFO: [0mEpoch 114 Step 39/39 lr 0.010000 loss 0.1541 (0.1202) acc@1 0.9531 (0.9603) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:44] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:39:44] __main__ INFO: [0mVal 114
[32m[2022-06-16 11:39:45] __main__ INFO: [0mEpoch 114 loss 1.6956 acc@1 0.6539 acc@5 0.9637
[32m[2022-06-16 11:39:45] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:39:45] __main__ INFO: [0mTrain 115 4446
[32m[2022-06-16 11:39:47] __main__ INFO: [0mEpoch 115 Step 39/39 lr 0.010000 loss 0.1677 (0.1158) acc@1 0.9375 (0.9635) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:47] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:39:47] __main__ INFO: [0mVal 115
[32m[2022-06-16 11:39:48] __main__ INFO: [0mEpoch 115 loss 1.6785 acc@1 0.6529 acc@5 0.9659
[32m[2022-06-16 11:39:48] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:39:48] __main__ INFO: [0mTrain 116 4485
[32m[2022-06-16 11:39:49] __main__ INFO: [0mEpoch 116 Step 39/39 lr 0.010000 loss 0.1350 (0.1231) acc@1 0.9688 (0.9607) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:49] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:39:49] __main__ INFO: [0mVal 116
[32m[2022-06-16 11:39:50] __main__ INFO: [0mEpoch 116 loss 1.7096 acc@1 0.6551 acc@5 0.9640
[32m[2022-06-16 11:39:50] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:39:50] __main__ INFO: [0mTrain 117 4524
[32m[2022-06-16 11:39:52] __main__ INFO: [0mEpoch 117 Step 39/39 lr 0.010000 loss 0.2274 (0.1222) acc@1 0.9062 (0.9593) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:52] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:39:52] __main__ INFO: [0mVal 117
[32m[2022-06-16 11:39:52] __main__ INFO: [0mEpoch 117 loss 1.6931 acc@1 0.6531 acc@5 0.9659
[32m[2022-06-16 11:39:52] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:39:52] __main__ INFO: [0mTrain 118 4563
[32m[2022-06-16 11:39:54] __main__ INFO: [0mEpoch 118 Step 39/39 lr 0.010000 loss 0.1064 (0.1100) acc@1 0.9688 (0.9621) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:54] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:39:54] __main__ INFO: [0mVal 118
[32m[2022-06-16 11:39:55] __main__ INFO: [0mEpoch 118 loss 1.7889 acc@1 0.6448 acc@5 0.9637
[32m[2022-06-16 11:39:55] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:39:55] __main__ INFO: [0mTrain 119 4602
[32m[2022-06-16 11:39:56] __main__ INFO: [0mEpoch 119 Step 39/39 lr 0.010000 loss 0.1607 (0.1090) acc@1 0.9297 (0.9677) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:39:56] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:39:56] __main__ INFO: [0mVal 119
[32m[2022-06-16 11:39:57] __main__ INFO: [0mEpoch 119 loss 1.7058 acc@1 0.6552 acc@5 0.9651
[32m[2022-06-16 11:39:57] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:39:57] __main__ INFO: [0mTrain 120 4641
[32m[2022-06-16 11:39:59] __main__ INFO: [0mEpoch 120 Step 39/39 lr 0.010000 loss 0.1166 (0.1089) acc@1 0.9609 (0.9653) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:39:59] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:39:59] __main__ INFO: [0mVal 120
[32m[2022-06-16 11:40:00] __main__ INFO: [0mEpoch 120 loss 1.7577 acc@1 0.6556 acc@5 0.9639
[32m[2022-06-16 11:40:00] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:40:00] __main__ INFO: [0mTrain 121 4680
[32m[2022-06-16 11:40:01] __main__ INFO: [0mEpoch 121 Step 39/39 lr 0.001000 loss 0.1367 (0.0988) acc@1 0.9531 (0.9667) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:01] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:40:01] __main__ INFO: [0mVal 121
[32m[2022-06-16 11:40:02] __main__ INFO: [0mEpoch 121 loss 1.7203 acc@1 0.6555 acc@5 0.9648
[32m[2022-06-16 11:40:02] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:40:02] __main__ INFO: [0mTrain 122 4719
[32m[2022-06-16 11:40:04] __main__ INFO: [0mEpoch 122 Step 39/39 lr 0.001000 loss 0.0834 (0.0934) acc@1 0.9766 (0.9718) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:04] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:40:04] __main__ INFO: [0mVal 122
[32m[2022-06-16 11:40:04] __main__ INFO: [0mEpoch 122 loss 1.7062 acc@1 0.6603 acc@5 0.9649
[32m[2022-06-16 11:40:04] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:40:04] __main__ INFO: [0mTrain 123 4758
[32m[2022-06-16 11:40:06] __main__ INFO: [0mEpoch 123 Step 39/39 lr 0.001000 loss 0.1257 (0.0794) acc@1 0.9531 (0.9788) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:06] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:06] __main__ INFO: [0mVal 123
[32m[2022-06-16 11:40:07] __main__ INFO: [0mEpoch 123 loss 1.7081 acc@1 0.6592 acc@5 0.9660
[32m[2022-06-16 11:40:07] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:40:07] __main__ INFO: [0mTrain 124 4797
[32m[2022-06-16 11:40:09] __main__ INFO: [0mEpoch 124 Step 39/39 lr 0.001000 loss 0.1016 (0.0951) acc@1 0.9844 (0.9716) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:09] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:40:09] __main__ INFO: [0mVal 124
[32m[2022-06-16 11:40:09] __main__ INFO: [0mEpoch 124 loss 1.7210 acc@1 0.6585 acc@5 0.9645
[32m[2022-06-16 11:40:09] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:40:09] __main__ INFO: [0mTrain 125 4836
[32m[2022-06-16 11:40:11] __main__ INFO: [0mEpoch 125 Step 39/39 lr 0.001000 loss 0.0713 (0.0808) acc@1 0.9844 (0.9784) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:11] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:40:11] __main__ INFO: [0mVal 125
[32m[2022-06-16 11:40:12] __main__ INFO: [0mEpoch 125 loss 1.7163 acc@1 0.6578 acc@5 0.9654
[32m[2022-06-16 11:40:12] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:40:12] __main__ INFO: [0mTrain 126 4875
[32m[2022-06-16 11:40:13] __main__ INFO: [0mEpoch 126 Step 39/39 lr 0.001000 loss 0.1357 (0.0885) acc@1 0.9609 (0.9736) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:14] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:40:14] __main__ INFO: [0mVal 126
[32m[2022-06-16 11:40:14] __main__ INFO: [0mEpoch 126 loss 1.7219 acc@1 0.6588 acc@5 0.9648
[32m[2022-06-16 11:40:14] __main__ INFO: [0mElapsed 0.66
[32m[2022-06-16 11:40:14] __main__ INFO: [0mTrain 127 4914
[32m[2022-06-16 11:40:16] __main__ INFO: [0mEpoch 127 Step 39/39 lr 0.001000 loss 0.0767 (0.0889) acc@1 0.9766 (0.9738) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:16] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:40:16] __main__ INFO: [0mVal 127
[32m[2022-06-16 11:40:17] __main__ INFO: [0mEpoch 127 loss 1.7240 acc@1 0.6604 acc@5 0.9652
[32m[2022-06-16 11:40:17] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:40:17] __main__ INFO: [0mTrain 128 4953
[32m[2022-06-16 11:40:18] __main__ INFO: [0mEpoch 128 Step 39/39 lr 0.001000 loss 0.0508 (0.0816) acc@1 0.9922 (0.9748) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:18] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:18] __main__ INFO: [0mVal 128
[32m[2022-06-16 11:40:19] __main__ INFO: [0mEpoch 128 loss 1.7173 acc@1 0.6599 acc@5 0.9648
[32m[2022-06-16 11:40:19] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:40:19] __main__ INFO: [0mTrain 129 4992
[32m[2022-06-16 11:40:21] __main__ INFO: [0mEpoch 129 Step 39/39 lr 0.001000 loss 0.0501 (0.0869) acc@1 0.9922 (0.9732) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:21] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:40:21] __main__ INFO: [0mVal 129
[32m[2022-06-16 11:40:21] __main__ INFO: [0mEpoch 129 loss 1.7247 acc@1 0.6602 acc@5 0.9642
[32m[2022-06-16 11:40:21] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:40:21] __main__ INFO: [0mTrain 130 5031
[32m[2022-06-16 11:40:23] __main__ INFO: [0mEpoch 130 Step 39/39 lr 0.001000 loss 0.1269 (0.0799) acc@1 0.9531 (0.9748) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:40:23] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:40:23] __main__ INFO: [0mVal 130
[32m[2022-06-16 11:40:24] __main__ INFO: [0mEpoch 130 loss 1.7289 acc@1 0.6581 acc@5 0.9641
[32m[2022-06-16 11:40:24] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:40:24] __main__ INFO: [0mTrain 131 5070
[32m[2022-06-16 11:40:25] __main__ INFO: [0mEpoch 131 Step 39/39 lr 0.001000 loss 0.0580 (0.0786) acc@1 1.0000 (0.9778) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:25] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:40:25] __main__ INFO: [0mVal 131
[32m[2022-06-16 11:40:26] __main__ INFO: [0mEpoch 131 loss 1.7341 acc@1 0.6598 acc@5 0.9632
[32m[2022-06-16 11:40:26] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:40:26] __main__ INFO: [0mTrain 132 5109
[32m[2022-06-16 11:40:28] __main__ INFO: [0mEpoch 132 Step 39/39 lr 0.001000 loss 0.0454 (0.0728) acc@1 0.9922 (0.9804) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:28] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:28] __main__ INFO: [0mVal 132
[32m[2022-06-16 11:40:28] __main__ INFO: [0mEpoch 132 loss 1.7362 acc@1 0.6584 acc@5 0.9631
[32m[2022-06-16 11:40:28] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:40:28] __main__ INFO: [0mTrain 133 5148
[32m[2022-06-16 11:40:30] __main__ INFO: [0mEpoch 133 Step 39/39 lr 0.001000 loss 0.0668 (0.0829) acc@1 0.9844 (0.9758) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:40:30] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:40:30] __main__ INFO: [0mVal 133
[32m[2022-06-16 11:40:31] __main__ INFO: [0mEpoch 133 loss 1.7340 acc@1 0.6593 acc@5 0.9635
[32m[2022-06-16 11:40:31] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:40:31] __main__ INFO: [0mTrain 134 5187
[32m[2022-06-16 11:40:32] __main__ INFO: [0mEpoch 134 Step 39/39 lr 0.001000 loss 0.1175 (0.0870) acc@1 0.9688 (0.9720) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:33] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:40:33] __main__ INFO: [0mVal 134
[32m[2022-06-16 11:40:33] __main__ INFO: [0mEpoch 134 loss 1.7402 acc@1 0.6587 acc@5 0.9642
[32m[2022-06-16 11:40:33] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:40:33] __main__ INFO: [0mTrain 135 5226
[32m[2022-06-16 11:40:35] __main__ INFO: [0mEpoch 135 Step 39/39 lr 0.001000 loss 0.0572 (0.0755) acc@1 0.9766 (0.9776) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:35] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:40:35] __main__ INFO: [0mVal 135
[32m[2022-06-16 11:40:36] __main__ INFO: [0mEpoch 135 loss 1.7356 acc@1 0.6592 acc@5 0.9633
[32m[2022-06-16 11:40:36] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:40:36] __main__ INFO: [0mTrain 136 5265
[32m[2022-06-16 11:40:37] __main__ INFO: [0mEpoch 136 Step 39/39 lr 0.001000 loss 0.0447 (0.0796) acc@1 1.0000 (0.9788) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:40:37] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:40:37] __main__ INFO: [0mVal 136
[32m[2022-06-16 11:40:38] __main__ INFO: [0mEpoch 136 loss 1.7411 acc@1 0.6573 acc@5 0.9629
[32m[2022-06-16 11:40:38] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:40:38] __main__ INFO: [0mTrain 137 5304
[32m[2022-06-16 11:40:40] __main__ INFO: [0mEpoch 137 Step 39/39 lr 0.001000 loss 0.0932 (0.0821) acc@1 0.9766 (0.9758) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:40] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:40:40] __main__ INFO: [0mVal 137
[32m[2022-06-16 11:40:41] __main__ INFO: [0mEpoch 137 loss 1.7490 acc@1 0.6574 acc@5 0.9638
[32m[2022-06-16 11:40:41] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:40:41] __main__ INFO: [0mTrain 138 5343
[32m[2022-06-16 11:40:42] __main__ INFO: [0mEpoch 138 Step 39/39 lr 0.001000 loss 0.0644 (0.0824) acc@1 0.9844 (0.9768) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:42] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:42] __main__ INFO: [0mVal 138
[32m[2022-06-16 11:40:43] __main__ INFO: [0mEpoch 138 loss 1.7452 acc@1 0.6580 acc@5 0.9637
[32m[2022-06-16 11:40:43] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:40:43] __main__ INFO: [0mTrain 139 5382
[32m[2022-06-16 11:40:45] __main__ INFO: [0mEpoch 139 Step 39/39 lr 0.001000 loss 0.0861 (0.0748) acc@1 0.9766 (0.9780) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:45] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:40:45] __main__ INFO: [0mVal 139
[32m[2022-06-16 11:40:45] __main__ INFO: [0mEpoch 139 loss 1.7504 acc@1 0.6583 acc@5 0.9634
[32m[2022-06-16 11:40:45] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:40:45] __main__ INFO: [0mTrain 140 5421
[32m[2022-06-16 11:40:47] __main__ INFO: [0mEpoch 140 Step 39/39 lr 0.001000 loss 0.0482 (0.0768) acc@1 1.0000 (0.9766) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:47] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:47] __main__ INFO: [0mVal 140
[32m[2022-06-16 11:40:48] __main__ INFO: [0mEpoch 140 loss 1.7507 acc@1 0.6577 acc@5 0.9632
[32m[2022-06-16 11:40:48] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:40:48] __main__ INFO: [0mTrain 141 5460
[32m[2022-06-16 11:40:49] __main__ INFO: [0mEpoch 141 Step 39/39 lr 0.001000 loss 0.0463 (0.0837) acc@1 0.9922 (0.9762) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:49] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:40:49] __main__ INFO: [0mVal 141
[32m[2022-06-16 11:40:50] __main__ INFO: [0mEpoch 141 loss 1.7597 acc@1 0.6590 acc@5 0.9648
[32m[2022-06-16 11:40:50] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:40:50] __main__ INFO: [0mTrain 142 5499
[32m[2022-06-16 11:40:52] __main__ INFO: [0mEpoch 142 Step 39/39 lr 0.001000 loss 0.1224 (0.0691) acc@1 0.9609 (0.9822) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:52] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:40:52] __main__ INFO: [0mVal 142
[32m[2022-06-16 11:40:52] __main__ INFO: [0mEpoch 142 loss 1.7488 acc@1 0.6574 acc@5 0.9643
[32m[2022-06-16 11:40:52] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:40:52] __main__ INFO: [0mTrain 143 5538
[32m[2022-06-16 11:40:54] __main__ INFO: [0mEpoch 143 Step 39/39 lr 0.001000 loss 0.1163 (0.0798) acc@1 0.9531 (0.9770) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:54] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:40:54] __main__ INFO: [0mVal 143
[32m[2022-06-16 11:40:55] __main__ INFO: [0mEpoch 143 loss 1.7570 acc@1 0.6569 acc@5 0.9642
[32m[2022-06-16 11:40:55] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:40:55] __main__ INFO: [0mTrain 144 5577
[32m[2022-06-16 11:40:57] __main__ INFO: [0mEpoch 144 Step 39/39 lr 0.001000 loss 0.0766 (0.0756) acc@1 0.9688 (0.9796) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:57] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:40:57] __main__ INFO: [0mVal 144
[32m[2022-06-16 11:40:57] __main__ INFO: [0mEpoch 144 loss 1.7613 acc@1 0.6571 acc@5 0.9636
[32m[2022-06-16 11:40:57] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:40:57] __main__ INFO: [0mTrain 145 5616
[32m[2022-06-16 11:40:59] __main__ INFO: [0mEpoch 145 Step 39/39 lr 0.001000 loss 0.0455 (0.0725) acc@1 1.0000 (0.9800) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:40:59] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:40:59] __main__ INFO: [0mVal 145
[32m[2022-06-16 11:41:00] __main__ INFO: [0mEpoch 145 loss 1.7622 acc@1 0.6555 acc@5 0.9632
[32m[2022-06-16 11:41:00] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:00] __main__ INFO: [0mTrain 146 5655
[32m[2022-06-16 11:41:01] __main__ INFO: [0mEpoch 146 Step 39/39 lr 0.001000 loss 0.0556 (0.0747) acc@1 0.9922 (0.9778) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:01] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:41:01] __main__ INFO: [0mVal 146
[32m[2022-06-16 11:41:02] __main__ INFO: [0mEpoch 146 loss 1.7613 acc@1 0.6602 acc@5 0.9641
[32m[2022-06-16 11:41:02] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-16 11:41:02] __main__ INFO: [0mTrain 147 5694
[32m[2022-06-16 11:41:04] __main__ INFO: [0mEpoch 147 Step 39/39 lr 0.001000 loss 0.0748 (0.0702) acc@1 0.9688 (0.9794) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:04] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:41:04] __main__ INFO: [0mVal 147
[32m[2022-06-16 11:41:05] __main__ INFO: [0mEpoch 147 loss 1.7667 acc@1 0.6558 acc@5 0.9634
[32m[2022-06-16 11:41:05] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:41:05] __main__ INFO: [0mTrain 148 5733
[32m[2022-06-16 11:41:06] __main__ INFO: [0mEpoch 148 Step 39/39 lr 0.001000 loss 0.0620 (0.0674) acc@1 0.9766 (0.9812) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:06] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:41:06] __main__ INFO: [0mVal 148
[32m[2022-06-16 11:41:07] __main__ INFO: [0mEpoch 148 loss 1.7611 acc@1 0.6586 acc@5 0.9629
[32m[2022-06-16 11:41:07] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:41:07] __main__ INFO: [0mTrain 149 5772
[32m[2022-06-16 11:41:09] __main__ INFO: [0mEpoch 149 Step 39/39 lr 0.001000 loss 0.1020 (0.0744) acc@1 0.9688 (0.9772) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:09] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:41:09] __main__ INFO: [0mVal 149
[32m[2022-06-16 11:41:10] __main__ INFO: [0mEpoch 149 loss 1.7762 acc@1 0.6584 acc@5 0.9640
[32m[2022-06-16 11:41:10] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:41:10] __main__ INFO: [0mTrain 150 5811
[32m[2022-06-16 11:41:11] __main__ INFO: [0mEpoch 150 Step 39/39 lr 0.001000 loss 0.0975 (0.0684) acc@1 0.9688 (0.9814) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:11] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:41:11] __main__ INFO: [0mVal 150
[32m[2022-06-16 11:41:12] __main__ INFO: [0mEpoch 150 loss 1.7773 acc@1 0.6570 acc@5 0.9633
[32m[2022-06-16 11:41:12] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:41:12] __main__ INFO: [0mTrain 151 5850
[32m[2022-06-16 11:41:14] __main__ INFO: [0mEpoch 151 Step 39/39 lr 0.001000 loss 0.0733 (0.0734) acc@1 0.9766 (0.9784) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:14] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:41:14] __main__ INFO: [0mVal 151
[32m[2022-06-16 11:41:15] __main__ INFO: [0mEpoch 151 loss 1.7711 acc@1 0.6600 acc@5 0.9622
[32m[2022-06-16 11:41:15] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:15] __main__ INFO: [0mTrain 152 5889
[32m[2022-06-16 11:41:16] __main__ INFO: [0mEpoch 152 Step 39/39 lr 0.001000 loss 0.0720 (0.0727) acc@1 0.9844 (0.9796) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:16] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:41:16] __main__ INFO: [0mVal 152
[32m[2022-06-16 11:41:17] __main__ INFO: [0mEpoch 152 loss 1.7784 acc@1 0.6586 acc@5 0.9635
[32m[2022-06-16 11:41:17] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:41:17] __main__ INFO: [0mTrain 153 5928
[32m[2022-06-16 11:41:19] __main__ INFO: [0mEpoch 153 Step 39/39 lr 0.001000 loss 0.0702 (0.0691) acc@1 0.9844 (0.9792) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:19] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:41:19] __main__ INFO: [0mVal 153
[32m[2022-06-16 11:41:19] __main__ INFO: [0mEpoch 153 loss 1.7837 acc@1 0.6591 acc@5 0.9633
[32m[2022-06-16 11:41:19] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:19] __main__ INFO: [0mTrain 154 5967
[32m[2022-06-16 11:41:21] __main__ INFO: [0mEpoch 154 Step 39/39 lr 0.001000 loss 0.0768 (0.0651) acc@1 0.9688 (0.9834) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:41:21] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:41:21] __main__ INFO: [0mVal 154
[32m[2022-06-16 11:41:22] __main__ INFO: [0mEpoch 154 loss 1.7845 acc@1 0.6592 acc@5 0.9644
[32m[2022-06-16 11:41:22] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:41:22] __main__ INFO: [0mTrain 155 6006
[32m[2022-06-16 11:41:23] __main__ INFO: [0mEpoch 155 Step 39/39 lr 0.001000 loss 0.0759 (0.0733) acc@1 0.9844 (0.9786) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:23] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:41:23] __main__ INFO: [0mVal 155
[32m[2022-06-16 11:41:24] __main__ INFO: [0mEpoch 155 loss 1.7770 acc@1 0.6573 acc@5 0.9643
[32m[2022-06-16 11:41:24] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:41:24] __main__ INFO: [0mTrain 156 6045
[32m[2022-06-16 11:41:26] __main__ INFO: [0mEpoch 156 Step 39/39 lr 0.001000 loss 0.0743 (0.0666) acc@1 0.9844 (0.9800) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:26] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:41:26] __main__ INFO: [0mVal 156
[32m[2022-06-16 11:41:27] __main__ INFO: [0mEpoch 156 loss 1.7700 acc@1 0.6604 acc@5 0.9636
[32m[2022-06-16 11:41:27] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:41:27] __main__ INFO: [0mTrain 157 6084
[32m[2022-06-16 11:41:28] __main__ INFO: [0mEpoch 157 Step 39/39 lr 0.001000 loss 0.0720 (0.0647) acc@1 0.9688 (0.9828) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:28] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:41:28] __main__ INFO: [0mVal 157
[32m[2022-06-16 11:41:29] __main__ INFO: [0mEpoch 157 loss 1.7807 acc@1 0.6588 acc@5 0.9639
[32m[2022-06-16 11:41:29] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:41:29] __main__ INFO: [0mTrain 158 6123
[32m[2022-06-16 11:41:31] __main__ INFO: [0mEpoch 158 Step 39/39 lr 0.001000 loss 0.1171 (0.0752) acc@1 0.9375 (0.9782) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:31] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:41:31] __main__ INFO: [0mVal 158
[32m[2022-06-16 11:41:32] __main__ INFO: [0mEpoch 158 loss 1.7821 acc@1 0.6575 acc@5 0.9647
[32m[2022-06-16 11:41:32] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:32] __main__ INFO: [0mTrain 159 6162
[32m[2022-06-16 11:41:33] __main__ INFO: [0mEpoch 159 Step 39/39 lr 0.001000 loss 0.0737 (0.0720) acc@1 0.9766 (0.9804) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:41:33] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:41:33] __main__ INFO: [0mVal 159
[32m[2022-06-16 11:41:34] __main__ INFO: [0mEpoch 159 loss 1.7836 acc@1 0.6595 acc@5 0.9641
[32m[2022-06-16 11:41:34] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:41:34] __main__ INFO: [0mTrain 160 6201
[32m[2022-06-16 11:41:36] __main__ INFO: [0mEpoch 160 Step 39/39 lr 0.001000 loss 0.0530 (0.0652) acc@1 0.9844 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:36] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:41:36] __main__ INFO: [0mVal 160
[32m[2022-06-16 11:41:36] __main__ INFO: [0mEpoch 160 loss 1.7881 acc@1 0.6600 acc@5 0.9642
[32m[2022-06-16 11:41:36] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:41:36] __main__ INFO: [0mTrain 161 6240
[32m[2022-06-16 11:41:38] __main__ INFO: [0mEpoch 161 Step 39/39 lr 0.001000 loss 0.0233 (0.0681) acc@1 1.0000 (0.9800) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:38] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:41:38] __main__ INFO: [0mVal 161
[32m[2022-06-16 11:41:39] __main__ INFO: [0mEpoch 161 loss 1.7966 acc@1 0.6589 acc@5 0.9646
[32m[2022-06-16 11:41:39] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:41:39] __main__ INFO: [0mTrain 162 6279
[32m[2022-06-16 11:41:40] __main__ INFO: [0mEpoch 162 Step 39/39 lr 0.001000 loss 0.0595 (0.0689) acc@1 0.9844 (0.9812) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:41] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:41:41] __main__ INFO: [0mVal 162
[32m[2022-06-16 11:41:41] __main__ INFO: [0mEpoch 162 loss 1.8007 acc@1 0.6593 acc@5 0.9641
[32m[2022-06-16 11:41:41] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-16 11:41:41] __main__ INFO: [0mTrain 163 6318
[32m[2022-06-16 11:41:43] __main__ INFO: [0mEpoch 163 Step 39/39 lr 0.001000 loss 0.0553 (0.0645) acc@1 0.9766 (0.9818) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:43] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:41:43] __main__ INFO: [0mVal 163
[32m[2022-06-16 11:41:44] __main__ INFO: [0mEpoch 163 loss 1.7959 acc@1 0.6584 acc@5 0.9637
[32m[2022-06-16 11:41:44] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:41:44] __main__ INFO: [0mTrain 164 6357
[32m[2022-06-16 11:41:45] __main__ INFO: [0mEpoch 164 Step 39/39 lr 0.001000 loss 0.0721 (0.0693) acc@1 0.9922 (0.9800) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:45] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:41:45] __main__ INFO: [0mVal 164
[32m[2022-06-16 11:41:46] __main__ INFO: [0mEpoch 164 loss 1.8013 acc@1 0.6568 acc@5 0.9644
[32m[2022-06-16 11:41:46] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:41:46] __main__ INFO: [0mTrain 165 6396
[32m[2022-06-16 11:41:48] __main__ INFO: [0mEpoch 165 Step 39/39 lr 0.001000 loss 0.0692 (0.0622) acc@1 0.9688 (0.9832) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:48] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:41:48] __main__ INFO: [0mVal 165
[32m[2022-06-16 11:41:49] __main__ INFO: [0mEpoch 165 loss 1.8006 acc@1 0.6569 acc@5 0.9638
[32m[2022-06-16 11:41:49] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:41:49] __main__ INFO: [0mTrain 166 6435
[32m[2022-06-16 11:41:50] __main__ INFO: [0mEpoch 166 Step 39/39 lr 0.001000 loss 0.0738 (0.0598) acc@1 0.9688 (0.9834) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:50] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:41:50] __main__ INFO: [0mVal 166
[32m[2022-06-16 11:41:51] __main__ INFO: [0mEpoch 166 loss 1.8051 acc@1 0.6562 acc@5 0.9643
[32m[2022-06-16 11:41:51] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:51] __main__ INFO: [0mTrain 167 6474
[32m[2022-06-16 11:41:53] __main__ INFO: [0mEpoch 167 Step 39/39 lr 0.001000 loss 0.0717 (0.0710) acc@1 0.9844 (0.9792) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:53] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:41:53] __main__ INFO: [0mVal 167
[32m[2022-06-16 11:41:54] __main__ INFO: [0mEpoch 167 loss 1.7954 acc@1 0.6584 acc@5 0.9628
[32m[2022-06-16 11:41:54] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:41:54] __main__ INFO: [0mTrain 168 6513
[32m[2022-06-16 11:41:55] __main__ INFO: [0mEpoch 168 Step 39/39 lr 0.001000 loss 0.0579 (0.0622) acc@1 0.9844 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:55] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:41:55] __main__ INFO: [0mVal 168
[32m[2022-06-16 11:41:56] __main__ INFO: [0mEpoch 168 loss 1.8013 acc@1 0.6587 acc@5 0.9636
[32m[2022-06-16 11:41:56] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:41:56] __main__ INFO: [0mTrain 169 6552
[32m[2022-06-16 11:41:58] __main__ INFO: [0mEpoch 169 Step 39/39 lr 0.001000 loss 0.0641 (0.0617) acc@1 0.9844 (0.9826) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:41:58] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:41:58] __main__ INFO: [0mVal 169
[32m[2022-06-16 11:41:58] __main__ INFO: [0mEpoch 169 loss 1.8065 acc@1 0.6575 acc@5 0.9623
[32m[2022-06-16 11:41:58] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:41:58] __main__ INFO: [0mTrain 170 6591
[32m[2022-06-16 11:42:00] __main__ INFO: [0mEpoch 170 Step 39/39 lr 0.001000 loss 0.0497 (0.0625) acc@1 0.9922 (0.9808) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:00] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:42:00] __main__ INFO: [0mVal 170
[32m[2022-06-16 11:42:01] __main__ INFO: [0mEpoch 170 loss 1.8150 acc@1 0.6571 acc@5 0.9625
[32m[2022-06-16 11:42:01] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:01] __main__ INFO: [0mTrain 171 6630
[32m[2022-06-16 11:42:02] __main__ INFO: [0mEpoch 171 Step 39/39 lr 0.001000 loss 0.0513 (0.0618) acc@1 0.9922 (0.9828) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:02] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:42:02] __main__ INFO: [0mVal 171
[32m[2022-06-16 11:42:03] __main__ INFO: [0mEpoch 171 loss 1.8057 acc@1 0.6574 acc@5 0.9627
[32m[2022-06-16 11:42:03] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:42:03] __main__ INFO: [0mTrain 172 6669
[32m[2022-06-16 11:42:05] __main__ INFO: [0mEpoch 172 Step 39/39 lr 0.001000 loss 0.0875 (0.0601) acc@1 0.9688 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:05] __main__ INFO: [0mElapsed 1.79
[32m[2022-06-16 11:42:05] __main__ INFO: [0mVal 172
[32m[2022-06-16 11:42:06] __main__ INFO: [0mEpoch 172 loss 1.8120 acc@1 0.6574 acc@5 0.9637
[32m[2022-06-16 11:42:06] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:42:06] __main__ INFO: [0mTrain 173 6708
[32m[2022-06-16 11:42:07] __main__ INFO: [0mEpoch 173 Step 39/39 lr 0.001000 loss 0.0587 (0.0675) acc@1 0.9766 (0.9788) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:07] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:42:07] __main__ INFO: [0mVal 173
[32m[2022-06-16 11:42:08] __main__ INFO: [0mEpoch 173 loss 1.8110 acc@1 0.6573 acc@5 0.9636
[32m[2022-06-16 11:42:08] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:42:08] __main__ INFO: [0mTrain 174 6747
[32m[2022-06-16 11:42:10] __main__ INFO: [0mEpoch 174 Step 39/39 lr 0.001000 loss 0.0580 (0.0634) acc@1 1.0000 (0.9822) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:10] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:42:10] __main__ INFO: [0mVal 174
[32m[2022-06-16 11:42:11] __main__ INFO: [0mEpoch 174 loss 1.8154 acc@1 0.6582 acc@5 0.9629
[32m[2022-06-16 11:42:11] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:11] __main__ INFO: [0mTrain 175 6786
[32m[2022-06-16 11:42:12] __main__ INFO: [0mEpoch 175 Step 39/39 lr 0.001000 loss 0.0498 (0.0620) acc@1 0.9922 (0.9812) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:42:12] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:42:12] __main__ INFO: [0mVal 175
[32m[2022-06-16 11:42:13] __main__ INFO: [0mEpoch 175 loss 1.8034 acc@1 0.6586 acc@5 0.9632
[32m[2022-06-16 11:42:13] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:13] __main__ INFO: [0mTrain 176 6825
[32m[2022-06-16 11:42:15] __main__ INFO: [0mEpoch 176 Step 39/39 lr 0.001000 loss 0.0434 (0.0670) acc@1 0.9922 (0.9816) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:15] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:42:15] __main__ INFO: [0mVal 176
[32m[2022-06-16 11:42:15] __main__ INFO: [0mEpoch 176 loss 1.8272 acc@1 0.6555 acc@5 0.9632
[32m[2022-06-16 11:42:15] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:42:15] __main__ INFO: [0mTrain 177 6864
[32m[2022-06-16 11:42:17] __main__ INFO: [0mEpoch 177 Step 39/39 lr 0.001000 loss 0.0755 (0.0634) acc@1 0.9766 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:17] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:42:17] __main__ INFO: [0mVal 177
[32m[2022-06-16 11:42:18] __main__ INFO: [0mEpoch 177 loss 1.8169 acc@1 0.6564 acc@5 0.9635
[32m[2022-06-16 11:42:18] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:42:18] __main__ INFO: [0mTrain 178 6903
[32m[2022-06-16 11:42:20] __main__ INFO: [0mEpoch 178 Step 39/39 lr 0.001000 loss 0.0638 (0.0678) acc@1 0.9766 (0.9792) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:20] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:42:20] __main__ INFO: [0mVal 178
[32m[2022-06-16 11:42:20] __main__ INFO: [0mEpoch 178 loss 1.8237 acc@1 0.6569 acc@5 0.9631
[32m[2022-06-16 11:42:20] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:42:20] __main__ INFO: [0mTrain 179 6942
[32m[2022-06-16 11:42:22] __main__ INFO: [0mEpoch 179 Step 39/39 lr 0.001000 loss 0.0448 (0.0632) acc@1 0.9922 (0.9812) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:22] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:42:22] __main__ INFO: [0mVal 179
[32m[2022-06-16 11:42:23] __main__ INFO: [0mEpoch 179 loss 1.8299 acc@1 0.6561 acc@5 0.9630
[32m[2022-06-16 11:42:23] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:42:23] __main__ INFO: [0mTrain 180 6981
[32m[2022-06-16 11:42:24] __main__ INFO: [0mEpoch 180 Step 39/39 lr 0.001000 loss 0.0738 (0.0656) acc@1 0.9766 (0.9804) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:25] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:42:25] __main__ INFO: [0mVal 180
[32m[2022-06-16 11:42:25] __main__ INFO: [0mEpoch 180 loss 1.8298 acc@1 0.6556 acc@5 0.9633
[32m[2022-06-16 11:42:25] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:42:25] __main__ INFO: [0mTrain 181 7020
[32m[2022-06-16 11:42:27] __main__ INFO: [0mEpoch 181 Step 39/39 lr 0.001000 loss 0.0696 (0.0677) acc@1 0.9766 (0.9808) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:27] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:42:27] __main__ INFO: [0mVal 181
[32m[2022-06-16 11:42:28] __main__ INFO: [0mEpoch 181 loss 1.8275 acc@1 0.6572 acc@5 0.9638
[32m[2022-06-16 11:42:28] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:42:28] __main__ INFO: [0mTrain 182 7059
[32m[2022-06-16 11:42:29] __main__ INFO: [0mEpoch 182 Step 39/39 lr 0.001000 loss 0.0655 (0.0618) acc@1 0.9766 (0.9834) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:29] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:42:29] __main__ INFO: [0mVal 182
[32m[2022-06-16 11:42:30] __main__ INFO: [0mEpoch 182 loss 1.8255 acc@1 0.6544 acc@5 0.9633
[32m[2022-06-16 11:42:30] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:30] __main__ INFO: [0mTrain 183 7098
[32m[2022-06-16 11:42:32] __main__ INFO: [0mEpoch 183 Step 39/39 lr 0.001000 loss 0.0639 (0.0640) acc@1 0.9766 (0.9820) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:32] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:42:32] __main__ INFO: [0mVal 183
[32m[2022-06-16 11:42:33] __main__ INFO: [0mEpoch 183 loss 1.8282 acc@1 0.6550 acc@5 0.9640
[32m[2022-06-16 11:42:33] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:42:33] __main__ INFO: [0mTrain 184 7137
[32m[2022-06-16 11:42:34] __main__ INFO: [0mEpoch 184 Step 39/39 lr 0.001000 loss 0.0352 (0.0649) acc@1 1.0000 (0.9814) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:34] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:42:34] __main__ INFO: [0mVal 184
[32m[2022-06-16 11:42:35] __main__ INFO: [0mEpoch 184 loss 1.8320 acc@1 0.6556 acc@5 0.9644
[32m[2022-06-16 11:42:35] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:42:35] __main__ INFO: [0mTrain 185 7176
[32m[2022-06-16 11:42:37] __main__ INFO: [0mEpoch 185 Step 39/39 lr 0.001000 loss 0.0865 (0.0642) acc@1 0.9766 (0.9802) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:37] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:42:37] __main__ INFO: [0mVal 185
[32m[2022-06-16 11:42:37] __main__ INFO: [0mEpoch 185 loss 1.8290 acc@1 0.6582 acc@5 0.9636
[32m[2022-06-16 11:42:37] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:42:37] __main__ INFO: [0mTrain 186 7215
[32m[2022-06-16 11:42:39] __main__ INFO: [0mEpoch 186 Step 39/39 lr 0.001000 loss 0.0388 (0.0609) acc@1 0.9922 (0.9820) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:42:39] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:42:39] __main__ INFO: [0mVal 186
[32m[2022-06-16 11:42:40] __main__ INFO: [0mEpoch 186 loss 1.8350 acc@1 0.6567 acc@5 0.9634
[32m[2022-06-16 11:42:40] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:42:40] __main__ INFO: [0mTrain 187 7254
[32m[2022-06-16 11:42:42] __main__ INFO: [0mEpoch 187 Step 39/39 lr 0.001000 loss 0.1002 (0.0580) acc@1 0.9609 (0.9844) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:42] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:42:42] __main__ INFO: [0mVal 187
[32m[2022-06-16 11:42:42] __main__ INFO: [0mEpoch 187 loss 1.8326 acc@1 0.6577 acc@5 0.9639
[32m[2022-06-16 11:42:42] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:42] __main__ INFO: [0mTrain 188 7293
[32m[2022-06-16 11:42:44] __main__ INFO: [0mEpoch 188 Step 39/39 lr 0.001000 loss 0.0649 (0.0578) acc@1 0.9844 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:44] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:42:44] __main__ INFO: [0mVal 188
[32m[2022-06-16 11:42:45] __main__ INFO: [0mEpoch 188 loss 1.8195 acc@1 0.6577 acc@5 0.9646
[32m[2022-06-16 11:42:45] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:42:45] __main__ INFO: [0mTrain 189 7332
[32m[2022-06-16 11:42:46] __main__ INFO: [0mEpoch 189 Step 39/39 lr 0.001000 loss 0.0754 (0.0571) acc@1 0.9766 (0.9834) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:42:46] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:42:46] __main__ INFO: [0mVal 189
[32m[2022-06-16 11:42:47] __main__ INFO: [0mEpoch 189 loss 1.8421 acc@1 0.6566 acc@5 0.9635
[32m[2022-06-16 11:42:47] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:42:47] __main__ INFO: [0mTrain 190 7371
[32m[2022-06-16 11:42:49] __main__ INFO: [0mEpoch 190 Step 39/39 lr 0.001000 loss 0.0700 (0.0602) acc@1 0.9766 (0.9834) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:49] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:42:49] __main__ INFO: [0mVal 190
[32m[2022-06-16 11:42:50] __main__ INFO: [0mEpoch 190 loss 1.8356 acc@1 0.6564 acc@5 0.9630
[32m[2022-06-16 11:42:50] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:42:50] __main__ INFO: [0mTrain 191 7410
[32m[2022-06-16 11:42:51] __main__ INFO: [0mEpoch 191 Step 39/39 lr 0.001000 loss 0.0524 (0.0645) acc@1 0.9922 (0.9820) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:51] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:42:51] __main__ INFO: [0mVal 191
[32m[2022-06-16 11:42:52] __main__ INFO: [0mEpoch 191 loss 1.8352 acc@1 0.6574 acc@5 0.9632
[32m[2022-06-16 11:42:52] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:42:52] __main__ INFO: [0mTrain 192 7449
[32m[2022-06-16 11:42:54] __main__ INFO: [0mEpoch 192 Step 39/39 lr 0.001000 loss 0.0551 (0.0621) acc@1 0.9844 (0.9814) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:54] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:42:54] __main__ INFO: [0mVal 192
[32m[2022-06-16 11:42:55] __main__ INFO: [0mEpoch 192 loss 1.8468 acc@1 0.6568 acc@5 0.9633
[32m[2022-06-16 11:42:55] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:42:55] __main__ INFO: [0mTrain 193 7488
[32m[2022-06-16 11:42:56] __main__ INFO: [0mEpoch 193 Step 39/39 lr 0.001000 loss 0.1020 (0.0600) acc@1 0.9688 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:56] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:42:56] __main__ INFO: [0mVal 193
[32m[2022-06-16 11:42:57] __main__ INFO: [0mEpoch 193 loss 1.8556 acc@1 0.6558 acc@5 0.9629
[32m[2022-06-16 11:42:57] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:42:57] __main__ INFO: [0mTrain 194 7527
[32m[2022-06-16 11:42:58] __main__ INFO: [0mEpoch 194 Step 39/39 lr 0.001000 loss 0.0780 (0.0618) acc@1 0.9922 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:42:58] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:42:58] __main__ INFO: [0mVal 194
[32m[2022-06-16 11:42:59] __main__ INFO: [0mEpoch 194 loss 1.8587 acc@1 0.6564 acc@5 0.9621
[32m[2022-06-16 11:42:59] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:42:59] __main__ INFO: [0mTrain 195 7566
[32m[2022-06-16 11:43:01] __main__ INFO: [0mEpoch 195 Step 39/39 lr 0.001000 loss 0.1012 (0.0608) acc@1 0.9766 (0.9840) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:01] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:43:01] __main__ INFO: [0mVal 195
[32m[2022-06-16 11:43:02] __main__ INFO: [0mEpoch 195 loss 1.8546 acc@1 0.6574 acc@5 0.9627
[32m[2022-06-16 11:43:02] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:43:02] __main__ INFO: [0mTrain 196 7605
[32m[2022-06-16 11:43:03] __main__ INFO: [0mEpoch 196 Step 39/39 lr 0.001000 loss 0.0804 (0.0638) acc@1 0.9688 (0.9812) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:03] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-16 11:43:03] __main__ INFO: [0mVal 196
[32m[2022-06-16 11:43:04] __main__ INFO: [0mEpoch 196 loss 1.8476 acc@1 0.6565 acc@5 0.9635
[32m[2022-06-16 11:43:04] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:43:04] __main__ INFO: [0mTrain 197 7644
[32m[2022-06-16 11:43:06] __main__ INFO: [0mEpoch 197 Step 39/39 lr 0.001000 loss 0.0837 (0.0553) acc@1 0.9766 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:06] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:43:06] __main__ INFO: [0mVal 197
[32m[2022-06-16 11:43:07] __main__ INFO: [0mEpoch 197 loss 1.8534 acc@1 0.6555 acc@5 0.9629
[32m[2022-06-16 11:43:07] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:43:07] __main__ INFO: [0mTrain 198 7683
[32m[2022-06-16 11:43:08] __main__ INFO: [0mEpoch 198 Step 39/39 lr 0.001000 loss 0.0557 (0.0592) acc@1 0.9844 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:08] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:43:08] __main__ INFO: [0mVal 198
[32m[2022-06-16 11:43:09] __main__ INFO: [0mEpoch 198 loss 1.8467 acc@1 0.6557 acc@5 0.9639
[32m[2022-06-16 11:43:09] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:43:09] __main__ INFO: [0mTrain 199 7722
[32m[2022-06-16 11:43:11] __main__ INFO: [0mEpoch 199 Step 39/39 lr 0.001000 loss 0.0806 (0.0556) acc@1 0.9844 (0.9866) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:11] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:11] __main__ INFO: [0mVal 199
[32m[2022-06-16 11:43:11] __main__ INFO: [0mEpoch 199 loss 1.8575 acc@1 0.6551 acc@5 0.9635
[32m[2022-06-16 11:43:11] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:43:11] __main__ INFO: [0mTrain 200 7761
[32m[2022-06-16 11:43:13] __main__ INFO: [0mEpoch 200 Step 39/39 lr 0.001000 loss 0.1020 (0.0620) acc@1 0.9609 (0.9830) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:13] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:43:13] __main__ INFO: [0mVal 200
[32m[2022-06-16 11:43:14] __main__ INFO: [0mEpoch 200 loss 1.8547 acc@1 0.6546 acc@5 0.9642
[32m[2022-06-16 11:43:14] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:43:14] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00200.pth
[32m[2022-06-16 11:43:14] __main__ INFO: [0mTrain 201 7800
[32m[2022-06-16 11:43:15] __main__ INFO: [0mEpoch 201 Step 39/39 lr 0.001000 loss 0.0738 (0.0559) acc@1 0.9766 (0.9836) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:15] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:43:15] __main__ INFO: [0mVal 201
[32m[2022-06-16 11:43:16] __main__ INFO: [0mEpoch 201 loss 1.8438 acc@1 0.6578 acc@5 0.9645
[32m[2022-06-16 11:43:16] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:43:16] __main__ INFO: [0mTrain 202 7839
[32m[2022-06-16 11:43:18] __main__ INFO: [0mEpoch 202 Step 39/39 lr 0.001000 loss 0.0686 (0.0567) acc@1 0.9766 (0.9840) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:18] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:43:18] __main__ INFO: [0mVal 202
[32m[2022-06-16 11:43:19] __main__ INFO: [0mEpoch 202 loss 1.8471 acc@1 0.6583 acc@5 0.9638
[32m[2022-06-16 11:43:19] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:43:19] __main__ INFO: [0mTrain 203 7878
[32m[2022-06-16 11:43:20] __main__ INFO: [0mEpoch 203 Step 39/39 lr 0.001000 loss 0.0385 (0.0544) acc@1 0.9922 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:20] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:20] __main__ INFO: [0mVal 203
[32m[2022-06-16 11:43:21] __main__ INFO: [0mEpoch 203 loss 1.8410 acc@1 0.6576 acc@5 0.9630
[32m[2022-06-16 11:43:21] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:43:21] __main__ INFO: [0mTrain 204 7917
[32m[2022-06-16 11:43:23] __main__ INFO: [0mEpoch 204 Step 39/39 lr 0.001000 loss 0.0603 (0.0556) acc@1 0.9844 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:23] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:23] __main__ INFO: [0mVal 204
[32m[2022-06-16 11:43:24] __main__ INFO: [0mEpoch 204 loss 1.8518 acc@1 0.6561 acc@5 0.9632
[32m[2022-06-16 11:43:24] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:43:24] __main__ INFO: [0mTrain 205 7956
[32m[2022-06-16 11:43:25] __main__ INFO: [0mEpoch 205 Step 39/39 lr 0.001000 loss 0.0439 (0.0609) acc@1 0.9922 (0.9822) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:25] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-16 11:43:25] __main__ INFO: [0mVal 205
[32m[2022-06-16 11:43:26] __main__ INFO: [0mEpoch 205 loss 1.8668 acc@1 0.6551 acc@5 0.9628
[32m[2022-06-16 11:43:26] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:43:26] __main__ INFO: [0mTrain 206 7995
[32m[2022-06-16 11:43:28] __main__ INFO: [0mEpoch 206 Step 39/39 lr 0.001000 loss 0.0780 (0.0598) acc@1 0.9688 (0.9840) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:28] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:43:28] __main__ INFO: [0mVal 206
[32m[2022-06-16 11:43:29] __main__ INFO: [0mEpoch 206 loss 1.8622 acc@1 0.6548 acc@5 0.9634
[32m[2022-06-16 11:43:29] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:43:29] __main__ INFO: [0mTrain 207 8034
[32m[2022-06-16 11:43:30] __main__ INFO: [0mEpoch 207 Step 39/39 lr 0.001000 loss 0.0342 (0.0590) acc@1 0.9922 (0.9844) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:30] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:43:30] __main__ INFO: [0mVal 207
[32m[2022-06-16 11:43:31] __main__ INFO: [0mEpoch 207 loss 1.8669 acc@1 0.6558 acc@5 0.9624
[32m[2022-06-16 11:43:31] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:43:31] __main__ INFO: [0mTrain 208 8073
[32m[2022-06-16 11:43:33] __main__ INFO: [0mEpoch 208 Step 39/39 lr 0.001000 loss 0.0627 (0.0634) acc@1 0.9766 (0.9826) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:33] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:43:33] __main__ INFO: [0mVal 208
[32m[2022-06-16 11:43:33] __main__ INFO: [0mEpoch 208 loss 1.8582 acc@1 0.6569 acc@5 0.9633
[32m[2022-06-16 11:43:33] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:43:33] __main__ INFO: [0mTrain 209 8112
[32m[2022-06-16 11:43:35] __main__ INFO: [0mEpoch 209 Step 39/39 lr 0.001000 loss 0.0587 (0.0586) acc@1 0.9844 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:35] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:43:35] __main__ INFO: [0mVal 209
[32m[2022-06-16 11:43:36] __main__ INFO: [0mEpoch 209 loss 1.8659 acc@1 0.6547 acc@5 0.9639
[32m[2022-06-16 11:43:36] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:43:36] __main__ INFO: [0mTrain 210 8151
[32m[2022-06-16 11:43:38] __main__ INFO: [0mEpoch 210 Step 39/39 lr 0.001000 loss 0.0580 (0.0561) acc@1 0.9844 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:38] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:43:38] __main__ INFO: [0mVal 210
[32m[2022-06-16 11:43:38] __main__ INFO: [0mEpoch 210 loss 1.8752 acc@1 0.6547 acc@5 0.9629
[32m[2022-06-16 11:43:38] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:43:38] __main__ INFO: [0mTrain 211 8190
[32m[2022-06-16 11:43:40] __main__ INFO: [0mEpoch 211 Step 39/39 lr 0.001000 loss 0.0605 (0.0534) acc@1 0.9844 (0.9866) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:40] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:43:40] __main__ INFO: [0mVal 211
[32m[2022-06-16 11:43:41] __main__ INFO: [0mEpoch 211 loss 1.8678 acc@1 0.6547 acc@5 0.9626
[32m[2022-06-16 11:43:41] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:43:41] __main__ INFO: [0mTrain 212 8229
[32m[2022-06-16 11:43:42] __main__ INFO: [0mEpoch 212 Step 39/39 lr 0.001000 loss 0.0430 (0.0566) acc@1 0.9922 (0.9840) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:42] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:43:42] __main__ INFO: [0mVal 212
[32m[2022-06-16 11:43:43] __main__ INFO: [0mEpoch 212 loss 1.8793 acc@1 0.6541 acc@5 0.9628
[32m[2022-06-16 11:43:43] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:43:43] __main__ INFO: [0mTrain 213 8268
[32m[2022-06-16 11:43:45] __main__ INFO: [0mEpoch 213 Step 39/39 lr 0.001000 loss 0.0641 (0.0567) acc@1 0.9688 (0.9832) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:45] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:45] __main__ INFO: [0mVal 213
[32m[2022-06-16 11:43:45] __main__ INFO: [0mEpoch 213 loss 1.8704 acc@1 0.6545 acc@5 0.9633
[32m[2022-06-16 11:43:45] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:43:45] __main__ INFO: [0mTrain 214 8307
[32m[2022-06-16 11:43:47] __main__ INFO: [0mEpoch 214 Step 39/39 lr 0.001000 loss 0.0549 (0.0542) acc@1 0.9844 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:47] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:43:47] __main__ INFO: [0mVal 214
[32m[2022-06-16 11:43:48] __main__ INFO: [0mEpoch 214 loss 1.8797 acc@1 0.6554 acc@5 0.9628
[32m[2022-06-16 11:43:48] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:43:48] __main__ INFO: [0mTrain 215 8346
[32m[2022-06-16 11:43:49] __main__ INFO: [0mEpoch 215 Step 39/39 lr 0.001000 loss 0.0308 (0.0535) acc@1 1.0000 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:50] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:50] __main__ INFO: [0mVal 215
[32m[2022-06-16 11:43:50] __main__ INFO: [0mEpoch 215 loss 1.8774 acc@1 0.6543 acc@5 0.9635
[32m[2022-06-16 11:43:50] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:43:50] __main__ INFO: [0mTrain 216 8385
[32m[2022-06-16 11:43:52] __main__ INFO: [0mEpoch 216 Step 39/39 lr 0.001000 loss 0.0449 (0.0567) acc@1 0.9922 (0.9852) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:52] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:43:52] __main__ INFO: [0mVal 216
[32m[2022-06-16 11:43:53] __main__ INFO: [0mEpoch 216 loss 1.8744 acc@1 0.6553 acc@5 0.9624
[32m[2022-06-16 11:43:53] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:43:53] __main__ INFO: [0mTrain 217 8424
[32m[2022-06-16 11:43:54] __main__ INFO: [0mEpoch 217 Step 39/39 lr 0.001000 loss 0.0615 (0.0571) acc@1 0.9766 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:54] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:43:54] __main__ INFO: [0mVal 217
[32m[2022-06-16 11:43:55] __main__ INFO: [0mEpoch 217 loss 1.8766 acc@1 0.6565 acc@5 0.9630
[32m[2022-06-16 11:43:55] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:43:55] __main__ INFO: [0mTrain 218 8463
[32m[2022-06-16 11:43:57] __main__ INFO: [0mEpoch 218 Step 39/39 lr 0.001000 loss 0.0438 (0.0491) acc@1 0.9844 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:57] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:43:57] __main__ INFO: [0mVal 218
[32m[2022-06-16 11:43:58] __main__ INFO: [0mEpoch 218 loss 1.8837 acc@1 0.6572 acc@5 0.9627
[32m[2022-06-16 11:43:58] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:43:58] __main__ INFO: [0mTrain 219 8502
[32m[2022-06-16 11:43:59] __main__ INFO: [0mEpoch 219 Step 39/39 lr 0.001000 loss 0.0351 (0.0541) acc@1 0.9922 (0.9850) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:43:59] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:43:59] __main__ INFO: [0mVal 219
[32m[2022-06-16 11:44:00] __main__ INFO: [0mEpoch 219 loss 1.8897 acc@1 0.6555 acc@5 0.9629
[32m[2022-06-16 11:44:00] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:44:00] __main__ INFO: [0mTrain 220 8541
[32m[2022-06-16 11:44:02] __main__ INFO: [0mEpoch 220 Step 39/39 lr 0.001000 loss 0.0351 (0.0564) acc@1 0.9922 (0.9848) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:02] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:44:02] __main__ INFO: [0mVal 220
[32m[2022-06-16 11:44:02] __main__ INFO: [0mEpoch 220 loss 1.8965 acc@1 0.6553 acc@5 0.9628
[32m[2022-06-16 11:44:02] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:44:02] __main__ INFO: [0mTrain 221 8580
[32m[2022-06-16 11:44:04] __main__ INFO: [0mEpoch 221 Step 39/39 lr 0.001000 loss 0.0698 (0.0561) acc@1 0.9688 (0.9836) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:04] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:44:04] __main__ INFO: [0mVal 221
[32m[2022-06-16 11:44:05] __main__ INFO: [0mEpoch 221 loss 1.8953 acc@1 0.6553 acc@5 0.9630
[32m[2022-06-16 11:44:05] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:44:05] __main__ INFO: [0mTrain 222 8619
[32m[2022-06-16 11:44:06] __main__ INFO: [0mEpoch 222 Step 39/39 lr 0.001000 loss 0.0652 (0.0539) acc@1 0.9922 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:07] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:44:07] __main__ INFO: [0mVal 222
[32m[2022-06-16 11:44:07] __main__ INFO: [0mEpoch 222 loss 1.8898 acc@1 0.6555 acc@5 0.9636
[32m[2022-06-16 11:44:07] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:44:07] __main__ INFO: [0mTrain 223 8658
[32m[2022-06-16 11:44:09] __main__ INFO: [0mEpoch 223 Step 39/39 lr 0.001000 loss 0.1155 (0.0571) acc@1 0.9531 (0.9838) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:09] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:44:09] __main__ INFO: [0mVal 223
[32m[2022-06-16 11:44:10] __main__ INFO: [0mEpoch 223 loss 1.9011 acc@1 0.6532 acc@5 0.9624
[32m[2022-06-16 11:44:10] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:44:10] __main__ INFO: [0mTrain 224 8697
[32m[2022-06-16 11:44:11] __main__ INFO: [0mEpoch 224 Step 39/39 lr 0.001000 loss 0.0626 (0.0544) acc@1 0.9766 (0.9852) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:11] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:44:11] __main__ INFO: [0mVal 224
[32m[2022-06-16 11:44:12] __main__ INFO: [0mEpoch 224 loss 1.9016 acc@1 0.6543 acc@5 0.9631
[32m[2022-06-16 11:44:12] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-16 11:44:12] __main__ INFO: [0mTrain 225 8736
[32m[2022-06-16 11:44:14] __main__ INFO: [0mEpoch 225 Step 39/39 lr 0.001000 loss 0.0327 (0.0498) acc@1 0.9922 (0.9880) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:14] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:44:14] __main__ INFO: [0mVal 225
[32m[2022-06-16 11:44:15] __main__ INFO: [0mEpoch 225 loss 1.8919 acc@1 0.6556 acc@5 0.9627
[32m[2022-06-16 11:44:15] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:44:15] __main__ INFO: [0mTrain 226 8775
[32m[2022-06-16 11:44:16] __main__ INFO: [0mEpoch 226 Step 39/39 lr 0.001000 loss 0.0378 (0.0533) acc@1 0.9922 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:16] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:44:16] __main__ INFO: [0mVal 226
[32m[2022-06-16 11:44:17] __main__ INFO: [0mEpoch 226 loss 1.8903 acc@1 0.6564 acc@5 0.9625
[32m[2022-06-16 11:44:17] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:44:17] __main__ INFO: [0mTrain 227 8814
[32m[2022-06-16 11:44:19] __main__ INFO: [0mEpoch 227 Step 39/39 lr 0.001000 loss 0.0511 (0.0542) acc@1 0.9844 (0.9836) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:19] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:44:19] __main__ INFO: [0mVal 227
[32m[2022-06-16 11:44:20] __main__ INFO: [0mEpoch 227 loss 1.9085 acc@1 0.6554 acc@5 0.9629
[32m[2022-06-16 11:44:20] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:44:20] __main__ INFO: [0mTrain 228 8853
[32m[2022-06-16 11:44:21] __main__ INFO: [0mEpoch 228 Step 39/39 lr 0.001000 loss 0.0774 (0.0525) acc@1 0.9922 (0.9854) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:21] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:44:21] __main__ INFO: [0mVal 228
[32m[2022-06-16 11:44:22] __main__ INFO: [0mEpoch 228 loss 1.9008 acc@1 0.6554 acc@5 0.9624
[32m[2022-06-16 11:44:22] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:44:22] __main__ INFO: [0mTrain 229 8892
[32m[2022-06-16 11:44:24] __main__ INFO: [0mEpoch 229 Step 39/39 lr 0.001000 loss 0.0781 (0.0542) acc@1 0.9766 (0.9852) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:24] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:44:24] __main__ INFO: [0mVal 229
[32m[2022-06-16 11:44:25] __main__ INFO: [0mEpoch 229 loss 1.8961 acc@1 0.6549 acc@5 0.9618
[32m[2022-06-16 11:44:25] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:44:25] __main__ INFO: [0mTrain 230 8931
[32m[2022-06-16 11:44:26] __main__ INFO: [0mEpoch 230 Step 39/39 lr 0.001000 loss 0.0409 (0.0583) acc@1 0.9922 (0.9824) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:26] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:44:26] __main__ INFO: [0mVal 230
[32m[2022-06-16 11:44:27] __main__ INFO: [0mEpoch 230 loss 1.9093 acc@1 0.6520 acc@5 0.9617
[32m[2022-06-16 11:44:27] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:44:27] __main__ INFO: [0mTrain 231 8970
[32m[2022-06-16 11:44:29] __main__ INFO: [0mEpoch 231 Step 39/39 lr 0.001000 loss 0.0225 (0.0551) acc@1 1.0000 (0.9838) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:29] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:44:29] __main__ INFO: [0mVal 231
[32m[2022-06-16 11:44:29] __main__ INFO: [0mEpoch 231 loss 1.8949 acc@1 0.6559 acc@5 0.9627
[32m[2022-06-16 11:44:29] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:44:29] __main__ INFO: [0mTrain 232 9009
[32m[2022-06-16 11:44:31] __main__ INFO: [0mEpoch 232 Step 39/39 lr 0.001000 loss 0.0291 (0.0510) acc@1 0.9922 (0.9862) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:31] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:44:31] __main__ INFO: [0mVal 232
[32m[2022-06-16 11:44:32] __main__ INFO: [0mEpoch 232 loss 1.9079 acc@1 0.6538 acc@5 0.9624
[32m[2022-06-16 11:44:32] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:44:32] __main__ INFO: [0mTrain 233 9048
[32m[2022-06-16 11:44:33] __main__ INFO: [0mEpoch 233 Step 39/39 lr 0.001000 loss 0.0814 (0.0524) acc@1 0.9609 (0.9868) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:34] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:44:34] __main__ INFO: [0mVal 233
[32m[2022-06-16 11:44:34] __main__ INFO: [0mEpoch 233 loss 1.9068 acc@1 0.6539 acc@5 0.9624
[32m[2022-06-16 11:44:34] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:44:34] __main__ INFO: [0mTrain 234 9087
[32m[2022-06-16 11:44:36] __main__ INFO: [0mEpoch 234 Step 39/39 lr 0.001000 loss 0.0307 (0.0471) acc@1 1.0000 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:36] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:44:36] __main__ INFO: [0mVal 234
[32m[2022-06-16 11:44:37] __main__ INFO: [0mEpoch 234 loss 1.9042 acc@1 0.6572 acc@5 0.9624
[32m[2022-06-16 11:44:37] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:44:37] __main__ INFO: [0mTrain 235 9126
[32m[2022-06-16 11:44:38] __main__ INFO: [0mEpoch 235 Step 39/39 lr 0.001000 loss 0.0391 (0.0509) acc@1 0.9844 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:38] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:44:38] __main__ INFO: [0mVal 235
[32m[2022-06-16 11:44:39] __main__ INFO: [0mEpoch 235 loss 1.9106 acc@1 0.6555 acc@5 0.9628
[32m[2022-06-16 11:44:39] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:44:39] __main__ INFO: [0mTrain 236 9165
[32m[2022-06-16 11:44:41] __main__ INFO: [0mEpoch 236 Step 39/39 lr 0.001000 loss 0.0275 (0.0519) acc@1 1.0000 (0.9844) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:41] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:44:41] __main__ INFO: [0mVal 236
[32m[2022-06-16 11:44:42] __main__ INFO: [0mEpoch 236 loss 1.9069 acc@1 0.6523 acc@5 0.9637
[32m[2022-06-16 11:44:42] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:44:42] __main__ INFO: [0mTrain 237 9204
[32m[2022-06-16 11:44:43] __main__ INFO: [0mEpoch 237 Step 39/39 lr 0.001000 loss 0.0604 (0.0520) acc@1 0.9766 (0.9872) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:43] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:44:43] __main__ INFO: [0mVal 237
[32m[2022-06-16 11:44:44] __main__ INFO: [0mEpoch 237 loss 1.9048 acc@1 0.6560 acc@5 0.9630
[32m[2022-06-16 11:44:44] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:44:44] __main__ INFO: [0mTrain 238 9243
[32m[2022-06-16 11:44:46] __main__ INFO: [0mEpoch 238 Step 39/39 lr 0.001000 loss 0.0641 (0.0525) acc@1 0.9766 (0.9850) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:46] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:44:46] __main__ INFO: [0mVal 238
[32m[2022-06-16 11:44:47] __main__ INFO: [0mEpoch 238 loss 1.9176 acc@1 0.6536 acc@5 0.9632
[32m[2022-06-16 11:44:47] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:44:47] __main__ INFO: [0mTrain 239 9282
[32m[2022-06-16 11:44:48] __main__ INFO: [0mEpoch 239 Step 39/39 lr 0.001000 loss 0.0656 (0.0540) acc@1 0.9688 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:48] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:44:48] __main__ INFO: [0mVal 239
[32m[2022-06-16 11:44:49] __main__ INFO: [0mEpoch 239 loss 1.9207 acc@1 0.6541 acc@5 0.9638
[32m[2022-06-16 11:44:49] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:44:49] __main__ INFO: [0mTrain 240 9321
[32m[2022-06-16 11:44:50] __main__ INFO: [0mEpoch 240 Step 39/39 lr 0.001000 loss 0.0766 (0.0512) acc@1 0.9844 (0.9870) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:51] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:44:51] __main__ INFO: [0mVal 240
[32m[2022-06-16 11:44:51] __main__ INFO: [0mEpoch 240 loss 1.9132 acc@1 0.6545 acc@5 0.9623
[32m[2022-06-16 11:44:51] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:44:51] __main__ INFO: [0mTrain 241 9360
[32m[2022-06-16 11:44:53] __main__ INFO: [0mEpoch 241 Step 39/39 lr 0.001000 loss 0.0470 (0.0439) acc@1 0.9844 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:53] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:44:53] __main__ INFO: [0mVal 241
[32m[2022-06-16 11:44:54] __main__ INFO: [0mEpoch 241 loss 1.9167 acc@1 0.6546 acc@5 0.9625
[32m[2022-06-16 11:44:54] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:44:54] __main__ INFO: [0mTrain 242 9399
[32m[2022-06-16 11:44:55] __main__ INFO: [0mEpoch 242 Step 39/39 lr 0.001000 loss 0.0243 (0.0481) acc@1 1.0000 (0.9870) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:55] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:44:55] __main__ INFO: [0mVal 242
[32m[2022-06-16 11:44:56] __main__ INFO: [0mEpoch 242 loss 1.8975 acc@1 0.6575 acc@5 0.9633
[32m[2022-06-16 11:44:56] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:44:56] __main__ INFO: [0mTrain 243 9438
[32m[2022-06-16 11:44:58] __main__ INFO: [0mEpoch 243 Step 39/39 lr 0.001000 loss 0.0243 (0.0460) acc@1 0.9922 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:44:58] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:44:58] __main__ INFO: [0mVal 243
[32m[2022-06-16 11:44:59] __main__ INFO: [0mEpoch 243 loss 1.9248 acc@1 0.6546 acc@5 0.9620
[32m[2022-06-16 11:44:59] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:44:59] __main__ INFO: [0mTrain 244 9477
[32m[2022-06-16 11:45:00] __main__ INFO: [0mEpoch 244 Step 39/39 lr 0.001000 loss 0.0708 (0.0530) acc@1 0.9609 (0.9850) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:00] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:45:00] __main__ INFO: [0mVal 244
[32m[2022-06-16 11:45:01] __main__ INFO: [0mEpoch 244 loss 1.9189 acc@1 0.6564 acc@5 0.9638
[32m[2022-06-16 11:45:01] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:45:01] __main__ INFO: [0mTrain 245 9516
[32m[2022-06-16 11:45:03] __main__ INFO: [0mEpoch 245 Step 39/39 lr 0.001000 loss 0.0304 (0.0463) acc@1 1.0000 (0.9866) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:03] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:45:03] __main__ INFO: [0mVal 245
[32m[2022-06-16 11:45:03] __main__ INFO: [0mEpoch 245 loss 1.9113 acc@1 0.6549 acc@5 0.9630
[32m[2022-06-16 11:45:03] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:45:03] __main__ INFO: [0mTrain 246 9555
[32m[2022-06-16 11:45:05] __main__ INFO: [0mEpoch 246 Step 39/39 lr 0.001000 loss 0.0489 (0.0473) acc@1 0.9844 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:05] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:45:05] __main__ INFO: [0mVal 246
[32m[2022-06-16 11:45:06] __main__ INFO: [0mEpoch 246 loss 1.9236 acc@1 0.6552 acc@5 0.9632
[32m[2022-06-16 11:45:06] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:45:06] __main__ INFO: [0mTrain 247 9594
[32m[2022-06-16 11:45:07] __main__ INFO: [0mEpoch 247 Step 39/39 lr 0.001000 loss 0.0472 (0.0505) acc@1 0.9844 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:07] __main__ INFO: [0mElapsed 1.50
[32m[2022-06-16 11:45:07] __main__ INFO: [0mVal 247
[32m[2022-06-16 11:45:08] __main__ INFO: [0mEpoch 247 loss 1.9221 acc@1 0.6535 acc@5 0.9637
[32m[2022-06-16 11:45:08] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:45:08] __main__ INFO: [0mTrain 248 9633
[32m[2022-06-16 11:45:10] __main__ INFO: [0mEpoch 248 Step 39/39 lr 0.001000 loss 0.0700 (0.0430) acc@1 0.9766 (0.9896) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:10] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:45:10] __main__ INFO: [0mVal 248
[32m[2022-06-16 11:45:11] __main__ INFO: [0mEpoch 248 loss 1.9216 acc@1 0.6551 acc@5 0.9627
[32m[2022-06-16 11:45:11] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:45:11] __main__ INFO: [0mTrain 249 9672
[32m[2022-06-16 11:45:12] __main__ INFO: [0mEpoch 249 Step 39/39 lr 0.001000 loss 0.0838 (0.0529) acc@1 0.9766 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:12] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-16 11:45:12] __main__ INFO: [0mVal 249
[32m[2022-06-16 11:45:13] __main__ INFO: [0mEpoch 249 loss 1.9144 acc@1 0.6546 acc@5 0.9639
[32m[2022-06-16 11:45:13] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:45:13] __main__ INFO: [0mTrain 250 9711
[32m[2022-06-16 11:45:15] __main__ INFO: [0mEpoch 250 Step 39/39 lr 0.001000 loss 0.0253 (0.0477) acc@1 1.0000 (0.9878) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:15] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:45:15] __main__ INFO: [0mVal 250
[32m[2022-06-16 11:45:15] __main__ INFO: [0mEpoch 250 loss 1.9179 acc@1 0.6544 acc@5 0.9624
[32m[2022-06-16 11:45:15] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:45:15] __main__ INFO: [0mTrain 251 9750
[32m[2022-06-16 11:45:17] __main__ INFO: [0mEpoch 251 Step 39/39 lr 0.001000 loss 0.0399 (0.0495) acc@1 0.9766 (0.9868) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:17] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:45:17] __main__ INFO: [0mVal 251
[32m[2022-06-16 11:45:18] __main__ INFO: [0mEpoch 251 loss 1.9415 acc@1 0.6536 acc@5 0.9630
[32m[2022-06-16 11:45:18] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:45:18] __main__ INFO: [0mTrain 252 9789
[32m[2022-06-16 11:45:20] __main__ INFO: [0mEpoch 252 Step 39/39 lr 0.001000 loss 0.0751 (0.0503) acc@1 0.9766 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:20] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:45:20] __main__ INFO: [0mVal 252
[32m[2022-06-16 11:45:20] __main__ INFO: [0mEpoch 252 loss 1.9368 acc@1 0.6552 acc@5 0.9631
[32m[2022-06-16 11:45:20] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:45:20] __main__ INFO: [0mTrain 253 9828
[32m[2022-06-16 11:45:22] __main__ INFO: [0mEpoch 253 Step 39/39 lr 0.001000 loss 0.0413 (0.0487) acc@1 0.9844 (0.9856) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:22] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:45:22] __main__ INFO: [0mVal 253
[32m[2022-06-16 11:45:23] __main__ INFO: [0mEpoch 253 loss 1.9368 acc@1 0.6540 acc@5 0.9629
[32m[2022-06-16 11:45:23] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:45:23] __main__ INFO: [0mTrain 254 9867
[32m[2022-06-16 11:45:25] __main__ INFO: [0mEpoch 254 Step 39/39 lr 0.001000 loss 0.0684 (0.0454) acc@1 0.9688 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:25] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:45:25] __main__ INFO: [0mVal 254
[32m[2022-06-16 11:45:25] __main__ INFO: [0mEpoch 254 loss 1.9241 acc@1 0.6557 acc@5 0.9632
[32m[2022-06-16 11:45:25] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-16 11:45:25] __main__ INFO: [0mTrain 255 9906
[32m[2022-06-16 11:45:27] __main__ INFO: [0mEpoch 255 Step 39/39 lr 0.001000 loss 0.0630 (0.0512) acc@1 0.9844 (0.9854) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:27] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:45:27] __main__ INFO: [0mVal 255
[32m[2022-06-16 11:45:28] __main__ INFO: [0mEpoch 255 loss 1.9418 acc@1 0.6553 acc@5 0.9623
[32m[2022-06-16 11:45:28] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:45:28] __main__ INFO: [0mTrain 256 9945
[32m[2022-06-16 11:45:29] __main__ INFO: [0mEpoch 256 Step 39/39 lr 0.001000 loss 0.1034 (0.0537) acc@1 0.9609 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:29] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:45:29] __main__ INFO: [0mVal 256
[32m[2022-06-16 11:45:30] __main__ INFO: [0mEpoch 256 loss 1.9336 acc@1 0.6553 acc@5 0.9621
[32m[2022-06-16 11:45:30] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:45:30] __main__ INFO: [0mTrain 257 9984
[32m[2022-06-16 11:45:32] __main__ INFO: [0mEpoch 257 Step 39/39 lr 0.001000 loss 0.0499 (0.0513) acc@1 1.0000 (0.9856) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:32] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:45:32] __main__ INFO: [0mVal 257
[32m[2022-06-16 11:45:33] __main__ INFO: [0mEpoch 257 loss 1.9397 acc@1 0.6551 acc@5 0.9623
[32m[2022-06-16 11:45:33] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:45:33] __main__ INFO: [0mTrain 258 10023
[32m[2022-06-16 11:45:34] __main__ INFO: [0mEpoch 258 Step 39/39 lr 0.001000 loss 0.0442 (0.0450) acc@1 0.9922 (0.9890) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:34] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:45:34] __main__ INFO: [0mVal 258
[32m[2022-06-16 11:45:35] __main__ INFO: [0mEpoch 258 loss 1.9410 acc@1 0.6555 acc@5 0.9630
[32m[2022-06-16 11:45:35] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:45:35] __main__ INFO: [0mTrain 259 10062
[32m[2022-06-16 11:45:37] __main__ INFO: [0mEpoch 259 Step 39/39 lr 0.001000 loss 0.0684 (0.0516) acc@1 0.9688 (0.9848) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:37] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:45:37] __main__ INFO: [0mVal 259
[32m[2022-06-16 11:45:37] __main__ INFO: [0mEpoch 259 loss 1.9419 acc@1 0.6570 acc@5 0.9630
[32m[2022-06-16 11:45:37] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-16 11:45:37] __main__ INFO: [0mTrain 260 10101
[32m[2022-06-16 11:45:39] __main__ INFO: [0mEpoch 260 Step 39/39 lr 0.001000 loss 0.0441 (0.0513) acc@1 0.9922 (0.9842) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:39] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:45:39] __main__ INFO: [0mVal 260
[32m[2022-06-16 11:45:40] __main__ INFO: [0mEpoch 260 loss 1.9353 acc@1 0.6552 acc@5 0.9638
[32m[2022-06-16 11:45:40] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:45:40] __main__ INFO: [0mTrain 261 10140
[32m[2022-06-16 11:45:42] __main__ INFO: [0mEpoch 261 Step 39/39 lr 0.001000 loss 0.0816 (0.0427) acc@1 0.9844 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:42] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:45:42] __main__ INFO: [0mVal 261
[32m[2022-06-16 11:45:42] __main__ INFO: [0mEpoch 261 loss 1.9433 acc@1 0.6570 acc@5 0.9630
[32m[2022-06-16 11:45:42] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:45:42] __main__ INFO: [0mTrain 262 10179
[32m[2022-06-16 11:45:44] __main__ INFO: [0mEpoch 262 Step 39/39 lr 0.001000 loss 0.0624 (0.0476) acc@1 0.9844 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:44] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:45:44] __main__ INFO: [0mVal 262
[32m[2022-06-16 11:45:45] __main__ INFO: [0mEpoch 262 loss 1.9388 acc@1 0.6567 acc@5 0.9633
[32m[2022-06-16 11:45:45] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:45:45] __main__ INFO: [0mTrain 263 10218
[32m[2022-06-16 11:45:46] __main__ INFO: [0mEpoch 263 Step 39/39 lr 0.001000 loss 0.0337 (0.0523) acc@1 0.9922 (0.9834) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:47] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:45:47] __main__ INFO: [0mVal 263
[32m[2022-06-16 11:45:47] __main__ INFO: [0mEpoch 263 loss 1.9457 acc@1 0.6550 acc@5 0.9624
[32m[2022-06-16 11:45:47] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:45:47] __main__ INFO: [0mTrain 264 10257
[32m[2022-06-16 11:45:49] __main__ INFO: [0mEpoch 264 Step 39/39 lr 0.001000 loss 0.0812 (0.0509) acc@1 0.9766 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:49] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:45:49] __main__ INFO: [0mVal 264
[32m[2022-06-16 11:45:50] __main__ INFO: [0mEpoch 264 loss 1.9488 acc@1 0.6552 acc@5 0.9624
[32m[2022-06-16 11:45:50] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:45:50] __main__ INFO: [0mTrain 265 10296
[32m[2022-06-16 11:45:51] __main__ INFO: [0mEpoch 265 Step 39/39 lr 0.001000 loss 0.0660 (0.0482) acc@1 0.9688 (0.9858) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:51] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-16 11:45:51] __main__ INFO: [0mVal 265
[32m[2022-06-16 11:45:52] __main__ INFO: [0mEpoch 265 loss 1.9424 acc@1 0.6534 acc@5 0.9631
[32m[2022-06-16 11:45:52] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:45:52] __main__ INFO: [0mTrain 266 10335
[32m[2022-06-16 11:45:54] __main__ INFO: [0mEpoch 266 Step 39/39 lr 0.001000 loss 0.0404 (0.0433) acc@1 0.9922 (0.9890) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:54] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:45:54] __main__ INFO: [0mVal 266
[32m[2022-06-16 11:45:55] __main__ INFO: [0mEpoch 266 loss 1.9579 acc@1 0.6549 acc@5 0.9623
[32m[2022-06-16 11:45:55] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:45:55] __main__ INFO: [0mTrain 267 10374
[32m[2022-06-16 11:45:56] __main__ INFO: [0mEpoch 267 Step 39/39 lr 0.001000 loss 0.0318 (0.0484) acc@1 0.9922 (0.9872) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:45:56] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:45:56] __main__ INFO: [0mVal 267
[32m[2022-06-16 11:45:57] __main__ INFO: [0mEpoch 267 loss 1.9600 acc@1 0.6538 acc@5 0.9616
[32m[2022-06-16 11:45:57] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:45:57] __main__ INFO: [0mTrain 268 10413
[32m[2022-06-16 11:45:59] __main__ INFO: [0mEpoch 268 Step 39/39 lr 0.001000 loss 0.0684 (0.0449) acc@1 0.9688 (0.9888) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:45:59] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:45:59] __main__ INFO: [0mVal 268
[32m[2022-06-16 11:46:00] __main__ INFO: [0mEpoch 268 loss 1.9538 acc@1 0.6549 acc@5 0.9633
[32m[2022-06-16 11:46:00] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:46:00] __main__ INFO: [0mTrain 269 10452
[32m[2022-06-16 11:46:01] __main__ INFO: [0mEpoch 269 Step 39/39 lr 0.001000 loss 0.0336 (0.0439) acc@1 0.9922 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:01] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:46:01] __main__ INFO: [0mVal 269
[32m[2022-06-16 11:46:02] __main__ INFO: [0mEpoch 269 loss 1.9644 acc@1 0.6529 acc@5 0.9627
[32m[2022-06-16 11:46:02] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:46:02] __main__ INFO: [0mTrain 270 10491
[32m[2022-06-16 11:46:04] __main__ INFO: [0mEpoch 270 Step 39/39 lr 0.001000 loss 0.0358 (0.0516) acc@1 0.9922 (0.9868) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:04] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:46:04] __main__ INFO: [0mVal 270
[32m[2022-06-16 11:46:04] __main__ INFO: [0mEpoch 270 loss 1.9383 acc@1 0.6552 acc@5 0.9628
[32m[2022-06-16 11:46:04] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:46:04] __main__ INFO: [0mTrain 271 10530
[32m[2022-06-16 11:46:06] __main__ INFO: [0mEpoch 271 Step 39/39 lr 0.001000 loss 0.0776 (0.0483) acc@1 0.9844 (0.9858) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:06] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:46:06] __main__ INFO: [0mVal 271
[32m[2022-06-16 11:46:07] __main__ INFO: [0mEpoch 271 loss 1.9601 acc@1 0.6542 acc@5 0.9627
[32m[2022-06-16 11:46:07] __main__ INFO: [0mElapsed 0.66
[32m[2022-06-16 11:46:07] __main__ INFO: [0mTrain 272 10569
[32m[2022-06-16 11:46:08] __main__ INFO: [0mEpoch 272 Step 39/39 lr 0.001000 loss 0.1060 (0.0561) acc@1 0.9609 (0.9846) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:08] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:46:08] __main__ INFO: [0mVal 272
[32m[2022-06-16 11:46:09] __main__ INFO: [0mEpoch 272 loss 1.9730 acc@1 0.6521 acc@5 0.9623
[32m[2022-06-16 11:46:09] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:46:09] __main__ INFO: [0mTrain 273 10608
[32m[2022-06-16 11:46:11] __main__ INFO: [0mEpoch 273 Step 39/39 lr 0.001000 loss 0.0798 (0.0526) acc@1 0.9688 (0.9848) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:11] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:46:11] __main__ INFO: [0mVal 273
[32m[2022-06-16 11:46:12] __main__ INFO: [0mEpoch 273 loss 1.9613 acc@1 0.6540 acc@5 0.9617
[32m[2022-06-16 11:46:12] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:46:12] __main__ INFO: [0mTrain 274 10647
[32m[2022-06-16 11:46:13] __main__ INFO: [0mEpoch 274 Step 39/39 lr 0.001000 loss 0.0318 (0.0447) acc@1 0.9922 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:13] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:46:13] __main__ INFO: [0mVal 274
[32m[2022-06-16 11:46:14] __main__ INFO: [0mEpoch 274 loss 1.9624 acc@1 0.6534 acc@5 0.9625
[32m[2022-06-16 11:46:14] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:46:14] __main__ INFO: [0mTrain 275 10686
[32m[2022-06-16 11:46:15] __main__ INFO: [0mEpoch 275 Step 39/39 lr 0.001000 loss 0.0314 (0.0450) acc@1 1.0000 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:16] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:46:16] __main__ INFO: [0mVal 275
[32m[2022-06-16 11:46:16] __main__ INFO: [0mEpoch 275 loss 1.9588 acc@1 0.6532 acc@5 0.9628
[32m[2022-06-16 11:46:16] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:46:16] __main__ INFO: [0mTrain 276 10725
[32m[2022-06-16 11:46:18] __main__ INFO: [0mEpoch 276 Step 39/39 lr 0.001000 loss 0.0431 (0.0454) acc@1 0.9844 (0.9880) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:18] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:46:18] __main__ INFO: [0mVal 276
[32m[2022-06-16 11:46:19] __main__ INFO: [0mEpoch 276 loss 1.9557 acc@1 0.6543 acc@5 0.9623
[32m[2022-06-16 11:46:19] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:46:19] __main__ INFO: [0mTrain 277 10764
[32m[2022-06-16 11:46:20] __main__ INFO: [0mEpoch 277 Step 39/39 lr 0.001000 loss 0.0328 (0.0453) acc@1 0.9922 (0.9878) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:20] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:46:20] __main__ INFO: [0mVal 277
[32m[2022-06-16 11:46:21] __main__ INFO: [0mEpoch 277 loss 1.9593 acc@1 0.6556 acc@5 0.9629
[32m[2022-06-16 11:46:21] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:46:21] __main__ INFO: [0mTrain 278 10803
[32m[2022-06-16 11:46:23] __main__ INFO: [0mEpoch 278 Step 39/39 lr 0.001000 loss 0.0744 (0.0514) acc@1 0.9688 (0.9848) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:23] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:46:23] __main__ INFO: [0mVal 278
[32m[2022-06-16 11:46:24] __main__ INFO: [0mEpoch 278 loss 1.9487 acc@1 0.6562 acc@5 0.9623
[32m[2022-06-16 11:46:24] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:46:24] __main__ INFO: [0mTrain 279 10842
[32m[2022-06-16 11:46:25] __main__ INFO: [0mEpoch 279 Step 39/39 lr 0.001000 loss 0.0496 (0.0453) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:25] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:46:25] __main__ INFO: [0mVal 279
[32m[2022-06-16 11:46:26] __main__ INFO: [0mEpoch 279 loss 1.9646 acc@1 0.6544 acc@5 0.9631
[32m[2022-06-16 11:46:26] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:46:26] __main__ INFO: [0mTrain 280 10881
[32m[2022-06-16 11:46:28] __main__ INFO: [0mEpoch 280 Step 39/39 lr 0.001000 loss 0.0608 (0.0476) acc@1 0.9844 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:28] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:46:28] __main__ INFO: [0mVal 280
[32m[2022-06-16 11:46:28] __main__ INFO: [0mEpoch 280 loss 1.9545 acc@1 0.6559 acc@5 0.9629
[32m[2022-06-16 11:46:28] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:46:28] __main__ INFO: [0mTrain 281 10920
[32m[2022-06-16 11:46:30] __main__ INFO: [0mEpoch 281 Step 39/39 lr 0.001000 loss 0.0543 (0.0447) acc@1 0.9844 (0.9880) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:30] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:46:30] __main__ INFO: [0mVal 281
[32m[2022-06-16 11:46:31] __main__ INFO: [0mEpoch 281 loss 1.9567 acc@1 0.6564 acc@5 0.9621
[32m[2022-06-16 11:46:31] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:46:31] __main__ INFO: [0mTrain 282 10959
[32m[2022-06-16 11:46:33] __main__ INFO: [0mEpoch 282 Step 39/39 lr 0.001000 loss 0.0358 (0.0456) acc@1 0.9844 (0.9874) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:33] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:46:33] __main__ INFO: [0mVal 282
[32m[2022-06-16 11:46:33] __main__ INFO: [0mEpoch 282 loss 1.9564 acc@1 0.6553 acc@5 0.9627
[32m[2022-06-16 11:46:33] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:46:33] __main__ INFO: [0mTrain 283 10998
[32m[2022-06-16 11:46:35] __main__ INFO: [0mEpoch 283 Step 39/39 lr 0.001000 loss 0.0399 (0.0440) acc@1 0.9922 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:35] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:46:35] __main__ INFO: [0mVal 283
[32m[2022-06-16 11:46:36] __main__ INFO: [0mEpoch 283 loss 1.9710 acc@1 0.6555 acc@5 0.9628
[32m[2022-06-16 11:46:36] __main__ INFO: [0mElapsed 0.85
[32m[2022-06-16 11:46:36] __main__ INFO: [0mTrain 284 11037
[32m[2022-06-16 11:46:37] __main__ INFO: [0mEpoch 284 Step 39/39 lr 0.001000 loss 0.0517 (0.0496) acc@1 0.9922 (0.9868) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:37] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:46:37] __main__ INFO: [0mVal 284
[32m[2022-06-16 11:46:38] __main__ INFO: [0mEpoch 284 loss 1.9677 acc@1 0.6524 acc@5 0.9626
[32m[2022-06-16 11:46:38] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:46:38] __main__ INFO: [0mTrain 285 11076
[32m[2022-06-16 11:46:40] __main__ INFO: [0mEpoch 285 Step 39/39 lr 0.001000 loss 0.0297 (0.0432) acc@1 0.9922 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:40] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:46:40] __main__ INFO: [0mVal 285
[32m[2022-06-16 11:46:41] __main__ INFO: [0mEpoch 285 loss 1.9771 acc@1 0.6555 acc@5 0.9622
[32m[2022-06-16 11:46:41] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:46:41] __main__ INFO: [0mTrain 286 11115
[32m[2022-06-16 11:46:42] __main__ INFO: [0mEpoch 286 Step 39/39 lr 0.001000 loss 0.0848 (0.0443) acc@1 0.9609 (0.9876) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:42] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:46:42] __main__ INFO: [0mVal 286
[32m[2022-06-16 11:46:43] __main__ INFO: [0mEpoch 286 loss 1.9756 acc@1 0.6537 acc@5 0.9629
[32m[2022-06-16 11:46:43] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:46:43] __main__ INFO: [0mTrain 287 11154
[32m[2022-06-16 11:46:45] __main__ INFO: [0mEpoch 287 Step 39/39 lr 0.001000 loss 0.0553 (0.0453) acc@1 0.9844 (0.9880) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:45] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:46:45] __main__ INFO: [0mVal 287
[32m[2022-06-16 11:46:46] __main__ INFO: [0mEpoch 287 loss 1.9806 acc@1 0.6554 acc@5 0.9625
[32m[2022-06-16 11:46:46] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:46:46] __main__ INFO: [0mTrain 288 11193
[32m[2022-06-16 11:46:47] __main__ INFO: [0mEpoch 288 Step 39/39 lr 0.001000 loss 0.0331 (0.0435) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:47] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:46:47] __main__ INFO: [0mVal 288
[32m[2022-06-16 11:46:48] __main__ INFO: [0mEpoch 288 loss 1.9822 acc@1 0.6550 acc@5 0.9628
[32m[2022-06-16 11:46:48] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:46:48] __main__ INFO: [0mTrain 289 11232
[32m[2022-06-16 11:46:50] __main__ INFO: [0mEpoch 289 Step 39/39 lr 0.001000 loss 0.0401 (0.0468) acc@1 0.9922 (0.9860) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:50] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:46:50] __main__ INFO: [0mVal 289
[32m[2022-06-16 11:46:50] __main__ INFO: [0mEpoch 289 loss 1.9725 acc@1 0.6560 acc@5 0.9629
[32m[2022-06-16 11:46:50] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:46:50] __main__ INFO: [0mTrain 290 11271
[32m[2022-06-16 11:46:52] __main__ INFO: [0mEpoch 290 Step 39/39 lr 0.001000 loss 0.0463 (0.0447) acc@1 0.9844 (0.9876) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:52] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:46:52] __main__ INFO: [0mVal 290
[32m[2022-06-16 11:46:53] __main__ INFO: [0mEpoch 290 loss 1.9649 acc@1 0.6547 acc@5 0.9640
[32m[2022-06-16 11:46:53] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:46:53] __main__ INFO: [0mTrain 291 11310
[32m[2022-06-16 11:46:54] __main__ INFO: [0mEpoch 291 Step 39/39 lr 0.001000 loss 0.0226 (0.0456) acc@1 1.0000 (0.9876) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:54] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:46:54] __main__ INFO: [0mVal 291
[32m[2022-06-16 11:46:55] __main__ INFO: [0mEpoch 291 loss 1.9791 acc@1 0.6554 acc@5 0.9625
[32m[2022-06-16 11:46:55] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:46:55] __main__ INFO: [0mTrain 292 11349
[32m[2022-06-16 11:46:57] __main__ INFO: [0mEpoch 292 Step 39/39 lr 0.001000 loss 0.0676 (0.0445) acc@1 0.9766 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:57] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:46:57] __main__ INFO: [0mVal 292
[32m[2022-06-16 11:46:58] __main__ INFO: [0mEpoch 292 loss 1.9809 acc@1 0.6546 acc@5 0.9625
[32m[2022-06-16 11:46:58] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:46:58] __main__ INFO: [0mTrain 293 11388
[32m[2022-06-16 11:46:59] __main__ INFO: [0mEpoch 293 Step 39/39 lr 0.001000 loss 0.0173 (0.0410) acc@1 1.0000 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:46:59] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:46:59] __main__ INFO: [0mVal 293
[32m[2022-06-16 11:47:00] __main__ INFO: [0mEpoch 293 loss 1.9703 acc@1 0.6569 acc@5 0.9627
[32m[2022-06-16 11:47:00] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:47:00] __main__ INFO: [0mTrain 294 11427
[32m[2022-06-16 11:47:02] __main__ INFO: [0mEpoch 294 Step 39/39 lr 0.001000 loss 0.0413 (0.0430) acc@1 0.9922 (0.9872) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:02] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:47:02] __main__ INFO: [0mVal 294
[32m[2022-06-16 11:47:03] __main__ INFO: [0mEpoch 294 loss 1.9739 acc@1 0.6558 acc@5 0.9633
[32m[2022-06-16 11:47:03] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:47:03] __main__ INFO: [0mTrain 295 11466
[32m[2022-06-16 11:47:04] __main__ INFO: [0mEpoch 295 Step 39/39 lr 0.001000 loss 0.0623 (0.0367) acc@1 0.9609 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:04] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:47:04] __main__ INFO: [0mVal 295
[32m[2022-06-16 11:47:05] __main__ INFO: [0mEpoch 295 loss 1.9767 acc@1 0.6549 acc@5 0.9632
[32m[2022-06-16 11:47:05] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:47:05] __main__ INFO: [0mTrain 296 11505
[32m[2022-06-16 11:47:07] __main__ INFO: [0mEpoch 296 Step 39/39 lr 0.001000 loss 0.0670 (0.0418) acc@1 0.9688 (0.9876) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:07] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:47:07] __main__ INFO: [0mVal 296
[32m[2022-06-16 11:47:08] __main__ INFO: [0mEpoch 296 loss 1.9865 acc@1 0.6556 acc@5 0.9631
[32m[2022-06-16 11:47:08] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-16 11:47:08] __main__ INFO: [0mTrain 297 11544
[32m[2022-06-16 11:47:09] __main__ INFO: [0mEpoch 297 Step 39/39 lr 0.001000 loss 0.0467 (0.0447) acc@1 0.9766 (0.9876) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:09] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:47:09] __main__ INFO: [0mVal 297
[32m[2022-06-16 11:47:10] __main__ INFO: [0mEpoch 297 loss 1.9810 acc@1 0.6557 acc@5 0.9643
[32m[2022-06-16 11:47:10] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:47:10] __main__ INFO: [0mTrain 298 11583
[32m[2022-06-16 11:47:12] __main__ INFO: [0mEpoch 298 Step 39/39 lr 0.001000 loss 0.0214 (0.0425) acc@1 1.0000 (0.9892) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:12] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:47:12] __main__ INFO: [0mVal 298
[32m[2022-06-16 11:47:13] __main__ INFO: [0mEpoch 298 loss 1.9738 acc@1 0.6577 acc@5 0.9621
[32m[2022-06-16 11:47:13] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:47:13] __main__ INFO: [0mTrain 299 11622
[32m[2022-06-16 11:47:14] __main__ INFO: [0mEpoch 299 Step 39/39 lr 0.001000 loss 0.0437 (0.0394) acc@1 0.9844 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:14] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:47:14] __main__ INFO: [0mVal 299
[32m[2022-06-16 11:47:15] __main__ INFO: [0mEpoch 299 loss 2.0062 acc@1 0.6541 acc@5 0.9619
[32m[2022-06-16 11:47:15] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:47:15] __main__ INFO: [0mTrain 300 11661
[32m[2022-06-16 11:47:17] __main__ INFO: [0mEpoch 300 Step 39/39 lr 0.001000 loss 0.0298 (0.0424) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:17] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:47:17] __main__ INFO: [0mVal 300
[32m[2022-06-16 11:47:17] __main__ INFO: [0mEpoch 300 loss 1.9937 acc@1 0.6566 acc@5 0.9623
[32m[2022-06-16 11:47:17] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:47:17] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00300.pth
[32m[2022-06-16 11:47:17] __main__ INFO: [0mTrain 301 11700
[32m[2022-06-16 11:47:19] __main__ INFO: [0mEpoch 301 Step 39/39 lr 0.001000 loss 0.0328 (0.0457) acc@1 0.9922 (0.9872) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:19] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:47:19] __main__ INFO: [0mVal 301
[32m[2022-06-16 11:47:20] __main__ INFO: [0mEpoch 301 loss 1.9979 acc@1 0.6544 acc@5 0.9629
[32m[2022-06-16 11:47:20] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:47:20] __main__ INFO: [0mTrain 302 11739
[32m[2022-06-16 11:47:21] __main__ INFO: [0mEpoch 302 Step 39/39 lr 0.001000 loss 0.0940 (0.0414) acc@1 0.9844 (0.9892) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:22] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:47:22] __main__ INFO: [0mVal 302
[32m[2022-06-16 11:47:22] __main__ INFO: [0mEpoch 302 loss 1.9900 acc@1 0.6560 acc@5 0.9634
[32m[2022-06-16 11:47:22] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:47:22] __main__ INFO: [0mTrain 303 11778
[32m[2022-06-16 11:47:24] __main__ INFO: [0mEpoch 303 Step 39/39 lr 0.001000 loss 0.0220 (0.0420) acc@1 1.0000 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:24] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:47:24] __main__ INFO: [0mVal 303
[32m[2022-06-16 11:47:25] __main__ INFO: [0mEpoch 303 loss 1.9900 acc@1 0.6560 acc@5 0.9623
[32m[2022-06-16 11:47:25] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:47:25] __main__ INFO: [0mTrain 304 11817
[32m[2022-06-16 11:47:26] __main__ INFO: [0mEpoch 304 Step 39/39 lr 0.001000 loss 0.0232 (0.0376) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:26] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:47:26] __main__ INFO: [0mVal 304
[32m[2022-06-16 11:47:27] __main__ INFO: [0mEpoch 304 loss 1.9877 acc@1 0.6563 acc@5 0.9628
[32m[2022-06-16 11:47:27] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:47:27] __main__ INFO: [0mTrain 305 11856
[32m[2022-06-16 11:47:29] __main__ INFO: [0mEpoch 305 Step 39/39 lr 0.001000 loss 0.0191 (0.0386) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:29] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:47:29] __main__ INFO: [0mVal 305
[32m[2022-06-16 11:47:30] __main__ INFO: [0mEpoch 305 loss 1.9840 acc@1 0.6560 acc@5 0.9625
[32m[2022-06-16 11:47:30] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:47:30] __main__ INFO: [0mTrain 306 11895
[32m[2022-06-16 11:47:31] __main__ INFO: [0mEpoch 306 Step 39/39 lr 0.001000 loss 0.0402 (0.0432) acc@1 0.9922 (0.9904) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:31] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:47:31] __main__ INFO: [0mVal 306
[32m[2022-06-16 11:47:32] __main__ INFO: [0mEpoch 306 loss 2.0016 acc@1 0.6559 acc@5 0.9627
[32m[2022-06-16 11:47:32] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:47:32] __main__ INFO: [0mTrain 307 11934
[32m[2022-06-16 11:47:34] __main__ INFO: [0mEpoch 307 Step 39/39 lr 0.001000 loss 0.0244 (0.0465) acc@1 1.0000 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:34] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-16 11:47:34] __main__ INFO: [0mVal 307
[32m[2022-06-16 11:47:34] __main__ INFO: [0mEpoch 307 loss 1.9949 acc@1 0.6566 acc@5 0.9622
[32m[2022-06-16 11:47:34] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:47:34] __main__ INFO: [0mTrain 308 11973
[32m[2022-06-16 11:47:36] __main__ INFO: [0mEpoch 308 Step 39/39 lr 0.001000 loss 0.0162 (0.0427) acc@1 1.0000 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:36] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-16 11:47:36] __main__ INFO: [0mVal 308
[32m[2022-06-16 11:47:37] __main__ INFO: [0mEpoch 308 loss 2.0023 acc@1 0.6556 acc@5 0.9624
[32m[2022-06-16 11:47:37] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:47:37] __main__ INFO: [0mTrain 309 12012
[32m[2022-06-16 11:47:38] __main__ INFO: [0mEpoch 309 Step 39/39 lr 0.001000 loss 0.0596 (0.0474) acc@1 0.9766 (0.9864) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:38] __main__ INFO: [0mElapsed 1.58
[32m[2022-06-16 11:47:38] __main__ INFO: [0mVal 309
[32m[2022-06-16 11:47:39] __main__ INFO: [0mEpoch 309 loss 2.0298 acc@1 0.6528 acc@5 0.9614
[32m[2022-06-16 11:47:39] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:47:39] __main__ INFO: [0mTrain 310 12051
[32m[2022-06-16 11:47:41] __main__ INFO: [0mEpoch 310 Step 39/39 lr 0.001000 loss 0.0809 (0.0393) acc@1 0.9844 (0.9904) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:41] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:47:41] __main__ INFO: [0mVal 310
[32m[2022-06-16 11:47:42] __main__ INFO: [0mEpoch 310 loss 2.0083 acc@1 0.6550 acc@5 0.9614
[32m[2022-06-16 11:47:42] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:47:42] __main__ INFO: [0mTrain 311 12090
[32m[2022-06-16 11:47:43] __main__ INFO: [0mEpoch 311 Step 39/39 lr 0.001000 loss 0.0313 (0.0418) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:43] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:47:43] __main__ INFO: [0mVal 311
[32m[2022-06-16 11:47:44] __main__ INFO: [0mEpoch 311 loss 2.0062 acc@1 0.6569 acc@5 0.9625
[32m[2022-06-16 11:47:44] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:47:44] __main__ INFO: [0mTrain 312 12129
[32m[2022-06-16 11:47:46] __main__ INFO: [0mEpoch 312 Step 39/39 lr 0.001000 loss 0.0725 (0.0422) acc@1 0.9844 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:46] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:47:46] __main__ INFO: [0mVal 312
[32m[2022-06-16 11:47:47] __main__ INFO: [0mEpoch 312 loss 2.0093 acc@1 0.6533 acc@5 0.9623
[32m[2022-06-16 11:47:47] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:47:47] __main__ INFO: [0mTrain 313 12168
[32m[2022-06-16 11:47:48] __main__ INFO: [0mEpoch 313 Step 39/39 lr 0.001000 loss 0.0306 (0.0410) acc@1 1.0000 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:48] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:47:48] __main__ INFO: [0mVal 313
[32m[2022-06-16 11:47:49] __main__ INFO: [0mEpoch 313 loss 1.9992 acc@1 0.6558 acc@5 0.9619
[32m[2022-06-16 11:47:49] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:47:49] __main__ INFO: [0mTrain 314 12207
[32m[2022-06-16 11:47:51] __main__ INFO: [0mEpoch 314 Step 39/39 lr 0.001000 loss 0.0319 (0.0396) acc@1 0.9922 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:51] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:47:51] __main__ INFO: [0mVal 314
[32m[2022-06-16 11:47:51] __main__ INFO: [0mEpoch 314 loss 2.0074 acc@1 0.6560 acc@5 0.9622
[32m[2022-06-16 11:47:51] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:47:51] __main__ INFO: [0mTrain 315 12246
[32m[2022-06-16 11:47:53] __main__ INFO: [0mEpoch 315 Step 39/39 lr 0.001000 loss 0.0449 (0.0370) acc@1 0.9766 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:53] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:47:53] __main__ INFO: [0mVal 315
[32m[2022-06-16 11:47:54] __main__ INFO: [0mEpoch 315 loss 2.0033 acc@1 0.6555 acc@5 0.9621
[32m[2022-06-16 11:47:54] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:47:54] __main__ INFO: [0mTrain 316 12285
[32m[2022-06-16 11:47:55] __main__ INFO: [0mEpoch 316 Step 39/39 lr 0.001000 loss 0.0494 (0.0381) acc@1 0.9844 (0.9908) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:47:55] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:47:55] __main__ INFO: [0mVal 316
[32m[2022-06-16 11:47:56] __main__ INFO: [0mEpoch 316 loss 1.9924 acc@1 0.6563 acc@5 0.9627
[32m[2022-06-16 11:47:56] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:47:56] __main__ INFO: [0mTrain 317 12324
[32m[2022-06-16 11:47:58] __main__ INFO: [0mEpoch 317 Step 39/39 lr 0.001000 loss 0.0287 (0.0405) acc@1 0.9922 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:47:58] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:47:58] __main__ INFO: [0mVal 317
[32m[2022-06-16 11:47:59] __main__ INFO: [0mEpoch 317 loss 2.0081 acc@1 0.6560 acc@5 0.9611
[32m[2022-06-16 11:47:59] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:47:59] __main__ INFO: [0mTrain 318 12363
[32m[2022-06-16 11:48:00] __main__ INFO: [0mEpoch 318 Step 39/39 lr 0.001000 loss 0.0512 (0.0372) acc@1 0.9844 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:00] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:48:00] __main__ INFO: [0mVal 318
[32m[2022-06-16 11:48:01] __main__ INFO: [0mEpoch 318 loss 2.0067 acc@1 0.6557 acc@5 0.9636
[32m[2022-06-16 11:48:01] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:48:01] __main__ INFO: [0mTrain 319 12402
[32m[2022-06-16 11:48:03] __main__ INFO: [0mEpoch 319 Step 39/39 lr 0.001000 loss 0.0285 (0.0408) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:03] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:48:03] __main__ INFO: [0mVal 319
[32m[2022-06-16 11:48:03] __main__ INFO: [0mEpoch 319 loss 2.0178 acc@1 0.6541 acc@5 0.9624
[32m[2022-06-16 11:48:03] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:48:03] __main__ INFO: [0mTrain 320 12441
[32m[2022-06-16 11:48:05] __main__ INFO: [0mEpoch 320 Step 39/39 lr 0.001000 loss 0.0307 (0.0403) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:05] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:48:05] __main__ INFO: [0mVal 320
[32m[2022-06-16 11:48:06] __main__ INFO: [0mEpoch 320 loss 2.0147 acc@1 0.6546 acc@5 0.9627
[32m[2022-06-16 11:48:06] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:48:06] __main__ INFO: [0mTrain 321 12480
[32m[2022-06-16 11:48:07] __main__ INFO: [0mEpoch 321 Step 39/39 lr 0.001000 loss 0.0355 (0.0388) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:07] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:48:07] __main__ INFO: [0mVal 321
[32m[2022-06-16 11:48:08] __main__ INFO: [0mEpoch 321 loss 2.0204 acc@1 0.6545 acc@5 0.9632
[32m[2022-06-16 11:48:08] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:48:08] __main__ INFO: [0mTrain 322 12519
[32m[2022-06-16 11:48:10] __main__ INFO: [0mEpoch 322 Step 39/39 lr 0.001000 loss 0.0553 (0.0377) acc@1 0.9766 (0.9906) acc@5 1.0000 (0.9998)
[32m[2022-06-16 11:48:10] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:48:10] __main__ INFO: [0mVal 322
[32m[2022-06-16 11:48:11] __main__ INFO: [0mEpoch 322 loss 2.0167 acc@1 0.6552 acc@5 0.9616
[32m[2022-06-16 11:48:11] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:48:11] __main__ INFO: [0mTrain 323 12558
[32m[2022-06-16 11:48:12] __main__ INFO: [0mEpoch 323 Step 39/39 lr 0.001000 loss 0.0487 (0.0386) acc@1 0.9766 (0.9890) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:12] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:48:12] __main__ INFO: [0mVal 323
[32m[2022-06-16 11:48:13] __main__ INFO: [0mEpoch 323 loss 2.0089 acc@1 0.6562 acc@5 0.9634
[32m[2022-06-16 11:48:13] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:48:13] __main__ INFO: [0mTrain 324 12597
[32m[2022-06-16 11:48:15] __main__ INFO: [0mEpoch 324 Step 39/39 lr 0.001000 loss 0.0305 (0.0357) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:15] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:48:15] __main__ INFO: [0mVal 324
[32m[2022-06-16 11:48:15] __main__ INFO: [0mEpoch 324 loss 2.0117 acc@1 0.6563 acc@5 0.9620
[32m[2022-06-16 11:48:15] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:48:15] __main__ INFO: [0mTrain 325 12636
[32m[2022-06-16 11:48:17] __main__ INFO: [0mEpoch 325 Step 39/39 lr 0.001000 loss 0.0340 (0.0388) acc@1 0.9922 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:17] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:48:17] __main__ INFO: [0mVal 325
[32m[2022-06-16 11:48:18] __main__ INFO: [0mEpoch 325 loss 2.0246 acc@1 0.6561 acc@5 0.9621
[32m[2022-06-16 11:48:18] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:48:18] __main__ INFO: [0mTrain 326 12675
[32m[2022-06-16 11:48:19] __main__ INFO: [0mEpoch 326 Step 39/39 lr 0.001000 loss 0.0349 (0.0422) acc@1 0.9922 (0.9880) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:20] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:48:20] __main__ INFO: [0mVal 326
[32m[2022-06-16 11:48:20] __main__ INFO: [0mEpoch 326 loss 2.0139 acc@1 0.6549 acc@5 0.9629
[32m[2022-06-16 11:48:20] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:20] __main__ INFO: [0mTrain 327 12714
[32m[2022-06-16 11:48:22] __main__ INFO: [0mEpoch 327 Step 39/39 lr 0.001000 loss 0.0349 (0.0450) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:22] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:48:22] __main__ INFO: [0mVal 327
[32m[2022-06-16 11:48:23] __main__ INFO: [0mEpoch 327 loss 2.0246 acc@1 0.6535 acc@5 0.9623
[32m[2022-06-16 11:48:23] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:23] __main__ INFO: [0mTrain 328 12753
[32m[2022-06-16 11:48:24] __main__ INFO: [0mEpoch 328 Step 39/39 lr 0.001000 loss 0.0458 (0.0419) acc@1 0.9922 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:24] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:48:24] __main__ INFO: [0mVal 328
[32m[2022-06-16 11:48:25] __main__ INFO: [0mEpoch 328 loss 2.0156 acc@1 0.6538 acc@5 0.9627
[32m[2022-06-16 11:48:25] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:48:25] __main__ INFO: [0mTrain 329 12792
[32m[2022-06-16 11:48:27] __main__ INFO: [0mEpoch 329 Step 39/39 lr 0.001000 loss 0.0271 (0.0344) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:27] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:48:27] __main__ INFO: [0mVal 329
[32m[2022-06-16 11:48:28] __main__ INFO: [0mEpoch 329 loss 2.0231 acc@1 0.6524 acc@5 0.9625
[32m[2022-06-16 11:48:28] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-16 11:48:28] __main__ INFO: [0mTrain 330 12831
[32m[2022-06-16 11:48:29] __main__ INFO: [0mEpoch 330 Step 39/39 lr 0.001000 loss 0.0475 (0.0414) acc@1 0.9922 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:29] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:48:29] __main__ INFO: [0mVal 330
[32m[2022-06-16 11:48:30] __main__ INFO: [0mEpoch 330 loss 2.0226 acc@1 0.6520 acc@5 0.9624
[32m[2022-06-16 11:48:30] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:48:30] __main__ INFO: [0mTrain 331 12870
[32m[2022-06-16 11:48:32] __main__ INFO: [0mEpoch 331 Step 39/39 lr 0.001000 loss 0.0523 (0.0392) acc@1 0.9844 (0.9890) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:32] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:48:32] __main__ INFO: [0mVal 331
[32m[2022-06-16 11:48:32] __main__ INFO: [0mEpoch 331 loss 2.0126 acc@1 0.6536 acc@5 0.9640
[32m[2022-06-16 11:48:32] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:48:32] __main__ INFO: [0mTrain 332 12909
[32m[2022-06-16 11:48:34] __main__ INFO: [0mEpoch 332 Step 39/39 lr 0.001000 loss 0.0346 (0.0413) acc@1 1.0000 (0.9890) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:34] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:48:34] __main__ INFO: [0mVal 332
[32m[2022-06-16 11:48:35] __main__ INFO: [0mEpoch 332 loss 2.0267 acc@1 0.6536 acc@5 0.9626
[32m[2022-06-16 11:48:35] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:35] __main__ INFO: [0mTrain 333 12948
[32m[2022-06-16 11:48:37] __main__ INFO: [0mEpoch 333 Step 39/39 lr 0.001000 loss 0.0509 (0.0450) acc@1 0.9844 (0.9872) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:37] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:48:37] __main__ INFO: [0mVal 333
[32m[2022-06-16 11:48:37] __main__ INFO: [0mEpoch 333 loss 2.0399 acc@1 0.6513 acc@5 0.9626
[32m[2022-06-16 11:48:37] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:48:37] __main__ INFO: [0mTrain 334 12987
[32m[2022-06-16 11:48:39] __main__ INFO: [0mEpoch 334 Step 39/39 lr 0.001000 loss 0.0420 (0.0373) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:39] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:48:39] __main__ INFO: [0mVal 334
[32m[2022-06-16 11:48:40] __main__ INFO: [0mEpoch 334 loss 2.0280 acc@1 0.6516 acc@5 0.9634
[32m[2022-06-16 11:48:40] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:48:40] __main__ INFO: [0mTrain 335 13026
[32m[2022-06-16 11:48:41] __main__ INFO: [0mEpoch 335 Step 39/39 lr 0.001000 loss 0.0202 (0.0391) acc@1 1.0000 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:41] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:48:41] __main__ INFO: [0mVal 335
[32m[2022-06-16 11:48:42] __main__ INFO: [0mEpoch 335 loss 2.0225 acc@1 0.6553 acc@5 0.9625
[32m[2022-06-16 11:48:42] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:48:42] __main__ INFO: [0mTrain 336 13065
[32m[2022-06-16 11:48:44] __main__ INFO: [0mEpoch 336 Step 39/39 lr 0.001000 loss 0.0441 (0.0396) acc@1 0.9844 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:44] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:48:44] __main__ INFO: [0mVal 336
[32m[2022-06-16 11:48:45] __main__ INFO: [0mEpoch 336 loss 2.0222 acc@1 0.6572 acc@5 0.9626
[32m[2022-06-16 11:48:45] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:48:45] __main__ INFO: [0mTrain 337 13104
[32m[2022-06-16 11:48:46] __main__ INFO: [0mEpoch 337 Step 39/39 lr 0.001000 loss 0.0480 (0.0358) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:46] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:48:46] __main__ INFO: [0mVal 337
[32m[2022-06-16 11:48:47] __main__ INFO: [0mEpoch 337 loss 2.0257 acc@1 0.6542 acc@5 0.9623
[32m[2022-06-16 11:48:47] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:47] __main__ INFO: [0mTrain 338 13143
[32m[2022-06-16 11:48:49] __main__ INFO: [0mEpoch 338 Step 39/39 lr 0.001000 loss 0.0306 (0.0422) acc@1 0.9922 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:49] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:48:49] __main__ INFO: [0mVal 338
[32m[2022-06-16 11:48:49] __main__ INFO: [0mEpoch 338 loss 2.0178 acc@1 0.6555 acc@5 0.9632
[32m[2022-06-16 11:48:49] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:49] __main__ INFO: [0mTrain 339 13182
[32m[2022-06-16 11:48:51] __main__ INFO: [0mEpoch 339 Step 39/39 lr 0.001000 loss 0.0426 (0.0425) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:51] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:48:51] __main__ INFO: [0mVal 339
[32m[2022-06-16 11:48:52] __main__ INFO: [0mEpoch 339 loss 2.0229 acc@1 0.6548 acc@5 0.9636
[32m[2022-06-16 11:48:52] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:48:52] __main__ INFO: [0mTrain 340 13221
[32m[2022-06-16 11:48:54] __main__ INFO: [0mEpoch 340 Step 39/39 lr 0.001000 loss 0.0181 (0.0408) acc@1 0.9922 (0.9892) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:54] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:48:54] __main__ INFO: [0mVal 340
[32m[2022-06-16 11:48:54] __main__ INFO: [0mEpoch 340 loss 2.0230 acc@1 0.6533 acc@5 0.9621
[32m[2022-06-16 11:48:54] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:48:54] __main__ INFO: [0mTrain 341 13260
[32m[2022-06-16 11:48:56] __main__ INFO: [0mEpoch 341 Step 39/39 lr 0.001000 loss 0.0381 (0.0350) acc@1 0.9844 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:56] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:48:56] __main__ INFO: [0mVal 341
[32m[2022-06-16 11:48:57] __main__ INFO: [0mEpoch 341 loss 2.0307 acc@1 0.6551 acc@5 0.9623
[32m[2022-06-16 11:48:57] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:48:57] __main__ INFO: [0mTrain 342 13299
[32m[2022-06-16 11:48:58] __main__ INFO: [0mEpoch 342 Step 39/39 lr 0.001000 loss 0.0910 (0.0382) acc@1 0.9688 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:48:58] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:48:58] __main__ INFO: [0mVal 342
[32m[2022-06-16 11:48:59] __main__ INFO: [0mEpoch 342 loss 2.0558 acc@1 0.6531 acc@5 0.9623
[32m[2022-06-16 11:48:59] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:48:59] __main__ INFO: [0mTrain 343 13338
[32m[2022-06-16 11:49:01] __main__ INFO: [0mEpoch 343 Step 39/39 lr 0.001000 loss 0.0399 (0.0393) acc@1 0.9844 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:01] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:01] __main__ INFO: [0mVal 343
[32m[2022-06-16 11:49:02] __main__ INFO: [0mEpoch 343 loss 2.0326 acc@1 0.6535 acc@5 0.9631
[32m[2022-06-16 11:49:02] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:02] __main__ INFO: [0mTrain 344 13377
[32m[2022-06-16 11:49:03] __main__ INFO: [0mEpoch 344 Step 39/39 lr 0.001000 loss 0.0368 (0.0366) acc@1 0.9922 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:03] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:03] __main__ INFO: [0mVal 344
[32m[2022-06-16 11:49:04] __main__ INFO: [0mEpoch 344 loss 2.0387 acc@1 0.6528 acc@5 0.9629
[32m[2022-06-16 11:49:04] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:04] __main__ INFO: [0mTrain 345 13416
[32m[2022-06-16 11:49:05] __main__ INFO: [0mEpoch 345 Step 39/39 lr 0.001000 loss 0.0379 (0.0367) acc@1 0.9922 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:06] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:49:06] __main__ INFO: [0mVal 345
[32m[2022-06-16 11:49:06] __main__ INFO: [0mEpoch 345 loss 2.0405 acc@1 0.6525 acc@5 0.9629
[32m[2022-06-16 11:49:06] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:49:06] __main__ INFO: [0mTrain 346 13455
[32m[2022-06-16 11:49:08] __main__ INFO: [0mEpoch 346 Step 39/39 lr 0.001000 loss 0.0327 (0.0391) acc@1 0.9922 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:08] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:49:08] __main__ INFO: [0mVal 346
[32m[2022-06-16 11:49:09] __main__ INFO: [0mEpoch 346 loss 2.0410 acc@1 0.6532 acc@5 0.9625
[32m[2022-06-16 11:49:09] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:09] __main__ INFO: [0mTrain 347 13494
[32m[2022-06-16 11:49:10] __main__ INFO: [0mEpoch 347 Step 39/39 lr 0.001000 loss 0.0294 (0.0339) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:10] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:49:10] __main__ INFO: [0mVal 347
[32m[2022-06-16 11:49:11] __main__ INFO: [0mEpoch 347 loss 2.0448 acc@1 0.6541 acc@5 0.9625
[32m[2022-06-16 11:49:11] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:49:11] __main__ INFO: [0mTrain 348 13533
[32m[2022-06-16 11:49:13] __main__ INFO: [0mEpoch 348 Step 39/39 lr 0.001000 loss 0.0211 (0.0418) acc@1 1.0000 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:13] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:49:13] __main__ INFO: [0mVal 348
[32m[2022-06-16 11:49:13] __main__ INFO: [0mEpoch 348 loss 2.0365 acc@1 0.6548 acc@5 0.9622
[32m[2022-06-16 11:49:13] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:49:13] __main__ INFO: [0mTrain 349 13572
[32m[2022-06-16 11:49:15] __main__ INFO: [0mEpoch 349 Step 39/39 lr 0.001000 loss 0.0493 (0.0361) acc@1 0.9844 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:15] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:49:15] __main__ INFO: [0mVal 349
[32m[2022-06-16 11:49:16] __main__ INFO: [0mEpoch 349 loss 2.0367 acc@1 0.6538 acc@5 0.9623
[32m[2022-06-16 11:49:16] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:49:16] __main__ INFO: [0mTrain 350 13611
[32m[2022-06-16 11:49:17] __main__ INFO: [0mEpoch 350 Step 39/39 lr 0.001000 loss 0.0388 (0.0350) acc@1 0.9844 (0.9904) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:18] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:49:18] __main__ INFO: [0mVal 350
[32m[2022-06-16 11:49:18] __main__ INFO: [0mEpoch 350 loss 2.0317 acc@1 0.6563 acc@5 0.9628
[32m[2022-06-16 11:49:18] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:49:18] __main__ INFO: [0mTrain 351 13650
[32m[2022-06-16 11:49:20] __main__ INFO: [0mEpoch 351 Step 39/39 lr 0.001000 loss 0.0210 (0.0338) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:20] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:20] __main__ INFO: [0mVal 351
[32m[2022-06-16 11:49:21] __main__ INFO: [0mEpoch 351 loss 2.0312 acc@1 0.6555 acc@5 0.9618
[32m[2022-06-16 11:49:21] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:21] __main__ INFO: [0mTrain 352 13689
[32m[2022-06-16 11:49:22] __main__ INFO: [0mEpoch 352 Step 39/39 lr 0.001000 loss 0.0224 (0.0384) acc@1 0.9922 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:22] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:49:22] __main__ INFO: [0mVal 352
[32m[2022-06-16 11:49:23] __main__ INFO: [0mEpoch 352 loss 2.0408 acc@1 0.6563 acc@5 0.9619
[32m[2022-06-16 11:49:23] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:23] __main__ INFO: [0mTrain 353 13728
[32m[2022-06-16 11:49:25] __main__ INFO: [0mEpoch 353 Step 39/39 lr 0.001000 loss 0.0447 (0.0392) acc@1 0.9844 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:25] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:49:25] __main__ INFO: [0mVal 353
[32m[2022-06-16 11:49:25] __main__ INFO: [0mEpoch 353 loss 2.0423 acc@1 0.6566 acc@5 0.9624
[32m[2022-06-16 11:49:25] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:49:25] __main__ INFO: [0mTrain 354 13767
[32m[2022-06-16 11:49:27] __main__ INFO: [0mEpoch 354 Step 39/39 lr 0.001000 loss 0.0343 (0.0332) acc@1 0.9922 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:27] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:49:27] __main__ INFO: [0mVal 354
[32m[2022-06-16 11:49:28] __main__ INFO: [0mEpoch 354 loss 2.0450 acc@1 0.6553 acc@5 0.9629
[32m[2022-06-16 11:49:28] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:49:28] __main__ INFO: [0mTrain 355 13806
[32m[2022-06-16 11:49:30] __main__ INFO: [0mEpoch 355 Step 39/39 lr 0.001000 loss 0.0484 (0.0373) acc@1 0.9766 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:30] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:49:30] __main__ INFO: [0mVal 355
[32m[2022-06-16 11:49:30] __main__ INFO: [0mEpoch 355 loss 2.0523 acc@1 0.6566 acc@5 0.9636
[32m[2022-06-16 11:49:30] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:30] __main__ INFO: [0mTrain 356 13845
[32m[2022-06-16 11:49:32] __main__ INFO: [0mEpoch 356 Step 39/39 lr 0.001000 loss 0.0330 (0.0375) acc@1 0.9922 (0.9900) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:32] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:49:32] __main__ INFO: [0mVal 356
[32m[2022-06-16 11:49:33] __main__ INFO: [0mEpoch 356 loss 2.0505 acc@1 0.6543 acc@5 0.9630
[32m[2022-06-16 11:49:33] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:49:33] __main__ INFO: [0mTrain 357 13884
[32m[2022-06-16 11:49:34] __main__ INFO: [0mEpoch 357 Step 39/39 lr 0.001000 loss 0.0251 (0.0336) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:34] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:49:34] __main__ INFO: [0mVal 357
[32m[2022-06-16 11:49:35] __main__ INFO: [0mEpoch 357 loss 2.0406 acc@1 0.6584 acc@5 0.9630
[32m[2022-06-16 11:49:35] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:35] __main__ INFO: [0mTrain 358 13923
[32m[2022-06-16 11:49:37] __main__ INFO: [0mEpoch 358 Step 39/39 lr 0.001000 loss 0.0174 (0.0354) acc@1 0.9922 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:37] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:37] __main__ INFO: [0mVal 358
[32m[2022-06-16 11:49:38] __main__ INFO: [0mEpoch 358 loss 2.0584 acc@1 0.6554 acc@5 0.9620
[32m[2022-06-16 11:49:38] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:38] __main__ INFO: [0mTrain 359 13962
[32m[2022-06-16 11:49:39] __main__ INFO: [0mEpoch 359 Step 39/39 lr 0.001000 loss 0.0443 (0.0341) acc@1 0.9844 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:39] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:39] __main__ INFO: [0mVal 359
[32m[2022-06-16 11:49:40] __main__ INFO: [0mEpoch 359 loss 2.0475 acc@1 0.6567 acc@5 0.9626
[32m[2022-06-16 11:49:40] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:49:40] __main__ INFO: [0mTrain 360 14001
[32m[2022-06-16 11:49:42] __main__ INFO: [0mEpoch 360 Step 39/39 lr 0.001000 loss 0.0327 (0.0362) acc@1 0.9922 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:42] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:49:42] __main__ INFO: [0mVal 360
[32m[2022-06-16 11:49:43] __main__ INFO: [0mEpoch 360 loss 2.0623 acc@1 0.6561 acc@5 0.9636
[32m[2022-06-16 11:49:43] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:49:43] __main__ INFO: [0mTrain 361 14040
[32m[2022-06-16 11:49:44] __main__ INFO: [0mEpoch 361 Step 39/39 lr 0.001000 loss 0.0367 (0.0307) acc@1 0.9922 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:44] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:49:44] __main__ INFO: [0mVal 361
[32m[2022-06-16 11:49:45] __main__ INFO: [0mEpoch 361 loss 2.0611 acc@1 0.6566 acc@5 0.9627
[32m[2022-06-16 11:49:45] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:49:45] __main__ INFO: [0mTrain 362 14079
[32m[2022-06-16 11:49:46] __main__ INFO: [0mEpoch 362 Step 39/39 lr 0.001000 loss 0.0550 (0.0353) acc@1 0.9844 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:46] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:49:46] __main__ INFO: [0mVal 362
[32m[2022-06-16 11:49:47] __main__ INFO: [0mEpoch 362 loss 2.0680 acc@1 0.6555 acc@5 0.9627
[32m[2022-06-16 11:49:47] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:47] __main__ INFO: [0mTrain 363 14118
[32m[2022-06-16 11:49:49] __main__ INFO: [0mEpoch 363 Step 39/39 lr 0.001000 loss 0.0246 (0.0348) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:49] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:49:49] __main__ INFO: [0mVal 363
[32m[2022-06-16 11:49:50] __main__ INFO: [0mEpoch 363 loss 2.0578 acc@1 0.6573 acc@5 0.9623
[32m[2022-06-16 11:49:50] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:50] __main__ INFO: [0mTrain 364 14157
[32m[2022-06-16 11:49:51] __main__ INFO: [0mEpoch 364 Step 39/39 lr 0.001000 loss 0.0234 (0.0373) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:51] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:49:51] __main__ INFO: [0mVal 364
[32m[2022-06-16 11:49:52] __main__ INFO: [0mEpoch 364 loss 2.0692 acc@1 0.6573 acc@5 0.9629
[32m[2022-06-16 11:49:52] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:49:52] __main__ INFO: [0mTrain 365 14196
[32m[2022-06-16 11:49:54] __main__ INFO: [0mEpoch 365 Step 39/39 lr 0.001000 loss 0.0408 (0.0399) acc@1 0.9922 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:54] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:54] __main__ INFO: [0mVal 365
[32m[2022-06-16 11:49:55] __main__ INFO: [0mEpoch 365 loss 2.0702 acc@1 0.6549 acc@5 0.9631
[32m[2022-06-16 11:49:55] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:49:55] __main__ INFO: [0mTrain 366 14235
[32m[2022-06-16 11:49:56] __main__ INFO: [0mEpoch 366 Step 39/39 lr 0.001000 loss 0.0232 (0.0327) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:56] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:49:56] __main__ INFO: [0mVal 366
[32m[2022-06-16 11:49:57] __main__ INFO: [0mEpoch 366 loss 2.0606 acc@1 0.6551 acc@5 0.9637
[32m[2022-06-16 11:49:57] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:49:57] __main__ INFO: [0mTrain 367 14274
[32m[2022-06-16 11:49:59] __main__ INFO: [0mEpoch 367 Step 39/39 lr 0.001000 loss 0.0250 (0.0317) acc@1 0.9922 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:49:59] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:49:59] __main__ INFO: [0mVal 367
[32m[2022-06-16 11:49:59] __main__ INFO: [0mEpoch 367 loss 2.0686 acc@1 0.6544 acc@5 0.9629
[32m[2022-06-16 11:49:59] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:49:59] __main__ INFO: [0mTrain 368 14313
[32m[2022-06-16 11:50:01] __main__ INFO: [0mEpoch 368 Step 39/39 lr 0.001000 loss 0.0270 (0.0362) acc@1 0.9922 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:01] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:50:01] __main__ INFO: [0mVal 368
[32m[2022-06-16 11:50:02] __main__ INFO: [0mEpoch 368 loss 2.0623 acc@1 0.6569 acc@5 0.9630
[32m[2022-06-16 11:50:02] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:50:02] __main__ INFO: [0mTrain 369 14352
[32m[2022-06-16 11:50:03] __main__ INFO: [0mEpoch 369 Step 39/39 lr 0.001000 loss 0.0284 (0.0396) acc@1 0.9844 (0.9882) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:03] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:50:03] __main__ INFO: [0mVal 369
[32m[2022-06-16 11:50:04] __main__ INFO: [0mEpoch 369 loss 2.0590 acc@1 0.6544 acc@5 0.9628
[32m[2022-06-16 11:50:04] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:50:04] __main__ INFO: [0mTrain 370 14391
[32m[2022-06-16 11:50:06] __main__ INFO: [0mEpoch 370 Step 39/39 lr 0.001000 loss 0.0685 (0.0395) acc@1 0.9609 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:06] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:50:06] __main__ INFO: [0mVal 370
[32m[2022-06-16 11:50:07] __main__ INFO: [0mEpoch 370 loss 2.0776 acc@1 0.6544 acc@5 0.9631
[32m[2022-06-16 11:50:07] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:50:07] __main__ INFO: [0mTrain 371 14430
[32m[2022-06-16 11:50:08] __main__ INFO: [0mEpoch 371 Step 39/39 lr 0.001000 loss 0.0275 (0.0366) acc@1 0.9922 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:08] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:50:08] __main__ INFO: [0mVal 371
[32m[2022-06-16 11:50:09] __main__ INFO: [0mEpoch 371 loss 2.0751 acc@1 0.6542 acc@5 0.9625
[32m[2022-06-16 11:50:09] __main__ INFO: [0mElapsed 0.65
[32m[2022-06-16 11:50:09] __main__ INFO: [0mTrain 372 14469
[32m[2022-06-16 11:50:10] __main__ INFO: [0mEpoch 372 Step 39/39 lr 0.001000 loss 0.0247 (0.0344) acc@1 0.9922 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:10] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:50:10] __main__ INFO: [0mVal 372
[32m[2022-06-16 11:50:11] __main__ INFO: [0mEpoch 372 loss 2.0597 acc@1 0.6543 acc@5 0.9630
[32m[2022-06-16 11:50:11] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:50:11] __main__ INFO: [0mTrain 373 14508
[32m[2022-06-16 11:50:13] __main__ INFO: [0mEpoch 373 Step 39/39 lr 0.001000 loss 0.0261 (0.0359) acc@1 0.9922 (0.9884) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:13] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:50:13] __main__ INFO: [0mVal 373
[32m[2022-06-16 11:50:14] __main__ INFO: [0mEpoch 373 loss 2.0573 acc@1 0.6556 acc@5 0.9630
[32m[2022-06-16 11:50:14] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:50:14] __main__ INFO: [0mTrain 374 14547
[32m[2022-06-16 11:50:15] __main__ INFO: [0mEpoch 374 Step 39/39 lr 0.001000 loss 0.0101 (0.0356) acc@1 1.0000 (0.9898) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:15] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:50:15] __main__ INFO: [0mVal 374
[32m[2022-06-16 11:50:16] __main__ INFO: [0mEpoch 374 loss 2.0722 acc@1 0.6534 acc@5 0.9625
[32m[2022-06-16 11:50:16] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:50:16] __main__ INFO: [0mTrain 375 14586
[32m[2022-06-16 11:50:18] __main__ INFO: [0mEpoch 375 Step 39/39 lr 0.001000 loss 0.0624 (0.0394) acc@1 0.9844 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:18] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:50:18] __main__ INFO: [0mVal 375
[32m[2022-06-16 11:50:18] __main__ INFO: [0mEpoch 375 loss 2.0722 acc@1 0.6550 acc@5 0.9621
[32m[2022-06-16 11:50:18] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:50:18] __main__ INFO: [0mTrain 376 14625
[32m[2022-06-16 11:50:20] __main__ INFO: [0mEpoch 376 Step 39/39 lr 0.001000 loss 0.0437 (0.0342) acc@1 0.9844 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:20] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:50:20] __main__ INFO: [0mVal 376
[32m[2022-06-16 11:50:21] __main__ INFO: [0mEpoch 376 loss 2.0673 acc@1 0.6559 acc@5 0.9626
[32m[2022-06-16 11:50:21] __main__ INFO: [0mElapsed 0.82
[32m[2022-06-16 11:50:21] __main__ INFO: [0mTrain 377 14664
[32m[2022-06-16 11:50:22] __main__ INFO: [0mEpoch 377 Step 39/39 lr 0.001000 loss 0.0118 (0.0277) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:23] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:50:23] __main__ INFO: [0mVal 377
[32m[2022-06-16 11:50:23] __main__ INFO: [0mEpoch 377 loss 2.0684 acc@1 0.6546 acc@5 0.9637
[32m[2022-06-16 11:50:23] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:50:23] __main__ INFO: [0mTrain 378 14703
[32m[2022-06-16 11:50:25] __main__ INFO: [0mEpoch 378 Step 39/39 lr 0.001000 loss 0.0146 (0.0372) acc@1 1.0000 (0.9886) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:25] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:50:25] __main__ INFO: [0mVal 378
[32m[2022-06-16 11:50:26] __main__ INFO: [0mEpoch 378 loss 2.0684 acc@1 0.6557 acc@5 0.9635
[32m[2022-06-16 11:50:26] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:50:26] __main__ INFO: [0mTrain 379 14742
[32m[2022-06-16 11:50:27] __main__ INFO: [0mEpoch 379 Step 39/39 lr 0.001000 loss 0.0393 (0.0342) acc@1 0.9922 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:27] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:50:27] __main__ INFO: [0mVal 379
[32m[2022-06-16 11:50:28] __main__ INFO: [0mEpoch 379 loss 2.0620 acc@1 0.6566 acc@5 0.9630
[32m[2022-06-16 11:50:28] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:50:28] __main__ INFO: [0mTrain 380 14781
[32m[2022-06-16 11:50:30] __main__ INFO: [0mEpoch 380 Step 39/39 lr 0.001000 loss 0.0346 (0.0341) acc@1 0.9922 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:30] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:50:30] __main__ INFO: [0mVal 380
[32m[2022-06-16 11:50:30] __main__ INFO: [0mEpoch 380 loss 2.0699 acc@1 0.6557 acc@5 0.9626
[32m[2022-06-16 11:50:30] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:50:30] __main__ INFO: [0mTrain 381 14820
[32m[2022-06-16 11:50:32] __main__ INFO: [0mEpoch 381 Step 39/39 lr 0.001000 loss 0.0571 (0.0360) acc@1 0.9922 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:32] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:50:32] __main__ INFO: [0mVal 381
[32m[2022-06-16 11:50:33] __main__ INFO: [0mEpoch 381 loss 2.0779 acc@1 0.6548 acc@5 0.9617
[32m[2022-06-16 11:50:33] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:50:33] __main__ INFO: [0mTrain 382 14859
[32m[2022-06-16 11:50:35] __main__ INFO: [0mEpoch 382 Step 39/39 lr 0.001000 loss 0.0488 (0.0356) acc@1 0.9922 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:35] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:50:35] __main__ INFO: [0mVal 382
[32m[2022-06-16 11:50:35] __main__ INFO: [0mEpoch 382 loss 2.0779 acc@1 0.6557 acc@5 0.9632
[32m[2022-06-16 11:50:35] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:50:35] __main__ INFO: [0mTrain 383 14898
[32m[2022-06-16 11:50:37] __main__ INFO: [0mEpoch 383 Step 39/39 lr 0.001000 loss 0.0113 (0.0349) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:37] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:50:37] __main__ INFO: [0mVal 383
[32m[2022-06-16 11:50:38] __main__ INFO: [0mEpoch 383 loss 2.0755 acc@1 0.6566 acc@5 0.9629
[32m[2022-06-16 11:50:38] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:50:38] __main__ INFO: [0mTrain 384 14937
[32m[2022-06-16 11:50:39] __main__ INFO: [0mEpoch 384 Step 39/39 lr 0.001000 loss 0.0167 (0.0401) acc@1 1.0000 (0.9902) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:39] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:50:39] __main__ INFO: [0mVal 384
[32m[2022-06-16 11:50:40] __main__ INFO: [0mEpoch 384 loss 2.0674 acc@1 0.6556 acc@5 0.9624
[32m[2022-06-16 11:50:40] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:50:40] __main__ INFO: [0mTrain 385 14976
[32m[2022-06-16 11:50:42] __main__ INFO: [0mEpoch 385 Step 39/39 lr 0.001000 loss 0.0288 (0.0297) acc@1 0.9922 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:42] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:50:42] __main__ INFO: [0mVal 385
[32m[2022-06-16 11:50:43] __main__ INFO: [0mEpoch 385 loss 2.0871 acc@1 0.6544 acc@5 0.9621
[32m[2022-06-16 11:50:43] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:50:43] __main__ INFO: [0mTrain 386 15015
[32m[2022-06-16 11:50:44] __main__ INFO: [0mEpoch 386 Step 39/39 lr 0.001000 loss 0.0279 (0.0322) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:44] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:50:44] __main__ INFO: [0mVal 386
[32m[2022-06-16 11:50:45] __main__ INFO: [0mEpoch 386 loss 2.0834 acc@1 0.6543 acc@5 0.9630
[32m[2022-06-16 11:50:45] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:50:45] __main__ INFO: [0mTrain 387 15054
[32m[2022-06-16 11:50:47] __main__ INFO: [0mEpoch 387 Step 39/39 lr 0.001000 loss 0.0217 (0.0297) acc@1 1.0000 (0.9944) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:47] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:50:47] __main__ INFO: [0mVal 387
[32m[2022-06-16 11:50:47] __main__ INFO: [0mEpoch 387 loss 2.0841 acc@1 0.6546 acc@5 0.9622
[32m[2022-06-16 11:50:47] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:50:47] __main__ INFO: [0mTrain 388 15093
[32m[2022-06-16 11:50:49] __main__ INFO: [0mEpoch 388 Step 39/39 lr 0.001000 loss 0.0343 (0.0352) acc@1 0.9844 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:49] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:50:49] __main__ INFO: [0mVal 388
[32m[2022-06-16 11:50:50] __main__ INFO: [0mEpoch 388 loss 2.0829 acc@1 0.6547 acc@5 0.9623
[32m[2022-06-16 11:50:50] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:50:50] __main__ INFO: [0mTrain 389 15132
[32m[2022-06-16 11:50:52] __main__ INFO: [0mEpoch 389 Step 39/39 lr 0.001000 loss 0.0268 (0.0337) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:52] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:50:52] __main__ INFO: [0mVal 389
[32m[2022-06-16 11:50:52] __main__ INFO: [0mEpoch 389 loss 2.0849 acc@1 0.6546 acc@5 0.9616
[32m[2022-06-16 11:50:52] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:50:52] __main__ INFO: [0mTrain 390 15171
[32m[2022-06-16 11:50:54] __main__ INFO: [0mEpoch 390 Step 39/39 lr 0.001000 loss 0.0308 (0.0395) acc@1 0.9922 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:54] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:50:54] __main__ INFO: [0mVal 390
[32m[2022-06-16 11:50:55] __main__ INFO: [0mEpoch 390 loss 2.0824 acc@1 0.6538 acc@5 0.9619
[32m[2022-06-16 11:50:55] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:50:55] __main__ INFO: [0mTrain 391 15210
[32m[2022-06-16 11:50:56] __main__ INFO: [0mEpoch 391 Step 39/39 lr 0.001000 loss 0.0314 (0.0336) acc@1 0.9922 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:56] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:50:56] __main__ INFO: [0mVal 391
[32m[2022-06-16 11:50:57] __main__ INFO: [0mEpoch 391 loss 2.0927 acc@1 0.6543 acc@5 0.9626
[32m[2022-06-16 11:50:57] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:50:57] __main__ INFO: [0mTrain 392 15249
[32m[2022-06-16 11:50:59] __main__ INFO: [0mEpoch 392 Step 39/39 lr 0.001000 loss 0.0408 (0.0357) acc@1 0.9844 (0.9888) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:50:59] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:50:59] __main__ INFO: [0mVal 392
[32m[2022-06-16 11:51:00] __main__ INFO: [0mEpoch 392 loss 2.0918 acc@1 0.6547 acc@5 0.9616
[32m[2022-06-16 11:51:00] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:51:00] __main__ INFO: [0mTrain 393 15288
[32m[2022-06-16 11:51:01] __main__ INFO: [0mEpoch 393 Step 39/39 lr 0.001000 loss 0.0219 (0.0320) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:01] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:51:01] __main__ INFO: [0mVal 393
[32m[2022-06-16 11:51:02] __main__ INFO: [0mEpoch 393 loss 2.0807 acc@1 0.6549 acc@5 0.9615
[32m[2022-06-16 11:51:02] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:51:02] __main__ INFO: [0mTrain 394 15327
[32m[2022-06-16 11:51:04] __main__ INFO: [0mEpoch 394 Step 39/39 lr 0.001000 loss 0.0371 (0.0312) acc@1 1.0000 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:04] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:51:04] __main__ INFO: [0mVal 394
[32m[2022-06-16 11:51:05] __main__ INFO: [0mEpoch 394 loss 2.0882 acc@1 0.6551 acc@5 0.9614
[32m[2022-06-16 11:51:05] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:51:05] __main__ INFO: [0mTrain 395 15366
[32m[2022-06-16 11:51:06] __main__ INFO: [0mEpoch 395 Step 39/39 lr 0.001000 loss 0.0426 (0.0353) acc@1 0.9922 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:06] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:51:06] __main__ INFO: [0mVal 395
[32m[2022-06-16 11:51:07] __main__ INFO: [0mEpoch 395 loss 2.0761 acc@1 0.6553 acc@5 0.9622
[32m[2022-06-16 11:51:07] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:51:07] __main__ INFO: [0mTrain 396 15405
[32m[2022-06-16 11:51:09] __main__ INFO: [0mEpoch 396 Step 39/39 lr 0.001000 loss 0.0324 (0.0300) acc@1 0.9922 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:09] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:51:09] __main__ INFO: [0mVal 396
[32m[2022-06-16 11:51:09] __main__ INFO: [0mEpoch 396 loss 2.0783 acc@1 0.6552 acc@5 0.9619
[32m[2022-06-16 11:51:09] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:51:09] __main__ INFO: [0mTrain 397 15444
[32m[2022-06-16 11:51:11] __main__ INFO: [0mEpoch 397 Step 39/39 lr 0.001000 loss 0.0177 (0.0294) acc@1 0.9922 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:11] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:51:11] __main__ INFO: [0mVal 397
[32m[2022-06-16 11:51:12] __main__ INFO: [0mEpoch 397 loss 2.0853 acc@1 0.6560 acc@5 0.9624
[32m[2022-06-16 11:51:12] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:51:12] __main__ INFO: [0mTrain 398 15483
[32m[2022-06-16 11:51:14] __main__ INFO: [0mEpoch 398 Step 39/39 lr 0.001000 loss 0.0169 (0.0299) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:14] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:51:14] __main__ INFO: [0mVal 398
[32m[2022-06-16 11:51:14] __main__ INFO: [0mEpoch 398 loss 2.0814 acc@1 0.6556 acc@5 0.9629
[32m[2022-06-16 11:51:14] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:51:14] __main__ INFO: [0mTrain 399 15522
[32m[2022-06-16 11:51:16] __main__ INFO: [0mEpoch 399 Step 39/39 lr 0.001000 loss 0.0174 (0.0314) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:16] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:51:16] __main__ INFO: [0mVal 399
[32m[2022-06-16 11:51:17] __main__ INFO: [0mEpoch 399 loss 2.0801 acc@1 0.6561 acc@5 0.9627
[32m[2022-06-16 11:51:17] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:51:17] __main__ INFO: [0mTrain 400 15561
[32m[2022-06-16 11:51:19] __main__ INFO: [0mEpoch 400 Step 39/39 lr 0.001000 loss 0.0511 (0.0332) acc@1 0.9844 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:19] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:51:19] __main__ INFO: [0mVal 400
[32m[2022-06-16 11:51:19] __main__ INFO: [0mEpoch 400 loss 2.0809 acc@1 0.6559 acc@5 0.9625
[32m[2022-06-16 11:51:19] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:51:19] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00400.pth
[32m[2022-06-16 11:51:19] __main__ INFO: [0mTrain 401 15600
[32m[2022-06-16 11:51:21] __main__ INFO: [0mEpoch 401 Step 39/39 lr 0.001000 loss 0.0311 (0.0368) acc@1 0.9844 (0.9896) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:21] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:51:21] __main__ INFO: [0mVal 401
[32m[2022-06-16 11:51:22] __main__ INFO: [0mEpoch 401 loss 2.0854 acc@1 0.6568 acc@5 0.9627
[32m[2022-06-16 11:51:22] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:51:22] __main__ INFO: [0mTrain 402 15639
[32m[2022-06-16 11:51:23] __main__ INFO: [0mEpoch 402 Step 39/39 lr 0.001000 loss 0.0128 (0.0293) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:23] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:51:23] __main__ INFO: [0mVal 402
[32m[2022-06-16 11:51:24] __main__ INFO: [0mEpoch 402 loss 2.0952 acc@1 0.6553 acc@5 0.9628
[32m[2022-06-16 11:51:24] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:51:24] __main__ INFO: [0mTrain 403 15678
[32m[2022-06-16 11:51:26] __main__ INFO: [0mEpoch 403 Step 39/39 lr 0.001000 loss 0.0210 (0.0258) acc@1 0.9922 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:26] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:51:26] __main__ INFO: [0mVal 403
[32m[2022-06-16 11:51:27] __main__ INFO: [0mEpoch 403 loss 2.0942 acc@1 0.6558 acc@5 0.9628
[32m[2022-06-16 11:51:27] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:51:27] __main__ INFO: [0mTrain 404 15717
[32m[2022-06-16 11:51:28] __main__ INFO: [0mEpoch 404 Step 39/39 lr 0.001000 loss 0.0353 (0.0317) acc@1 0.9844 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:28] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:51:28] __main__ INFO: [0mVal 404
[32m[2022-06-16 11:51:29] __main__ INFO: [0mEpoch 404 loss 2.0791 acc@1 0.6563 acc@5 0.9636
[32m[2022-06-16 11:51:29] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:51:29] __main__ INFO: [0mTrain 405 15756
[32m[2022-06-16 11:51:31] __main__ INFO: [0mEpoch 405 Step 39/39 lr 0.001000 loss 0.0376 (0.0301) acc@1 0.9922 (0.9942) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:31] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:51:31] __main__ INFO: [0mVal 405
[32m[2022-06-16 11:51:32] __main__ INFO: [0mEpoch 405 loss 2.0901 acc@1 0.6566 acc@5 0.9623
[32m[2022-06-16 11:51:32] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:51:32] __main__ INFO: [0mTrain 406 15795
[32m[2022-06-16 11:51:33] __main__ INFO: [0mEpoch 406 Step 39/39 lr 0.001000 loss 0.0261 (0.0284) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:33] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:51:33] __main__ INFO: [0mVal 406
[32m[2022-06-16 11:51:34] __main__ INFO: [0mEpoch 406 loss 2.1046 acc@1 0.6549 acc@5 0.9619
[32m[2022-06-16 11:51:34] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:51:34] __main__ INFO: [0mTrain 407 15834
[32m[2022-06-16 11:51:36] __main__ INFO: [0mEpoch 407 Step 39/39 lr 0.001000 loss 0.0290 (0.0325) acc@1 1.0000 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:36] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:51:36] __main__ INFO: [0mVal 407
[32m[2022-06-16 11:51:36] __main__ INFO: [0mEpoch 407 loss 2.1009 acc@1 0.6565 acc@5 0.9615
[32m[2022-06-16 11:51:36] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:51:36] __main__ INFO: [0mTrain 408 15873
[32m[2022-06-16 11:51:38] __main__ INFO: [0mEpoch 408 Step 39/39 lr 0.001000 loss 0.0171 (0.0306) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:38] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:51:38] __main__ INFO: [0mVal 408
[32m[2022-06-16 11:51:39] __main__ INFO: [0mEpoch 408 loss 2.0966 acc@1 0.6587 acc@5 0.9628
[32m[2022-06-16 11:51:39] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:51:39] __main__ INFO: [0mTrain 409 15912
[32m[2022-06-16 11:51:41] __main__ INFO: [0mEpoch 409 Step 39/39 lr 0.001000 loss 0.0317 (0.0306) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:41] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:51:41] __main__ INFO: [0mVal 409
[32m[2022-06-16 11:51:41] __main__ INFO: [0mEpoch 409 loss 2.1102 acc@1 0.6573 acc@5 0.9620
[32m[2022-06-16 11:51:41] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:51:41] __main__ INFO: [0mTrain 410 15951
[32m[2022-06-16 11:51:43] __main__ INFO: [0mEpoch 410 Step 39/39 lr 0.001000 loss 0.0206 (0.0273) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:43] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:51:43] __main__ INFO: [0mVal 410
[32m[2022-06-16 11:51:44] __main__ INFO: [0mEpoch 410 loss 2.1066 acc@1 0.6558 acc@5 0.9624
[32m[2022-06-16 11:51:44] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:51:44] __main__ INFO: [0mTrain 411 15990
[32m[2022-06-16 11:51:46] __main__ INFO: [0mEpoch 411 Step 39/39 lr 0.001000 loss 0.0112 (0.0320) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:46] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-16 11:51:46] __main__ INFO: [0mVal 411
[32m[2022-06-16 11:51:46] __main__ INFO: [0mEpoch 411 loss 2.1095 acc@1 0.6559 acc@5 0.9625
[32m[2022-06-16 11:51:46] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:51:46] __main__ INFO: [0mTrain 412 16029
[32m[2022-06-16 11:51:48] __main__ INFO: [0mEpoch 412 Step 39/39 lr 0.001000 loss 0.0384 (0.0332) acc@1 0.9922 (0.9904) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:48] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:51:48] __main__ INFO: [0mVal 412
[32m[2022-06-16 11:51:49] __main__ INFO: [0mEpoch 412 loss 2.1028 acc@1 0.6557 acc@5 0.9623
[32m[2022-06-16 11:51:49] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:51:49] __main__ INFO: [0mTrain 413 16068
[32m[2022-06-16 11:51:50] __main__ INFO: [0mEpoch 413 Step 39/39 lr 0.001000 loss 0.0212 (0.0299) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:50] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:51:50] __main__ INFO: [0mVal 413
[32m[2022-06-16 11:51:51] __main__ INFO: [0mEpoch 413 loss 2.1218 acc@1 0.6553 acc@5 0.9616
[32m[2022-06-16 11:51:51] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:51:51] __main__ INFO: [0mTrain 414 16107
[32m[2022-06-16 11:51:53] __main__ INFO: [0mEpoch 414 Step 39/39 lr 0.001000 loss 0.0111 (0.0288) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:53] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:51:53] __main__ INFO: [0mVal 414
[32m[2022-06-16 11:51:54] __main__ INFO: [0mEpoch 414 loss 2.1140 acc@1 0.6560 acc@5 0.9628
[32m[2022-06-16 11:51:54] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:51:54] __main__ INFO: [0mTrain 415 16146
[32m[2022-06-16 11:51:55] __main__ INFO: [0mEpoch 415 Step 39/39 lr 0.001000 loss 0.0329 (0.0286) acc@1 0.9922 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:55] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:51:55] __main__ INFO: [0mVal 415
[32m[2022-06-16 11:51:56] __main__ INFO: [0mEpoch 415 loss 2.1378 acc@1 0.6540 acc@5 0.9621
[32m[2022-06-16 11:51:56] __main__ INFO: [0mElapsed 0.86
[32m[2022-06-16 11:51:56] __main__ INFO: [0mTrain 416 16185
[32m[2022-06-16 11:51:58] __main__ INFO: [0mEpoch 416 Step 39/39 lr 0.001000 loss 0.0363 (0.0306) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:51:58] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:51:58] __main__ INFO: [0mVal 416
[32m[2022-06-16 11:51:59] __main__ INFO: [0mEpoch 416 loss 2.1385 acc@1 0.6560 acc@5 0.9613
[32m[2022-06-16 11:51:59] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:51:59] __main__ INFO: [0mTrain 417 16224
[32m[2022-06-16 11:52:00] __main__ INFO: [0mEpoch 417 Step 39/39 lr 0.001000 loss 0.0395 (0.0280) acc@1 0.9922 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:00] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:52:00] __main__ INFO: [0mVal 417
[32m[2022-06-16 11:52:01] __main__ INFO: [0mEpoch 417 loss 2.1281 acc@1 0.6560 acc@5 0.9615
[32m[2022-06-16 11:52:01] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:52:01] __main__ INFO: [0mTrain 418 16263
[32m[2022-06-16 11:52:03] __main__ INFO: [0mEpoch 418 Step 39/39 lr 0.001000 loss 0.0168 (0.0300) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:03] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:52:03] __main__ INFO: [0mVal 418
[32m[2022-06-16 11:52:03] __main__ INFO: [0mEpoch 418 loss 2.1124 acc@1 0.6561 acc@5 0.9615
[32m[2022-06-16 11:52:03] __main__ INFO: [0mElapsed 0.67
[32m[2022-06-16 11:52:03] __main__ INFO: [0mTrain 419 16302
[32m[2022-06-16 11:52:05] __main__ INFO: [0mEpoch 419 Step 39/39 lr 0.001000 loss 0.0496 (0.0322) acc@1 0.9688 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:05] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:52:05] __main__ INFO: [0mVal 419
[32m[2022-06-16 11:52:06] __main__ INFO: [0mEpoch 419 loss 2.1177 acc@1 0.6566 acc@5 0.9628
[32m[2022-06-16 11:52:06] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:52:06] __main__ INFO: [0mTrain 420 16341
[32m[2022-06-16 11:52:07] __main__ INFO: [0mEpoch 420 Step 39/39 lr 0.001000 loss 0.0220 (0.0313) acc@1 1.0000 (0.9912) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:07] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:52:07] __main__ INFO: [0mVal 420
[32m[2022-06-16 11:52:08] __main__ INFO: [0mEpoch 420 loss 2.1217 acc@1 0.6537 acc@5 0.9629
[32m[2022-06-16 11:52:08] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:52:08] __main__ INFO: [0mTrain 421 16380
[32m[2022-06-16 11:52:10] __main__ INFO: [0mEpoch 421 Step 39/39 lr 0.001000 loss 0.0340 (0.0343) acc@1 0.9922 (0.9894) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:10] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:52:10] __main__ INFO: [0mVal 421
[32m[2022-06-16 11:52:11] __main__ INFO: [0mEpoch 421 loss 2.1159 acc@1 0.6519 acc@5 0.9627
[32m[2022-06-16 11:52:11] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:52:11] __main__ INFO: [0mTrain 422 16419
[32m[2022-06-16 11:52:12] __main__ INFO: [0mEpoch 422 Step 39/39 lr 0.001000 loss 0.0675 (0.0314) acc@1 0.9844 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:12] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:52:12] __main__ INFO: [0mVal 422
[32m[2022-06-16 11:52:13] __main__ INFO: [0mEpoch 422 loss 2.1152 acc@1 0.6543 acc@5 0.9621
[32m[2022-06-16 11:52:13] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:52:13] __main__ INFO: [0mTrain 423 16458
[32m[2022-06-16 11:52:15] __main__ INFO: [0mEpoch 423 Step 39/39 lr 0.001000 loss 0.0325 (0.0290) acc@1 0.9922 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:15] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:52:15] __main__ INFO: [0mVal 423
[32m[2022-06-16 11:52:15] __main__ INFO: [0mEpoch 423 loss 2.1149 acc@1 0.6544 acc@5 0.9632
[32m[2022-06-16 11:52:15] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:52:15] __main__ INFO: [0mTrain 424 16497
[32m[2022-06-16 11:52:17] __main__ INFO: [0mEpoch 424 Step 39/39 lr 0.001000 loss 0.0173 (0.0308) acc@1 1.0000 (0.9908) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:17] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:52:17] __main__ INFO: [0mVal 424
[32m[2022-06-16 11:52:18] __main__ INFO: [0mEpoch 424 loss 2.1071 acc@1 0.6573 acc@5 0.9626
[32m[2022-06-16 11:52:18] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:52:18] __main__ INFO: [0mTrain 425 16536
[32m[2022-06-16 11:52:19] __main__ INFO: [0mEpoch 425 Step 39/39 lr 0.001000 loss 0.0801 (0.0330) acc@1 0.9844 (0.9906) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:19] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:52:19] __main__ INFO: [0mVal 425
[32m[2022-06-16 11:52:20] __main__ INFO: [0mEpoch 425 loss 2.1149 acc@1 0.6571 acc@5 0.9632
[32m[2022-06-16 11:52:20] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:52:20] __main__ INFO: [0mTrain 426 16575
[32m[2022-06-16 11:52:22] __main__ INFO: [0mEpoch 426 Step 39/39 lr 0.001000 loss 0.0359 (0.0289) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:22] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:52:22] __main__ INFO: [0mVal 426
[32m[2022-06-16 11:52:23] __main__ INFO: [0mEpoch 426 loss 2.1154 acc@1 0.6550 acc@5 0.9624
[32m[2022-06-16 11:52:23] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:52:23] __main__ INFO: [0mTrain 427 16614
[32m[2022-06-16 11:52:24] __main__ INFO: [0mEpoch 427 Step 39/39 lr 0.001000 loss 0.0300 (0.0297) acc@1 0.9844 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:24] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:52:24] __main__ INFO: [0mVal 427
[32m[2022-06-16 11:52:25] __main__ INFO: [0mEpoch 427 loss 2.1168 acc@1 0.6553 acc@5 0.9628
[32m[2022-06-16 11:52:25] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:52:25] __main__ INFO: [0mTrain 428 16653
[32m[2022-06-16 11:52:27] __main__ INFO: [0mEpoch 428 Step 39/39 lr 0.001000 loss 0.0556 (0.0299) acc@1 0.9922 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:27] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:52:27] __main__ INFO: [0mVal 428
[32m[2022-06-16 11:52:28] __main__ INFO: [0mEpoch 428 loss 2.1288 acc@1 0.6558 acc@5 0.9613
[32m[2022-06-16 11:52:28] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:52:28] __main__ INFO: [0mTrain 429 16692
[32m[2022-06-16 11:52:29] __main__ INFO: [0mEpoch 429 Step 39/39 lr 0.001000 loss 0.0206 (0.0293) acc@1 0.9922 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:29] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:52:29] __main__ INFO: [0mVal 429
[32m[2022-06-16 11:52:30] __main__ INFO: [0mEpoch 429 loss 2.1206 acc@1 0.6569 acc@5 0.9619
[32m[2022-06-16 11:52:30] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:52:30] __main__ INFO: [0mTrain 430 16731
[32m[2022-06-16 11:52:32] __main__ INFO: [0mEpoch 430 Step 39/39 lr 0.001000 loss 0.0207 (0.0296) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:32] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:52:32] __main__ INFO: [0mVal 430
[32m[2022-06-16 11:52:32] __main__ INFO: [0mEpoch 430 loss 2.1175 acc@1 0.6540 acc@5 0.9623
[32m[2022-06-16 11:52:32] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:52:32] __main__ INFO: [0mTrain 431 16770
[32m[2022-06-16 11:52:34] __main__ INFO: [0mEpoch 431 Step 39/39 lr 0.001000 loss 0.0449 (0.0317) acc@1 0.9844 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:34] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:52:34] __main__ INFO: [0mVal 431
[32m[2022-06-16 11:52:35] __main__ INFO: [0mEpoch 431 loss 2.1189 acc@1 0.6556 acc@5 0.9629
[32m[2022-06-16 11:52:35] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:52:35] __main__ INFO: [0mTrain 432 16809
[32m[2022-06-16 11:52:36] __main__ INFO: [0mEpoch 432 Step 39/39 lr 0.001000 loss 0.0340 (0.0311) acc@1 0.9922 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:36] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:52:36] __main__ INFO: [0mVal 432
[32m[2022-06-16 11:52:37] __main__ INFO: [0mEpoch 432 loss 2.1147 acc@1 0.6559 acc@5 0.9629
[32m[2022-06-16 11:52:37] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:52:37] __main__ INFO: [0mTrain 433 16848
[32m[2022-06-16 11:52:39] __main__ INFO: [0mEpoch 433 Step 39/39 lr 0.001000 loss 0.0282 (0.0291) acc@1 0.9844 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:39] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:52:39] __main__ INFO: [0mVal 433
[32m[2022-06-16 11:52:40] __main__ INFO: [0mEpoch 433 loss 2.1260 acc@1 0.6542 acc@5 0.9630
[32m[2022-06-16 11:52:40] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:52:40] __main__ INFO: [0mTrain 434 16887
[32m[2022-06-16 11:52:41] __main__ INFO: [0mEpoch 434 Step 39/39 lr 0.001000 loss 0.0090 (0.0274) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:41] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:52:41] __main__ INFO: [0mVal 434
[32m[2022-06-16 11:52:42] __main__ INFO: [0mEpoch 434 loss 2.1115 acc@1 0.6555 acc@5 0.9619
[32m[2022-06-16 11:52:42] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:52:42] __main__ INFO: [0mTrain 435 16926
[32m[2022-06-16 11:52:44] __main__ INFO: [0mEpoch 435 Step 39/39 lr 0.001000 loss 0.0235 (0.0294) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:44] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:52:44] __main__ INFO: [0mVal 435
[32m[2022-06-16 11:52:44] __main__ INFO: [0mEpoch 435 loss 2.1224 acc@1 0.6547 acc@5 0.9622
[32m[2022-06-16 11:52:44] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:52:44] __main__ INFO: [0mTrain 436 16965
[32m[2022-06-16 11:52:46] __main__ INFO: [0mEpoch 436 Step 39/39 lr 0.001000 loss 0.0391 (0.0288) acc@1 0.9844 (0.9932) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:46] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:52:46] __main__ INFO: [0mVal 436
[32m[2022-06-16 11:52:47] __main__ INFO: [0mEpoch 436 loss 2.1186 acc@1 0.6564 acc@5 0.9626
[32m[2022-06-16 11:52:47] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:52:47] __main__ INFO: [0mTrain 437 17004
[32m[2022-06-16 11:52:48] __main__ INFO: [0mEpoch 437 Step 39/39 lr 0.001000 loss 0.0203 (0.0308) acc@1 0.9922 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:48] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:52:48] __main__ INFO: [0mVal 437
[32m[2022-06-16 11:52:49] __main__ INFO: [0mEpoch 437 loss 2.1375 acc@1 0.6533 acc@5 0.9625
[32m[2022-06-16 11:52:49] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:52:49] __main__ INFO: [0mTrain 438 17043
[32m[2022-06-16 11:52:51] __main__ INFO: [0mEpoch 438 Step 39/39 lr 0.001000 loss 0.0240 (0.0305) acc@1 1.0000 (0.9914) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:51] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:52:51] __main__ INFO: [0mVal 438
[32m[2022-06-16 11:52:52] __main__ INFO: [0mEpoch 438 loss 2.1364 acc@1 0.6549 acc@5 0.9625
[32m[2022-06-16 11:52:52] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:52:52] __main__ INFO: [0mTrain 439 17082
[32m[2022-06-16 11:52:53] __main__ INFO: [0mEpoch 439 Step 39/39 lr 0.001000 loss 0.0212 (0.0272) acc@1 0.9922 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:53] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-16 11:52:53] __main__ INFO: [0mVal 439
[32m[2022-06-16 11:52:54] __main__ INFO: [0mEpoch 439 loss 2.1444 acc@1 0.6522 acc@5 0.9625
[32m[2022-06-16 11:52:54] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:52:54] __main__ INFO: [0mTrain 440 17121
[32m[2022-06-16 11:52:56] __main__ INFO: [0mEpoch 440 Step 39/39 lr 0.001000 loss 0.0229 (0.0271) acc@1 1.0000 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:56] __main__ INFO: [0mElapsed 1.73
[32m[2022-06-16 11:52:56] __main__ INFO: [0mVal 440
[32m[2022-06-16 11:52:57] __main__ INFO: [0mEpoch 440 loss 2.1388 acc@1 0.6523 acc@5 0.9626
[32m[2022-06-16 11:52:57] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:52:57] __main__ INFO: [0mTrain 441 17160
[32m[2022-06-16 11:52:58] __main__ INFO: [0mEpoch 441 Step 39/39 lr 0.001000 loss 0.0309 (0.0289) acc@1 0.9922 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:52:58] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:52:58] __main__ INFO: [0mVal 441
[32m[2022-06-16 11:52:59] __main__ INFO: [0mEpoch 441 loss 2.1385 acc@1 0.6554 acc@5 0.9611
[32m[2022-06-16 11:52:59] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:52:59] __main__ INFO: [0mTrain 442 17199
[32m[2022-06-16 11:53:01] __main__ INFO: [0mEpoch 442 Step 39/39 lr 0.001000 loss 0.0307 (0.0317) acc@1 0.9844 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:01] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:53:01] __main__ INFO: [0mVal 442
[32m[2022-06-16 11:53:01] __main__ INFO: [0mEpoch 442 loss 2.1220 acc@1 0.6543 acc@5 0.9623
[32m[2022-06-16 11:53:01] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:53:01] __main__ INFO: [0mTrain 443 17238
[32m[2022-06-16 11:53:03] __main__ INFO: [0mEpoch 443 Step 39/39 lr 0.001000 loss 0.0146 (0.0291) acc@1 1.0000 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:03] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-16 11:53:03] __main__ INFO: [0mVal 443
[32m[2022-06-16 11:53:04] __main__ INFO: [0mEpoch 443 loss 2.1284 acc@1 0.6533 acc@5 0.9626
[32m[2022-06-16 11:53:04] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:53:04] __main__ INFO: [0mTrain 444 17277
[32m[2022-06-16 11:53:06] __main__ INFO: [0mEpoch 444 Step 39/39 lr 0.001000 loss 0.0344 (0.0326) acc@1 0.9922 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:06] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:53:06] __main__ INFO: [0mVal 444
[32m[2022-06-16 11:53:06] __main__ INFO: [0mEpoch 444 loss 2.1352 acc@1 0.6537 acc@5 0.9618
[32m[2022-06-16 11:53:06] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:53:06] __main__ INFO: [0mTrain 445 17316
[32m[2022-06-16 11:53:08] __main__ INFO: [0mEpoch 445 Step 39/39 lr 0.001000 loss 0.0189 (0.0266) acc@1 1.0000 (0.9950) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:08] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:53:08] __main__ INFO: [0mVal 445
[32m[2022-06-16 11:53:09] __main__ INFO: [0mEpoch 445 loss 2.1390 acc@1 0.6536 acc@5 0.9619
[32m[2022-06-16 11:53:09] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:53:09] __main__ INFO: [0mTrain 446 17355
[32m[2022-06-16 11:53:10] __main__ INFO: [0mEpoch 446 Step 39/39 lr 0.001000 loss 0.0316 (0.0274) acc@1 0.9922 (0.9944) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:11] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:53:11] __main__ INFO: [0mVal 446
[32m[2022-06-16 11:53:11] __main__ INFO: [0mEpoch 446 loss 2.1431 acc@1 0.6531 acc@5 0.9622
[32m[2022-06-16 11:53:11] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:53:11] __main__ INFO: [0mTrain 447 17394
[32m[2022-06-16 11:53:13] __main__ INFO: [0mEpoch 447 Step 39/39 lr 0.001000 loss 0.0265 (0.0312) acc@1 0.9922 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:13] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:53:13] __main__ INFO: [0mVal 447
[32m[2022-06-16 11:53:14] __main__ INFO: [0mEpoch 447 loss 2.1285 acc@1 0.6525 acc@5 0.9618
[32m[2022-06-16 11:53:14] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:53:14] __main__ INFO: [0mTrain 448 17433
[32m[2022-06-16 11:53:15] __main__ INFO: [0mEpoch 448 Step 39/39 lr 0.001000 loss 0.0215 (0.0302) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:15] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:53:15] __main__ INFO: [0mVal 448
[32m[2022-06-16 11:53:16] __main__ INFO: [0mEpoch 448 loss 2.1274 acc@1 0.6550 acc@5 0.9623
[32m[2022-06-16 11:53:16] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:53:16] __main__ INFO: [0mTrain 449 17472
[32m[2022-06-16 11:53:18] __main__ INFO: [0mEpoch 449 Step 39/39 lr 0.001000 loss 0.0262 (0.0274) acc@1 0.9922 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:18] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:53:18] __main__ INFO: [0mVal 449
[32m[2022-06-16 11:53:19] __main__ INFO: [0mEpoch 449 loss 2.1266 acc@1 0.6539 acc@5 0.9633
[32m[2022-06-16 11:53:19] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:53:19] __main__ INFO: [0mTrain 450 17511
[32m[2022-06-16 11:53:20] __main__ INFO: [0mEpoch 450 Step 39/39 lr 0.001000 loss 0.0212 (0.0289) acc@1 0.9922 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:20] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:53:20] __main__ INFO: [0mVal 450
[32m[2022-06-16 11:53:21] __main__ INFO: [0mEpoch 450 loss 2.1310 acc@1 0.6549 acc@5 0.9632
[32m[2022-06-16 11:53:21] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:53:21] __main__ INFO: [0mTrain 451 17550
[32m[2022-06-16 11:53:23] __main__ INFO: [0mEpoch 451 Step 39/39 lr 0.001000 loss 0.0270 (0.0295) acc@1 0.9922 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:23] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-16 11:53:23] __main__ INFO: [0mVal 451
[32m[2022-06-16 11:53:23] __main__ INFO: [0mEpoch 451 loss 2.1298 acc@1 0.6538 acc@5 0.9619
[32m[2022-06-16 11:53:23] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:53:23] __main__ INFO: [0mTrain 452 17589
[32m[2022-06-16 11:53:25] __main__ INFO: [0mEpoch 452 Step 39/39 lr 0.001000 loss 0.0370 (0.0286) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:25] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:53:25] __main__ INFO: [0mVal 452
[32m[2022-06-16 11:53:26] __main__ INFO: [0mEpoch 452 loss 2.1354 acc@1 0.6542 acc@5 0.9625
[32m[2022-06-16 11:53:26] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:53:26] __main__ INFO: [0mTrain 453 17628
[32m[2022-06-16 11:53:27] __main__ INFO: [0mEpoch 453 Step 39/39 lr 0.001000 loss 0.0095 (0.0268) acc@1 1.0000 (0.9946) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:28] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:53:28] __main__ INFO: [0mVal 453
[32m[2022-06-16 11:53:28] __main__ INFO: [0mEpoch 453 loss 2.1408 acc@1 0.6560 acc@5 0.9631
[32m[2022-06-16 11:53:28] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:53:28] __main__ INFO: [0mTrain 454 17667
[32m[2022-06-16 11:53:30] __main__ INFO: [0mEpoch 454 Step 39/39 lr 0.001000 loss 0.0209 (0.0292) acc@1 1.0000 (0.9916) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:30] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:53:30] __main__ INFO: [0mVal 454
[32m[2022-06-16 11:53:31] __main__ INFO: [0mEpoch 454 loss 2.1486 acc@1 0.6526 acc@5 0.9631
[32m[2022-06-16 11:53:31] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:53:31] __main__ INFO: [0mTrain 455 17706
[32m[2022-06-16 11:53:32] __main__ INFO: [0mEpoch 455 Step 39/39 lr 0.001000 loss 0.0271 (0.0287) acc@1 0.9922 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:32] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:53:32] __main__ INFO: [0mVal 455
[32m[2022-06-16 11:53:33] __main__ INFO: [0mEpoch 455 loss 2.1356 acc@1 0.6541 acc@5 0.9625
[32m[2022-06-16 11:53:33] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:53:33] __main__ INFO: [0mTrain 456 17745
[32m[2022-06-16 11:53:35] __main__ INFO: [0mEpoch 456 Step 39/39 lr 0.001000 loss 0.0253 (0.0279) acc@1 1.0000 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:35] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:53:35] __main__ INFO: [0mVal 456
[32m[2022-06-16 11:53:35] __main__ INFO: [0mEpoch 456 loss 2.1443 acc@1 0.6549 acc@5 0.9631
[32m[2022-06-16 11:53:35] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:53:35] __main__ INFO: [0mTrain 457 17784
[32m[2022-06-16 11:53:37] __main__ INFO: [0mEpoch 457 Step 39/39 lr 0.001000 loss 0.0299 (0.0279) acc@1 0.9922 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:37] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:53:37] __main__ INFO: [0mVal 457
[32m[2022-06-16 11:53:38] __main__ INFO: [0mEpoch 457 loss 2.1301 acc@1 0.6559 acc@5 0.9623
[32m[2022-06-16 11:53:38] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:53:38] __main__ INFO: [0mTrain 458 17823
[32m[2022-06-16 11:53:39] __main__ INFO: [0mEpoch 458 Step 39/39 lr 0.001000 loss 0.0438 (0.0268) acc@1 0.9922 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:39] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:53:39] __main__ INFO: [0mVal 458
[32m[2022-06-16 11:53:40] __main__ INFO: [0mEpoch 458 loss 2.1567 acc@1 0.6538 acc@5 0.9630
[32m[2022-06-16 11:53:40] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:53:40] __main__ INFO: [0mTrain 459 17862
[32m[2022-06-16 11:53:42] __main__ INFO: [0mEpoch 459 Step 39/39 lr 0.001000 loss 0.0276 (0.0294) acc@1 0.9922 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:42] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:53:42] __main__ INFO: [0mVal 459
[32m[2022-06-16 11:53:43] __main__ INFO: [0mEpoch 459 loss 2.1372 acc@1 0.6564 acc@5 0.9635
[32m[2022-06-16 11:53:43] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:53:43] __main__ INFO: [0mTrain 460 17901
[32m[2022-06-16 11:53:44] __main__ INFO: [0mEpoch 460 Step 39/39 lr 0.001000 loss 0.0130 (0.0285) acc@1 1.0000 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:44] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:53:44] __main__ INFO: [0mVal 460
[32m[2022-06-16 11:53:45] __main__ INFO: [0mEpoch 460 loss 2.1363 acc@1 0.6552 acc@5 0.9631
[32m[2022-06-16 11:53:45] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:53:45] __main__ INFO: [0mTrain 461 17940
[32m[2022-06-16 11:53:47] __main__ INFO: [0mEpoch 461 Step 39/39 lr 0.001000 loss 0.0189 (0.0259) acc@1 0.9922 (0.9952) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:47] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:53:47] __main__ INFO: [0mVal 461
[32m[2022-06-16 11:53:47] __main__ INFO: [0mEpoch 461 loss 2.1387 acc@1 0.6565 acc@5 0.9625
[32m[2022-06-16 11:53:47] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:53:47] __main__ INFO: [0mTrain 462 17979
[32m[2022-06-16 11:53:49] __main__ INFO: [0mEpoch 462 Step 39/39 lr 0.001000 loss 0.0724 (0.0259) acc@1 0.9688 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:49] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:53:49] __main__ INFO: [0mVal 462
[32m[2022-06-16 11:53:50] __main__ INFO: [0mEpoch 462 loss 2.1469 acc@1 0.6547 acc@5 0.9623
[32m[2022-06-16 11:53:50] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:53:50] __main__ INFO: [0mTrain 463 18018
[32m[2022-06-16 11:53:51] __main__ INFO: [0mEpoch 463 Step 39/39 lr 0.001000 loss 0.0330 (0.0266) acc@1 0.9922 (0.9946) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:51] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:53:51] __main__ INFO: [0mVal 463
[32m[2022-06-16 11:53:52] __main__ INFO: [0mEpoch 463 loss 2.1323 acc@1 0.6561 acc@5 0.9625
[32m[2022-06-16 11:53:52] __main__ INFO: [0mElapsed 0.68
[32m[2022-06-16 11:53:52] __main__ INFO: [0mTrain 464 18057
[32m[2022-06-16 11:53:54] __main__ INFO: [0mEpoch 464 Step 39/39 lr 0.001000 loss 0.0101 (0.0284) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:54] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:53:54] __main__ INFO: [0mVal 464
[32m[2022-06-16 11:53:55] __main__ INFO: [0mEpoch 464 loss 2.1261 acc@1 0.6557 acc@5 0.9615
[32m[2022-06-16 11:53:55] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-16 11:53:55] __main__ INFO: [0mTrain 465 18096
[32m[2022-06-16 11:53:56] __main__ INFO: [0mEpoch 465 Step 39/39 lr 0.001000 loss 0.0218 (0.0261) acc@1 1.0000 (0.9938) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:56] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:53:56] __main__ INFO: [0mVal 465
[32m[2022-06-16 11:53:57] __main__ INFO: [0mEpoch 465 loss 2.1289 acc@1 0.6585 acc@5 0.9628
[32m[2022-06-16 11:53:57] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-16 11:53:57] __main__ INFO: [0mTrain 466 18135
[32m[2022-06-16 11:53:59] __main__ INFO: [0mEpoch 466 Step 39/39 lr 0.001000 loss 0.0561 (0.0251) acc@1 0.9766 (0.9948) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:53:59] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:53:59] __main__ INFO: [0mVal 466
[32m[2022-06-16 11:53:59] __main__ INFO: [0mEpoch 466 loss 2.1363 acc@1 0.6565 acc@5 0.9611
[32m[2022-06-16 11:53:59] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:53:59] __main__ INFO: [0mTrain 467 18174
[32m[2022-06-16 11:54:01] __main__ INFO: [0mEpoch 467 Step 39/39 lr 0.001000 loss 0.0205 (0.0291) acc@1 0.9922 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:01] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:54:01] __main__ INFO: [0mVal 467
[32m[2022-06-16 11:54:02] __main__ INFO: [0mEpoch 467 loss 2.1265 acc@1 0.6603 acc@5 0.9623
[32m[2022-06-16 11:54:02] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:54:02] __main__ INFO: [0mTrain 468 18213
[32m[2022-06-16 11:54:04] __main__ INFO: [0mEpoch 468 Step 39/39 lr 0.001000 loss 0.0099 (0.0271) acc@1 1.0000 (0.9922) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:04] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:54:04] __main__ INFO: [0mVal 468
[32m[2022-06-16 11:54:04] __main__ INFO: [0mEpoch 468 loss 2.1405 acc@1 0.6577 acc@5 0.9611
[32m[2022-06-16 11:54:04] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:54:04] __main__ INFO: [0mTrain 469 18252
[32m[2022-06-16 11:54:06] __main__ INFO: [0mEpoch 469 Step 39/39 lr 0.001000 loss 0.0121 (0.0261) acc@1 1.0000 (0.9932) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:06] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:54:06] __main__ INFO: [0mVal 469
[32m[2022-06-16 11:54:07] __main__ INFO: [0mEpoch 469 loss 2.1560 acc@1 0.6544 acc@5 0.9617
[32m[2022-06-16 11:54:07] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:54:07] __main__ INFO: [0mTrain 470 18291
[32m[2022-06-16 11:54:08] __main__ INFO: [0mEpoch 470 Step 39/39 lr 0.001000 loss 0.0376 (0.0287) acc@1 0.9844 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:08] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:54:08] __main__ INFO: [0mVal 470
[32m[2022-06-16 11:54:09] __main__ INFO: [0mEpoch 470 loss 2.1530 acc@1 0.6551 acc@5 0.9616
[32m[2022-06-16 11:54:09] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:54:09] __main__ INFO: [0mTrain 471 18330
[32m[2022-06-16 11:54:11] __main__ INFO: [0mEpoch 471 Step 39/39 lr 0.001000 loss 0.0342 (0.0256) acc@1 0.9922 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:11] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:54:11] __main__ INFO: [0mVal 471
[32m[2022-06-16 11:54:12] __main__ INFO: [0mEpoch 471 loss 2.1540 acc@1 0.6551 acc@5 0.9617
[32m[2022-06-16 11:54:12] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:54:12] __main__ INFO: [0mTrain 472 18369
[32m[2022-06-16 11:54:13] __main__ INFO: [0mEpoch 472 Step 39/39 lr 0.001000 loss 0.0382 (0.0282) acc@1 0.9922 (0.9924) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:13] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:54:13] __main__ INFO: [0mVal 472
[32m[2022-06-16 11:54:14] __main__ INFO: [0mEpoch 472 loss 2.1454 acc@1 0.6546 acc@5 0.9629
[32m[2022-06-16 11:54:14] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:54:14] __main__ INFO: [0mTrain 473 18408
[32m[2022-06-16 11:54:16] __main__ INFO: [0mEpoch 473 Step 39/39 lr 0.001000 loss 0.0235 (0.0302) acc@1 0.9922 (0.9918) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:16] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:54:16] __main__ INFO: [0mVal 473
[32m[2022-06-16 11:54:17] __main__ INFO: [0mEpoch 473 loss 2.1528 acc@1 0.6552 acc@5 0.9628
[32m[2022-06-16 11:54:17] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:54:17] __main__ INFO: [0mTrain 474 18447
[32m[2022-06-16 11:54:18] __main__ INFO: [0mEpoch 474 Step 39/39 lr 0.001000 loss 0.0290 (0.0249) acc@1 0.9844 (0.9944) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:18] __main__ INFO: [0mElapsed 1.60
[32m[2022-06-16 11:54:18] __main__ INFO: [0mVal 474
[32m[2022-06-16 11:54:19] __main__ INFO: [0mEpoch 474 loss 2.1390 acc@1 0.6572 acc@5 0.9619
[32m[2022-06-16 11:54:19] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:54:19] __main__ INFO: [0mTrain 475 18486
[32m[2022-06-16 11:54:20] __main__ INFO: [0mEpoch 475 Step 39/39 lr 0.001000 loss 0.0087 (0.0282) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:21] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:54:21] __main__ INFO: [0mVal 475
[32m[2022-06-16 11:54:21] __main__ INFO: [0mEpoch 475 loss 2.1539 acc@1 0.6565 acc@5 0.9610
[32m[2022-06-16 11:54:21] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:54:21] __main__ INFO: [0mTrain 476 18525
[32m[2022-06-16 11:54:23] __main__ INFO: [0mEpoch 476 Step 39/39 lr 0.001000 loss 0.0217 (0.0278) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:23] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-16 11:54:23] __main__ INFO: [0mVal 476
[32m[2022-06-16 11:54:24] __main__ INFO: [0mEpoch 476 loss 2.1586 acc@1 0.6556 acc@5 0.9615
[32m[2022-06-16 11:54:24] __main__ INFO: [0mElapsed 0.70
[32m[2022-06-16 11:54:24] __main__ INFO: [0mTrain 477 18564
[32m[2022-06-16 11:54:25] __main__ INFO: [0mEpoch 477 Step 39/39 lr 0.001000 loss 0.0367 (0.0292) acc@1 0.9922 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:25] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:54:25] __main__ INFO: [0mVal 477
[32m[2022-06-16 11:54:26] __main__ INFO: [0mEpoch 477 loss 2.1445 acc@1 0.6557 acc@5 0.9619
[32m[2022-06-16 11:54:26] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:54:26] __main__ INFO: [0mTrain 478 18603
[32m[2022-06-16 11:54:28] __main__ INFO: [0mEpoch 478 Step 39/39 lr 0.001000 loss 0.0159 (0.0244) acc@1 1.0000 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:28] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:54:28] __main__ INFO: [0mVal 478
[32m[2022-06-16 11:54:29] __main__ INFO: [0mEpoch 478 loss 2.1575 acc@1 0.6555 acc@5 0.9621
[32m[2022-06-16 11:54:29] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:54:29] __main__ INFO: [0mTrain 479 18642
[32m[2022-06-16 11:54:30] __main__ INFO: [0mEpoch 479 Step 39/39 lr 0.001000 loss 0.0241 (0.0262) acc@1 1.0000 (0.9944) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:30] __main__ INFO: [0mElapsed 1.64
[32m[2022-06-16 11:54:30] __main__ INFO: [0mVal 479
[32m[2022-06-16 11:54:31] __main__ INFO: [0mEpoch 479 loss 2.1486 acc@1 0.6559 acc@5 0.9620
[32m[2022-06-16 11:54:31] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-16 11:54:31] __main__ INFO: [0mTrain 480 18681
[32m[2022-06-16 11:54:32] __main__ INFO: [0mEpoch 480 Step 39/39 lr 0.001000 loss 0.0456 (0.0257) acc@1 0.9844 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:33] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:54:33] __main__ INFO: [0mVal 480
[32m[2022-06-16 11:54:33] __main__ INFO: [0mEpoch 480 loss 2.1658 acc@1 0.6529 acc@5 0.9621
[32m[2022-06-16 11:54:33] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:54:33] __main__ INFO: [0mTrain 481 18720
[32m[2022-06-16 11:54:35] __main__ INFO: [0mEpoch 481 Step 39/39 lr 0.001000 loss 0.0112 (0.0227) acc@1 1.0000 (0.9962) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:35] __main__ INFO: [0mElapsed 1.58
[32m[2022-06-16 11:54:35] __main__ INFO: [0mVal 481
[32m[2022-06-16 11:54:36] __main__ INFO: [0mEpoch 481 loss 2.1716 acc@1 0.6541 acc@5 0.9630
[32m[2022-06-16 11:54:36] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:54:36] __main__ INFO: [0mTrain 482 18759
[32m[2022-06-16 11:54:37] __main__ INFO: [0mEpoch 482 Step 39/39 lr 0.001000 loss 0.0194 (0.0266) acc@1 0.9922 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:37] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:54:37] __main__ INFO: [0mVal 482
[32m[2022-06-16 11:54:38] __main__ INFO: [0mEpoch 482 loss 2.1628 acc@1 0.6530 acc@5 0.9624
[32m[2022-06-16 11:54:38] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:54:38] __main__ INFO: [0mTrain 483 18798
[32m[2022-06-16 11:54:40] __main__ INFO: [0mEpoch 483 Step 39/39 lr 0.001000 loss 0.0218 (0.0272) acc@1 1.0000 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:40] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:54:40] __main__ INFO: [0mVal 483
[32m[2022-06-16 11:54:41] __main__ INFO: [0mEpoch 483 loss 2.1497 acc@1 0.6567 acc@5 0.9622
[32m[2022-06-16 11:54:41] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:54:41] __main__ INFO: [0mTrain 484 18837
[32m[2022-06-16 11:54:42] __main__ INFO: [0mEpoch 484 Step 39/39 lr 0.001000 loss 0.0324 (0.0316) acc@1 0.9844 (0.9910) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:42] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:54:42] __main__ INFO: [0mVal 484
[32m[2022-06-16 11:54:43] __main__ INFO: [0mEpoch 484 loss 2.1675 acc@1 0.6539 acc@5 0.9638
[32m[2022-06-16 11:54:43] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:54:43] __main__ INFO: [0mTrain 485 18876
[32m[2022-06-16 11:54:45] __main__ INFO: [0mEpoch 485 Step 39/39 lr 0.001000 loss 0.0187 (0.0266) acc@1 1.0000 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:45] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:54:45] __main__ INFO: [0mVal 485
[32m[2022-06-16 11:54:45] __main__ INFO: [0mEpoch 485 loss 2.1780 acc@1 0.6540 acc@5 0.9629
[32m[2022-06-16 11:54:45] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:54:45] __main__ INFO: [0mTrain 486 18915
[32m[2022-06-16 11:54:47] __main__ INFO: [0mEpoch 486 Step 39/39 lr 0.001000 loss 0.0609 (0.0255) acc@1 0.9688 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:47] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:54:47] __main__ INFO: [0mVal 486
[32m[2022-06-16 11:54:48] __main__ INFO: [0mEpoch 486 loss 2.1768 acc@1 0.6548 acc@5 0.9633
[32m[2022-06-16 11:54:48] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:54:48] __main__ INFO: [0mTrain 487 18954
[32m[2022-06-16 11:54:49] __main__ INFO: [0mEpoch 487 Step 39/39 lr 0.001000 loss 0.0420 (0.0256) acc@1 0.9922 (0.9928) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:49] __main__ INFO: [0mElapsed 1.62
[32m[2022-06-16 11:54:49] __main__ INFO: [0mVal 487
[32m[2022-06-16 11:54:50] __main__ INFO: [0mEpoch 487 loss 2.1664 acc@1 0.6548 acc@5 0.9627
[32m[2022-06-16 11:54:50] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-16 11:54:50] __main__ INFO: [0mTrain 488 18993
[32m[2022-06-16 11:54:52] __main__ INFO: [0mEpoch 488 Step 39/39 lr 0.001000 loss 0.0194 (0.0244) acc@1 1.0000 (0.9942) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:52] __main__ INFO: [0mElapsed 1.63
[32m[2022-06-16 11:54:52] __main__ INFO: [0mVal 488
[32m[2022-06-16 11:54:53] __main__ INFO: [0mEpoch 488 loss 2.1786 acc@1 0.6535 acc@5 0.9620
[32m[2022-06-16 11:54:53] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:54:53] __main__ INFO: [0mTrain 489 19032
[32m[2022-06-16 11:54:54] __main__ INFO: [0mEpoch 489 Step 39/39 lr 0.001000 loss 0.0351 (0.0256) acc@1 1.0000 (0.9952) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:54] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:54:54] __main__ INFO: [0mVal 489
[32m[2022-06-16 11:54:55] __main__ INFO: [0mEpoch 489 loss 2.1695 acc@1 0.6575 acc@5 0.9625
[32m[2022-06-16 11:54:55] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:54:55] __main__ INFO: [0mTrain 490 19071
[32m[2022-06-16 11:54:57] __main__ INFO: [0mEpoch 490 Step 39/39 lr 0.001000 loss 0.0042 (0.0293) acc@1 1.0000 (0.9920) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:57] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:54:57] __main__ INFO: [0mVal 490
[32m[2022-06-16 11:54:57] __main__ INFO: [0mEpoch 490 loss 2.1924 acc@1 0.6535 acc@5 0.9613
[32m[2022-06-16 11:54:57] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-16 11:54:57] __main__ INFO: [0mTrain 491 19110
[32m[2022-06-16 11:54:59] __main__ INFO: [0mEpoch 491 Step 39/39 lr 0.001000 loss 0.0265 (0.0264) acc@1 0.9922 (0.9930) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:54:59] __main__ INFO: [0mElapsed 1.70
[32m[2022-06-16 11:54:59] __main__ INFO: [0mVal 491
[32m[2022-06-16 11:55:00] __main__ INFO: [0mEpoch 491 loss 2.1796 acc@1 0.6535 acc@5 0.9631
[32m[2022-06-16 11:55:00] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-16 11:55:00] __main__ INFO: [0mTrain 492 19149
[32m[2022-06-16 11:55:02] __main__ INFO: [0mEpoch 492 Step 39/39 lr 0.001000 loss 0.0543 (0.0259) acc@1 0.9844 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:02] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-16 11:55:02] __main__ INFO: [0mVal 492
[32m[2022-06-16 11:55:02] __main__ INFO: [0mEpoch 492 loss 2.1670 acc@1 0.6542 acc@5 0.9623
[32m[2022-06-16 11:55:02] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:55:02] __main__ INFO: [0mTrain 493 19188
[32m[2022-06-16 11:55:04] __main__ INFO: [0mEpoch 493 Step 39/39 lr 0.001000 loss 0.0260 (0.0215) acc@1 0.9922 (0.9958) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:04] __main__ INFO: [0mElapsed 1.69
[32m[2022-06-16 11:55:04] __main__ INFO: [0mVal 493
[32m[2022-06-16 11:55:05] __main__ INFO: [0mEpoch 493 loss 2.1771 acc@1 0.6551 acc@5 0.9615
[32m[2022-06-16 11:55:05] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:55:05] __main__ INFO: [0mTrain 494 19227
[32m[2022-06-16 11:55:06] __main__ INFO: [0mEpoch 494 Step 39/39 lr 0.001000 loss 0.0422 (0.0274) acc@1 0.9766 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:06] __main__ INFO: [0mElapsed 1.59
[32m[2022-06-16 11:55:06] __main__ INFO: [0mVal 494
[32m[2022-06-16 11:55:07] __main__ INFO: [0mEpoch 494 loss 2.1593 acc@1 0.6541 acc@5 0.9632
[32m[2022-06-16 11:55:07] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:55:07] __main__ INFO: [0mTrain 495 19266
[32m[2022-06-16 11:55:09] __main__ INFO: [0mEpoch 495 Step 39/39 lr 0.001000 loss 0.0142 (0.0235) acc@1 0.9922 (0.9936) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:09] __main__ INFO: [0mElapsed 1.65
[32m[2022-06-16 11:55:09] __main__ INFO: [0mVal 495
[32m[2022-06-16 11:55:09] __main__ INFO: [0mEpoch 495 loss 2.1598 acc@1 0.6558 acc@5 0.9626
[32m[2022-06-16 11:55:09] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:55:09] __main__ INFO: [0mTrain 496 19305
[32m[2022-06-16 11:55:11] __main__ INFO: [0mEpoch 496 Step 39/39 lr 0.001000 loss 0.0339 (0.0246) acc@1 0.9844 (0.9940) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:11] __main__ INFO: [0mElapsed 1.68
[32m[2022-06-16 11:55:11] __main__ INFO: [0mVal 496
[32m[2022-06-16 11:55:12] __main__ INFO: [0mEpoch 496 loss 2.1649 acc@1 0.6543 acc@5 0.9630
[32m[2022-06-16 11:55:12] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-16 11:55:12] __main__ INFO: [0mTrain 497 19344
[32m[2022-06-16 11:55:14] __main__ INFO: [0mEpoch 497 Step 39/39 lr 0.001000 loss 0.0086 (0.0292) acc@1 1.0000 (0.9926) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:14] __main__ INFO: [0mElapsed 1.67
[32m[2022-06-16 11:55:14] __main__ INFO: [0mVal 497
[32m[2022-06-16 11:55:14] __main__ INFO: [0mEpoch 497 loss 2.1674 acc@1 0.6542 acc@5 0.9622
[32m[2022-06-16 11:55:14] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-16 11:55:14] __main__ INFO: [0mTrain 498 19383
[32m[2022-06-16 11:55:16] __main__ INFO: [0mEpoch 498 Step 39/39 lr 0.001000 loss 0.0056 (0.0251) acc@1 1.0000 (0.9934) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:16] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-16 11:55:16] __main__ INFO: [0mVal 498
[32m[2022-06-16 11:55:17] __main__ INFO: [0mEpoch 498 loss 2.1594 acc@1 0.6532 acc@5 0.9621
[32m[2022-06-16 11:55:17] __main__ INFO: [0mElapsed 0.71
[32m[2022-06-16 11:55:17] __main__ INFO: [0mTrain 499 19422
[32m[2022-06-16 11:55:18] __main__ INFO: [0mEpoch 499 Step 39/39 lr 0.001000 loss 0.0390 (0.0261) acc@1 0.9922 (0.9942) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:19] __main__ INFO: [0mElapsed 1.66
[32m[2022-06-16 11:55:19] __main__ INFO: [0mVal 499
[32m[2022-06-16 11:55:19] __main__ INFO: [0mEpoch 499 loss 2.1697 acc@1 0.6549 acc@5 0.9614
[32m[2022-06-16 11:55:19] __main__ INFO: [0mElapsed 0.69
[32m[2022-06-16 11:55:19] __main__ INFO: [0mTrain 500 19461
[32m[2022-06-16 11:55:21] __main__ INFO: [0mEpoch 500 Step 39/39 lr 0.001000 loss 0.0553 (0.0281) acc@1 0.9844 (0.9932) acc@5 1.0000 (1.0000)
[32m[2022-06-16 11:55:21] __main__ INFO: [0mElapsed 1.61
[32m[2022-06-16 11:55:21] __main__ INFO: [0mVal 500
[32m[2022-06-16 11:55:22] __main__ INFO: [0mEpoch 500 loss 2.1742 acc@1 0.6553 acc@5 0.9627
[32m[2022-06-16 11:55:22] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-16 11:55:22] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00500.pth
[32m[2022-06-17 04:22:58] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 10
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: True
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-17 04:22:58] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-17 04:23:02] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-17 04:23:02] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-17 04:23:02] __main__ INFO: [0mVal 0
[32m[2022-06-17 04:23:03] __main__ INFO: [0mEpoch 0 loss 27477.4463 acc@1 0.1002 acc@5 0.5020
[32m[2022-06-17 04:23:03] __main__ INFO: [0mElapsed 0.84
[32m[2022-06-17 04:23:03] __main__ INFO: [0mTrain 1 0
[32m[2022-06-17 04:23:05] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 2.3365 (4.0211) acc@1 0.1355 (0.0997) acc@5 0.5546 (0.5110)
[32m[2022-06-17 04:23:06] __main__ INFO: [0mElapsed 2.24
[32m[2022-06-17 04:23:06] __main__ INFO: [0mVal 1
[32m[2022-06-17 04:23:06] __main__ INFO: [0mEpoch 1 loss 5.8008 acc@1 0.0947 acc@5 0.5237
[32m[2022-06-17 04:23:06] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-17 04:23:06] __main__ INFO: [0mTrain 2 39
[32m[2022-06-17 04:23:08] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 2.3730 (2.3377) acc@1 0.1220 (0.1027) acc@5 0.5030 (0.5087)
[32m[2022-06-17 04:23:08] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-17 04:23:08] __main__ INFO: [0mVal 2
[32m[2022-06-17 04:23:09] __main__ INFO: [0mEpoch 2 loss 2.3191 acc@1 0.1097 acc@5 0.5037
[32m[2022-06-17 04:23:09] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-17 04:23:09] __main__ INFO: [0mTrain 3 78
[32m[2022-06-17 04:23:11] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 2.3299 (2.3285) acc@1 0.1357 (0.0996) acc@5 0.5598 (0.5102)
[32m[2022-06-17 04:23:11] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-17 04:23:11] __main__ INFO: [0mVal 3
[32m[2022-06-17 04:23:11] __main__ INFO: [0mEpoch 3 loss 2.3336 acc@1 0.1047 acc@5 0.5059
[32m[2022-06-17 04:23:11] __main__ INFO: [0mElapsed 0.85
[32m[2022-06-17 04:23:11] __main__ INFO: [0mTrain 4 117
[32m[2022-06-17 04:23:13] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 2.3250 (2.3306) acc@1 0.0928 (0.1022) acc@5 0.4674 (0.5160)
[32m[2022-06-17 04:23:13] __main__ INFO: [0mElapsed 1.79
[32m[2022-06-17 04:23:13] __main__ INFO: [0mVal 4
[32m[2022-06-17 04:23:14] __main__ INFO: [0mEpoch 4 loss 2.3364 acc@1 0.1107 acc@5 0.5168
[32m[2022-06-17 04:23:14] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-17 04:23:14] __main__ INFO: [0mTrain 5 156
[32m[2022-06-17 04:23:16] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 2.3119 (2.3195) acc@1 0.1167 (0.0998) acc@5 0.5164 (0.5136)
[32m[2022-06-17 04:23:16] __main__ INFO: [0mElapsed 1.71
[32m[2022-06-17 04:23:16] __main__ INFO: [0mVal 5
[32m[2022-06-17 04:23:17] __main__ INFO: [0mEpoch 5 loss 2.4240 acc@1 0.1136 acc@5 0.5212
[32m[2022-06-17 04:23:17] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-17 04:23:17] __main__ INFO: [0mTrain 6 195
[32m[2022-06-17 04:23:18] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 2.3182 (2.3159) acc@1 0.1053 (0.0954) acc@5 0.5129 (0.5048)
[32m[2022-06-17 04:23:18] __main__ INFO: [0mElapsed 1.79
[32m[2022-06-17 04:23:18] __main__ INFO: [0mVal 6
[32m[2022-06-17 04:23:19] __main__ INFO: [0mEpoch 6 loss 2.3251 acc@1 0.1102 acc@5 0.5114
[32m[2022-06-17 04:23:19] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-17 04:23:19] __main__ INFO: [0mTrain 7 234
[32m[2022-06-17 04:23:21] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 2.3024 (2.3197) acc@1 0.1042 (0.1020) acc@5 0.5677 (0.5105)
[32m[2022-06-17 04:23:21] __main__ INFO: [0mElapsed 1.83
[32m[2022-06-17 04:23:21] __main__ INFO: [0mVal 7
[32m[2022-06-17 04:23:22] __main__ INFO: [0mEpoch 7 loss 2.3297 acc@1 0.1093 acc@5 0.5154
[32m[2022-06-17 04:23:22] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-17 04:23:22] __main__ INFO: [0mTrain 8 273
[32m[2022-06-17 04:23:23] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 2.3239 (2.3116) acc@1 0.1133 (0.1020) acc@5 0.4459 (0.5160)
[32m[2022-06-17 04:23:24] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-17 04:23:24] __main__ INFO: [0mVal 8
[32m[2022-06-17 04:23:24] __main__ INFO: [0mEpoch 8 loss 2.3113 acc@1 0.1254 acc@5 0.5157
[32m[2022-06-17 04:23:24] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-17 04:23:24] __main__ INFO: [0mTrain 9 312
[32m[2022-06-17 04:23:26] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 2.3349 (2.3096) acc@1 0.0595 (0.1086) acc@5 0.4914 (0.5211)
[32m[2022-06-17 04:23:26] __main__ INFO: [0mElapsed 1.84
[32m[2022-06-17 04:23:26] __main__ INFO: [0mVal 9
[32m[2022-06-17 04:23:27] __main__ INFO: [0mEpoch 9 loss 2.3295 acc@1 0.1132 acc@5 0.5229
[32m[2022-06-17 04:23:27] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-17 04:23:27] __main__ INFO: [0mTrain 10 351
[32m[2022-06-17 04:23:29] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 2.3095 (2.3134) acc@1 0.0636 (0.1127) acc@5 0.5348 (0.5103)
[32m[2022-06-17 04:23:29] __main__ INFO: [0mElapsed 1.78
[32m[2022-06-17 04:23:29] __main__ INFO: [0mVal 10
[32m[2022-06-17 04:23:29] __main__ INFO: [0mEpoch 10 loss 2.3409 acc@1 0.1096 acc@5 0.5411
[32m[2022-06-17 04:23:29] __main__ INFO: [0mElapsed 0.79
[32m[2022-06-17 04:23:29] fvcore.common.checkpoint INFO: [0mSaving checkpoint to experiments/cifar10/exp00/checkpoint_00010.pth
[32m[2022-06-17 04:29:25] __main__ INFO: [0mdevice: cuda
cudnn:
  benchmark: True
  deterministic: False
dataset:
  name: CIFAR10
  dataset_dir: ~/.torch/datasets/CIFAR10
  image_size: 32
  n_channels: 3
  n_classes: 10
model:
  type: cifar
  name: resnet
  init_mode: kaiming_fan_out
  vgg:
    n_channels: [64, 128, 256, 512, 512]
    n_layers: [2, 2, 3, 3, 3]
    use_bn: True
  resnet:
    depth: 50
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
  resnet_preact:
    depth: 110
    n_blocks: [2, 2, 2, 2]
    block_type: basic
    initial_channels: 16
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
  wrn:
    depth: 28
    initial_channels: 16
    widening_factor: 10
    drop_rate: 0.0
  densenet:
    depth: 100
    n_blocks: [6, 12, 24, 16]
    block_type: bottleneck
    growth_rate: 12
    drop_rate: 0.0
    compression_rate: 0.5
  pyramidnet:
    depth: 272
    n_blocks: [3, 24, 36, 3]
    initial_channels: 16
    block_type: bottleneck
    alpha: 200
  resnext:
    depth: 29
    n_blocks: [3, 4, 6, 3]
    initial_channels: 64
    cardinality: 8
    base_channels: 4
  shake_shake:
    depth: 26
    initial_channels: 96
    shake_forward: True
    shake_backward: True
    shake_image: True
  se_resnet_preact:
    depth: 110
    initial_channels: 16
    se_reduction: 16
    block_type: basic
    remove_first_relu: False
    add_last_bn: False
    preact_stage: [True, True, True]
train:
  checkpoint: ''
  resume: False
  use_apex: True
  precision: O0
  batch_size: 128
  small_train: True
  subdivision: 1
  optimizer: sgd
  base_lr: 0.1
  momentum: 0.9
  nesterov: True
  weight_decay: 0.0001
  no_weight_decay_on_bn: False
  gradient_clip: 0.0
  start_epoch: 0
  seed: 0
  val_first: True
  val_period: 1
  val_ratio: 0.0
  use_test_as_val: True
  output_dir: experiments/cifar10/exp00
  log_period: 100
  checkpoint_period: 100
  use_tensorboard: True
  dataloader:
    num_workers: 2
    drop_last: True
    pin_memory: False
    non_blocking: False
  distributed: False
  dist:
    backend: nccl
    init_method: env://
    world_size: -1
    node_rank: -1
    local_rank: 0
    use_sync_bn: False
tensorboard:
  train_images: False
  val_images: False
  model_params: False
optim:
  adam:
    betas: (0.9, 0.999)
  lars:
    eps: 1e-09
    threshold: 0.01
  adabound:
    betas: (0.9, 0.999)
    final_lr: 0.1
    gamma: 0.001
scheduler:
  epochs: 100
  warmup:
    type: none
    epochs: 0
    start_factor: 0.001
    exponent: 4
  type: multistep
  milestones: [80, 120]
  lr_decay: 0.1
  lr_min_factor: 0.001
  T0: 10
  T_mul: 1.0
validation:
  batch_size: 256
  dataloader:
    num_workers: 2
    drop_last: False
    pin_memory: False
    non_blocking: False
augmentation:
  use_random_crop: True
  use_random_horizontal_flip: True
  use_cutout: False
  use_random_erasing: False
  use_dual_cutout: False
  use_mixup: False
  use_ricap: True
  use_cutmix: False
  use_label_smoothing: False
  random_crop:
    padding: 4
    fill: 0
    padding_mode: constant
  random_horizontal_flip:
    prob: 0.5
  cutout:
    prob: 1.0
    mask_size: 16
    cut_inside: False
    mask_color: 0
    dual_cutout_alpha: 0.1
  random_erasing:
    prob: 0.5
    area_ratio_range: [0.02, 0.4]
    min_aspect_ratio: 0.3
    max_attempt: 20
  mixup:
    alpha: 1.0
  ricap:
    beta: 0.3
  cutmix:
    alpha: 1.0
  label_smoothing:
    epsilon: 0.1
tta:
  use_resize: False
  use_center_crop: False
  resize: 256
test:
  checkpoint: ''
  output_dir: ''
  batch_size: 256
  dataloader:
    num_workers: 2
    pin_memory: False
[32m[2022-06-17 04:29:25] __main__ INFO: [0menv_info:
  pytorch_version: 1.9.0a0+c3d40fd
  cuda_version: 11.3
  cudnn_version: 8201
  num_gpus: 2
  gpu_name: TITAN RTX
  gpu_capability: 7.5
[32m[2022-06-17 04:29:29] __main__ INFO: [0mMACs   : 112.57M
[32m[2022-06-17 04:29:29] __main__ INFO: [0m#params: 758.55K
[32m[2022-06-17 04:29:29] __main__ INFO: [0mVal 0
[32m[2022-06-17 04:29:30] __main__ INFO: [0mEpoch 0 loss 27477.4460 acc@1 0.1002 acc@5 0.5020
[32m[2022-06-17 04:29:30] __main__ INFO: [0mElapsed 0.86
[32m[2022-06-17 04:29:30] __main__ INFO: [0mTrain 1 0
[32m[2022-06-17 04:29:32] __main__ INFO: [0mEpoch 1 Step 39/39 lr 0.100000 loss 2.3478 (4.0921) acc@1 0.1238 (0.1062) acc@5 0.5112 (0.5020)
[32m[2022-06-17 04:29:32] __main__ INFO: [0mElapsed 2.12
[32m[2022-06-17 04:29:32] __main__ INFO: [0mVal 1
[32m[2022-06-17 04:29:33] __main__ INFO: [0mEpoch 1 loss 16.1683 acc@1 0.1008 acc@5 0.5515
[32m[2022-06-17 04:29:33] __main__ INFO: [0mElapsed 0.73
[32m[2022-06-17 04:29:33] __main__ INFO: [0mTrain 2 39
[32m[2022-06-17 04:29:34] __main__ INFO: [0mEpoch 2 Step 39/39 lr 0.100000 loss 2.3146 (2.3406) acc@1 0.1089 (0.1062) acc@5 0.5016 (0.5118)
[32m[2022-06-17 04:29:35] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-17 04:29:35] __main__ INFO: [0mVal 2
[32m[2022-06-17 04:29:35] __main__ INFO: [0mEpoch 2 loss 2.3304 acc@1 0.1190 acc@5 0.5266
[32m[2022-06-17 04:29:35] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-17 04:29:35] __main__ INFO: [0mTrain 3 78
[32m[2022-06-17 04:29:37] __main__ INFO: [0mEpoch 3 Step 39/39 lr 0.100000 loss 2.3135 (2.3211) acc@1 0.0792 (0.1095) acc@5 0.4970 (0.5283)
[32m[2022-06-17 04:29:37] __main__ INFO: [0mElapsed 1.80
[32m[2022-06-17 04:29:37] __main__ INFO: [0mVal 3
[32m[2022-06-17 04:29:38] __main__ INFO: [0mEpoch 3 loss 2.3154 acc@1 0.1247 acc@5 0.5285
[32m[2022-06-17 04:29:38] __main__ INFO: [0mElapsed 0.74
[32m[2022-06-17 04:29:38] __main__ INFO: [0mTrain 4 117
[32m[2022-06-17 04:29:40] __main__ INFO: [0mEpoch 4 Step 39/39 lr 0.100000 loss 2.3182 (2.3130) acc@1 0.0866 (0.1087) acc@5 0.5017 (0.5281)
[32m[2022-06-17 04:29:40] __main__ INFO: [0mElapsed 1.79
[32m[2022-06-17 04:29:40] __main__ INFO: [0mVal 4
[32m[2022-06-17 04:29:40] __main__ INFO: [0mEpoch 4 loss 2.3173 acc@1 0.1328 acc@5 0.5551
[32m[2022-06-17 04:29:40] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-17 04:29:40] __main__ INFO: [0mTrain 5 156
[32m[2022-06-17 04:29:42] __main__ INFO: [0mEpoch 5 Step 39/39 lr 0.100000 loss 2.2783 (2.3028) acc@1 0.0989 (0.1137) acc@5 0.5037 (0.5369)
[32m[2022-06-17 04:29:42] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-17 04:29:42] __main__ INFO: [0mVal 5
[32m[2022-06-17 04:29:43] __main__ INFO: [0mEpoch 5 loss 2.3040 acc@1 0.1004 acc@5 0.5004
[32m[2022-06-17 04:29:43] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-17 04:29:43] __main__ INFO: [0mTrain 6 195
[32m[2022-06-17 04:29:45] __main__ INFO: [0mEpoch 6 Step 39/39 lr 0.100000 loss 2.2941 (2.2996) acc@1 0.1393 (0.1204) acc@5 0.5226 (0.5423)
[32m[2022-06-17 04:29:45] __main__ INFO: [0mElapsed 1.75
[32m[2022-06-17 04:29:45] __main__ INFO: [0mVal 6
[32m[2022-06-17 04:29:46] __main__ INFO: [0mEpoch 6 loss 2.3047 acc@1 0.1004 acc@5 0.5005
[32m[2022-06-17 04:29:46] __main__ INFO: [0mElapsed 0.80
[32m[2022-06-17 04:29:46] __main__ INFO: [0mTrain 7 234
[32m[2022-06-17 04:29:47] __main__ INFO: [0mEpoch 7 Step 39/39 lr 0.100000 loss 2.2612 (2.2863) acc@1 0.1439 (0.1268) acc@5 0.5300 (0.5505)
[32m[2022-06-17 04:29:47] __main__ INFO: [0mElapsed 1.84
[32m[2022-06-17 04:29:47] __main__ INFO: [0mVal 7
[32m[2022-06-17 04:29:48] __main__ INFO: [0mEpoch 7 loss 2.2396 acc@1 0.1540 acc@5 0.6024
[32m[2022-06-17 04:29:48] __main__ INFO: [0mElapsed 0.72
[32m[2022-06-17 04:29:48] __main__ INFO: [0mTrain 8 273
[32m[2022-06-17 04:29:50] __main__ INFO: [0mEpoch 8 Step 39/39 lr 0.100000 loss 2.2870 (2.2806) acc@1 0.1136 (0.1163) acc@5 0.5468 (0.5575)
[32m[2022-06-17 04:29:50] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-17 04:29:50] __main__ INFO: [0mVal 8
[32m[2022-06-17 04:29:51] __main__ INFO: [0mEpoch 8 loss 2.2835 acc@1 0.1150 acc@5 0.5266
[32m[2022-06-17 04:29:51] __main__ INFO: [0mElapsed 0.78
[32m[2022-06-17 04:29:51] __main__ INFO: [0mTrain 9 312
[32m[2022-06-17 04:29:52] __main__ INFO: [0mEpoch 9 Step 39/39 lr 0.100000 loss 2.2678 (2.2717) acc@1 0.1327 (0.1246) acc@5 0.5459 (0.5615)
[32m[2022-06-17 04:29:52] __main__ INFO: [0mElapsed 1.76
[32m[2022-06-17 04:29:52] __main__ INFO: [0mVal 9
[32m[2022-06-17 04:29:53] __main__ INFO: [0mEpoch 9 loss 2.2195 acc@1 0.1395 acc@5 0.6161
[32m[2022-06-17 04:29:53] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-17 04:29:53] __main__ INFO: [0mTrain 10 351
[32m[2022-06-17 04:29:55] __main__ INFO: [0mEpoch 10 Step 39/39 lr 0.100000 loss 2.2781 (2.2564) acc@1 0.1226 (0.1349) acc@5 0.5202 (0.5736)
[32m[2022-06-17 04:29:55] __main__ INFO: [0mElapsed 1.79
[32m[2022-06-17 04:29:55] __main__ INFO: [0mVal 10
[32m[2022-06-17 04:29:56] __main__ INFO: [0mEpoch 10 loss 2.2013 acc@1 0.1741 acc@5 0.6463
[32m[2022-06-17 04:29:56] __main__ INFO: [0mElapsed 0.76
[32m[2022-06-17 04:29:56] __main__ INFO: [0mTrain 11 390
[32m[2022-06-17 04:29:57] __main__ INFO: [0mEpoch 11 Step 39/39 lr 0.100000 loss 2.3090 (2.2419) acc@1 0.1060 (0.1409) acc@5 0.4935 (0.5941)
[32m[2022-06-17 04:29:57] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-17 04:29:57] __main__ INFO: [0mVal 11
[32m[2022-06-17 04:29:58] __main__ INFO: [0mEpoch 11 loss 2.2083 acc@1 0.1486 acc@5 0.6170
[32m[2022-06-17 04:29:58] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-17 04:29:58] __main__ INFO: [0mTrain 12 429
[32m[2022-06-17 04:30:00] __main__ INFO: [0mEpoch 12 Step 39/39 lr 0.100000 loss 2.2644 (2.2273) acc@1 0.1338 (0.1534) acc@5 0.5553 (0.6122)
[32m[2022-06-17 04:30:00] __main__ INFO: [0mElapsed 1.74
[32m[2022-06-17 04:30:00] __main__ INFO: [0mVal 12
[32m[2022-06-17 04:30:01] __main__ INFO: [0mEpoch 12 loss 2.2432 acc@1 0.1459 acc@5 0.5824
[32m[2022-06-17 04:30:01] __main__ INFO: [0mElapsed 0.83
[32m[2022-06-17 04:30:01] __main__ INFO: [0mTrain 13 468
[32m[2022-06-17 04:30:03] __main__ INFO: [0mEpoch 13 Step 39/39 lr 0.100000 loss 2.2184 (2.2118) acc@1 0.1211 (0.1636) acc@5 0.6640 (0.6459)
[32m[2022-06-17 04:30:03] __main__ INFO: [0mElapsed 1.77
[32m[2022-06-17 04:30:03] __main__ INFO: [0mVal 13
[32m[2022-06-17 04:30:03] __main__ INFO: [0mEpoch 13 loss 2.2118 acc@1 0.1725 acc@5 0.6462
[32m[2022-06-17 04:30:03] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-17 04:30:03] __main__ INFO: [0mTrain 14 507
[32m[2022-06-17 04:30:05] __main__ INFO: [0mEpoch 14 Step 39/39 lr 0.100000 loss 2.1915 (2.1868) acc@1 0.1383 (0.1722) acc@5 0.6877 (0.6700)
[32m[2022-06-17 04:30:05] __main__ INFO: [0mElapsed 1.81
[32m[2022-06-17 04:30:05] __main__ INFO: [0mVal 14
[32m[2022-06-17 04:30:06] __main__ INFO: [0mEpoch 14 loss 2.1080 acc@1 0.2173 acc@5 0.7328
[32m[2022-06-17 04:30:06] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-17 04:30:06] __main__ INFO: [0mTrain 15 546
[32m[2022-06-17 04:30:08] __main__ INFO: [0mEpoch 15 Step 39/39 lr 0.100000 loss 2.2420 (2.1722) acc@1 0.1385 (0.1785) acc@5 0.6099 (0.6783)
[32m[2022-06-17 04:30:08] __main__ INFO: [0mElapsed 1.80
[32m[2022-06-17 04:30:08] __main__ INFO: [0mVal 15
[32m[2022-06-17 04:30:09] __main__ INFO: [0mEpoch 15 loss 2.0501 acc@1 0.2221 acc@5 0.7531
[32m[2022-06-17 04:30:09] __main__ INFO: [0mElapsed 0.75
[32m[2022-06-17 04:30:09] __main__ INFO: [0mTrain 16 585
[32m[2022-06-17 04:30:10] __main__ INFO: [0mEpoch 16 Step 39/39 lr 0.100000 loss 2.1778 (2.1652) acc@1 0.2032 (0.1782) acc@5 0.6619 (0.6858)
[32m[2022-06-17 04:30:10] __main__ INFO: [0mElapsed 1.72
[32m[2022-06-17 04:30:10] __main__ INFO: [0mVal 16
[32m[2022-06-17 04:30:11] __main__ INFO: [0mEpoch 16 loss 2.0547 acc@1 0.2207 acc@5 0.7682
[32m[2022-06-17 04:30:11] __main__ INFO: [0mElapsed 0.81
[32m[2022-06-17 04:30:11] __main__ INFO: [0mTrain 17 624
[32m[2022-06-17 04:30:13] __main__ INFO: [0mEpoch 17 Step 39/39 lr 0.100000 loss 2.1981 (2.1406) acc@1 0.1843 (0.1833) acc@5 0.6661 (0.6985)
[32m[2022-06-17 04:30:13] __main__ INFO: [0mElapsed 1.86
[32m[2022-06-17 04:30:13] __main__ INFO: [0mVal 17
[32m[2022-06-17 04:30:14] __main__ INFO: [0mEpoch 17 loss 2.0393 acc@1 0.2215 acc@5 0.7769
[32m[2022-06-17 04:30:14] __main__ INFO: [0mElapsed 0.77
[32m[2022-06-17 04:30:14] __main__ INFO: [0mTrain 18 663
[32m[2022-06-17 04:30:15] __main__ INFO: [0mEpoch 18 Step 39/39 lr 0.100000 loss 2.0879 (2.1314) acc@1 0.2149 (0.1974) acc@5 0.7492 (0.7080)
[32m[2022-06-17 04:30:16] __main__ INFO: [0mElapsed 1.81
[32m[2022-06-17 04:30:16] __main__ INFO: [0mVal 18
